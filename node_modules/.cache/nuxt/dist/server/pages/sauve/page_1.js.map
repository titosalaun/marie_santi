{"version":3,"file":"pages/sauve/page_1.js","sources":["webpack:///./node_modules/p5/lib/addons/p5.sound.js","webpack:///./pages/sauve/page_1.vue?e8dd","webpack:///./pages/sauve/page_1.vue?8465","webpack:///./pages/sauve/page_1.vue?5830","webpack:///./pages/sauve/page_1.vue"],"sourcesContent":["/** [p5.sound]  Version: 1.0.1 - 2021-05-25 */ \n /**\n *  <p>p5.sound extends p5 with <a href=\"http://caniuse.com/audio-api\"\n *  target=\"_blank\">Web Audio</a> functionality including audio input,\n *  playback, analysis and synthesis.\n *  </p>\n *  <ul>\n *  <li><a href=\"#/p5.SoundFile\"><b>p5.SoundFile</b></a>: Load and play sound files.</li>\n *  <li><a href=\"#/p5.Amplitude\"><b>p5.Amplitude</b></a>: Get the current volume of a sound.</li>\n *  <li><a href=\"#/p5.AudioIn\"><b>p5.AudioIn</b></a>: Get sound from an input source, typically\n *    a computer microphone.</li>\n *  <li><a href=\"#/p5.FFT\"><b>p5.FFT</b></a>: Analyze the frequency of sound. Returns\n *    results from the frequency spectrum or time domain (waveform).</li>\n *  <li><a href=\"#/p5.Oscillator\"><b>p5.Oscillator</b></a>: Generate Sine,\n *    Triangle, Square and Sawtooth waveforms. Base class of\n *    <li><a href=\"#/p5.Noise\">p5.Noise</a> and <a href=\"#/p5.Pulse\">p5.Pulse</a>.\n *    </li>\n *  <li>\n *    <a href=\"#/p5.MonoSynth\">p5.MonoSynth</a> and <a href=\"#/p5.PolySynth\">p5.PolySynth</a>: Play musical notes\n *  </li>\n *  <li><a href=\"#/p5.Envelope\"><b>p5.Envelope</b></a>: An Envelope is a series\n *    of fades over time. Often used to control an object's\n *    output gain level as an \"ADSR Envelope\" (Attack, Decay,\n *    Sustain, Release). Can also modulate other parameters.</li>\n *  <li><a href=\"#/p5.Delay\"><b>p5.Delay</b></a>: A delay effect with\n *    parameters for feedback, delayTime, and lowpass filter.</li>\n *  <li><a href=\"#/p5.Filter\"><b>p5.Filter</b></a>: Filter the frequency range of a\n *    sound.\n *  </li>\n *  <li><a href=\"#/p5.Reverb\"><b>p5.Reverb</b></a>: Add reverb to a sound by specifying\n *    duration and decay. </li>\n *  <b><li><a href=\"#/p5.Convolver\">p5.Convolver</a>:</b> Extends\n *  <a href=\"#/p5.Reverb\">p5.Reverb</a> to simulate the sound of real\n *    physical spaces through convolution.</li>\n *  <b><li><a href=\"#/p5.SoundRecorder\">p5.SoundRecorder</a></b>: Record sound for playback\n *    / save the .wav file.\n *  <b><li><a href=\"#/p5.SoundLoop\">p5.SoundLoop</a>, <a href=\"#/p5.Phrase\">p5.Phrase</a></b>, <b><a href=\"#/p5.Part\">p5.Part</a></b> and\n *  <b><a href=\"#/p5.Score\">p5.Score</a></b>: Compose musical sequences.\n *  </li>\n *  <li><a href=\"#/p5/userStartAudio\">userStartAudio</a>: Enable audio in a\n *  browser- and user-friendly way.</a>\n *  <p>p5.sound is on <a href=\"https://github.com/processing/p5.js-sound/\">GitHub</a>.\n *  Download the latest version\n *  <a href=\"https://github.com/processing/p5.js-sound/blob/master/lib/p5.sound.js\">here</a>.</p>\n *\n *  @module p5.sound\n *  @submodule p5.sound\n *  @for p5.sound\n *  @main\n */\n\n/**\n *  p5.sound \n *  https://p5js.org/reference/#/libraries/p5.sound\n *\n *  From the Processing Foundation and contributors\n *  https://github.com/processing/p5.js-sound/graphs/contributors\n *\n *  MIT License (MIT)\n *  https://github.com/processing/p5.js-sound/blob/master/LICENSE\n *\n *  Some of the many audio libraries & resources that inspire p5.sound:\n *   - TONE.js (c) Yotam Mann. Licensed under The MIT License (MIT). https://github.com/TONEnoTONE/Tone.js\n *   - buzz.js (c) Jay Salvat. Licensed under The MIT License (MIT). http://buzz.jaysalvat.com/\n *   - Boris Smus Web Audio API book, 2013. Licensed under the Apache License http://www.apache.org/licenses/LICENSE-2.0\n *   - wavesurfer.js https://github.com/katspaugh/wavesurfer.js\n *   - Web Audio Components by Jordan Santell https://github.com/web-audio-components\n *   - Wilm Thoben's Sound library for Processing https://github.com/processing/processing/tree/master/java/libraries/sound\n *\n *   Web Audio API: http://w3.org/TR/webaudio/\n */\n\n (function(modules) { \n \tvar installedModules = {};\n \tfunction __webpack_require__(moduleId) {\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n \t\tmodule.l = true;\n \t\treturn module.exports;\n \t}\n \t__webpack_require__.m = modules;\n \t__webpack_require__.c = installedModules;\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n \t__webpack_require__.p = \"\";\n \treturn __webpack_require__(__webpack_require__.s = 40);\n })\n ([\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_RESULT__ = (function(){\"use strict\";function a(t,e){this.isUndef(t)||1===t?this.input=this.context.createGain():1<t&&(this.input=new Array(t)),this.isUndef(e)||1===e?this.output=this.context.createGain():1<e&&(this.output=new Array(t))}var e;return a.prototype.set=function(t,e,n){if(this.isObject(t))n=e;else if(this.isString(t)){var o={};o[t]=e,t=o}t:for(var i in t){e=t[i];var r=this;if(-1!==i.indexOf(\".\")){for(var s=i.split(\".\"),u=0;u<s.length-1;u++)if((r=r[s[u]])instanceof a){s.splice(0,u+1);var p=s.join(\".\");r.set(p,e);continue t}i=s[s.length-1]}var c=r[i];this.isUndef(c)||(a.Signal&&c instanceof a.Signal||a.Param&&c instanceof a.Param?c.value!==e&&(this.isUndef(n)?c.value=e:c.rampTo(e,n)):c instanceof AudioParam?c.value!==e&&(c.value=e):c instanceof a?c.set(e):c!==e&&(r[i]=e))}return this},a.prototype.get=function(t){this.isUndef(t)?t=this._collectDefaults(this.constructor):this.isString(t)&&(t=[t]);for(var e={},n=0;n<t.length;n++){var o=t[n],i=this,r=e;if(-1!==o.indexOf(\".\")){for(var s=o.split(\".\"),u=0;u<s.length-1;u++){var p=s[u];r[p]=r[p]||{},r=r[p],i=i[p]}o=s[s.length-1]}var c=i[o];this.isObject(t[o])?r[o]=c.get():a.Signal&&c instanceof a.Signal?r[o]=c.value:a.Param&&c instanceof a.Param?r[o]=c.value:c instanceof AudioParam?r[o]=c.value:c instanceof a?r[o]=c.get():this.isFunction(c)||this.isUndef(c)||(r[o]=c)}return e},a.prototype._collectDefaults=function(t){var e=[];if(this.isUndef(t.defaults)||(e=Object.keys(t.defaults)),!this.isUndef(t._super))for(var n=this._collectDefaults(t._super),o=0;o<n.length;o++)-1===e.indexOf(n[o])&&e.push(n[o]);return e},a.prototype.toString=function(){for(var t in a){var e=t[0].match(/^[A-Z]$/),n=a[t]===this.constructor;if(this.isFunction(a[t])&&e&&n)return t}return\"Tone\"},Object.defineProperty(a.prototype,\"numberOfInputs\",{get:function(){return this.input?this.isArray(this.input)?this.input.length:1:0}}),Object.defineProperty(a.prototype,\"numberOfOutputs\",{get:function(){return this.output?this.isArray(this.output)?this.output.length:1:0}}),a.prototype.dispose=function(){return this.isUndef(this.input)||(this.input instanceof AudioNode&&this.input.disconnect(),this.input=null),this.isUndef(this.output)||(this.output instanceof AudioNode&&this.output.disconnect(),this.output=null),this},a.prototype.connect=function(t,e,n){return Array.isArray(this.output)?(e=this.defaultArg(e,0),this.output[e].connect(t,0,n)):this.output.connect(t,e,n),this},a.prototype.disconnect=function(t,e,n){this.isArray(this.output)?this.isNumber(t)?this.output[t].disconnect():(e=this.defaultArg(e,0),this.output[e].disconnect(t,0,n)):this.output.disconnect.apply(this.output,arguments)},a.prototype.connectSeries=function(){if(1<arguments.length)for(var t=arguments[0],e=1;e<arguments.length;e++){var n=arguments[e];t.connect(n),t=n}return this},a.prototype.chain=function(){if(0<arguments.length)for(var t=this,e=0;e<arguments.length;e++){var n=arguments[e];t.connect(n),t=n}return this},a.prototype.fan=function(){if(0<arguments.length)for(var t=0;t<arguments.length;t++)this.connect(arguments[t]);return this},AudioNode.prototype.chain=a.prototype.chain,AudioNode.prototype.fan=a.prototype.fan,a.prototype.defaultArg=function(t,e){if(this.isObject(t)&&this.isObject(e)){var n={};for(var o in t)n[o]=this.defaultArg(e[o],t[o]);for(var i in e)n[i]=this.defaultArg(t[i],e[i]);return n}return this.isUndef(t)?e:t},a.prototype.optionsObject=function(t,e,n){var o={};if(1===t.length&&this.isObject(t[0]))o=t[0];else for(var i=0;i<e.length;i++)o[e[i]]=t[i];return this.isUndef(n)?o:this.defaultArg(o,n)},a.prototype.isUndef=function(t){return void 0===t},a.prototype.isFunction=function(t){return\"function\"==typeof t},a.prototype.isNumber=function(t){return\"number\"==typeof t},a.prototype.isObject=function(t){return\"[object Object]\"===Object.prototype.toString.call(t)&&t.constructor===Object},a.prototype.isBoolean=function(t){return\"boolean\"==typeof t},a.prototype.isArray=function(t){return Array.isArray(t)},a.prototype.isString=function(t){return\"string\"==typeof t},a.noOp=function(){},a.prototype._readOnly=function(t){if(Array.isArray(t))for(var e=0;e<t.length;e++)this._readOnly(t[e]);else Object.defineProperty(this,t,{writable:!1,enumerable:!0})},a.prototype._writable=function(t){if(Array.isArray(t))for(var e=0;e<t.length;e++)this._writable(t[e]);else Object.defineProperty(this,t,{writable:!0})},a.State={Started:\"started\",Stopped:\"stopped\",Paused:\"paused\"},a.prototype.equalPowerScale=function(t){var e=.5*Math.PI;return Math.sin(t*e)},a.prototype.dbToGain=function(t){return Math.pow(2,t/6)},a.prototype.gainToDb=function(t){return Math.log(t)/Math.LN10*20},a.prototype.intervalToFrequencyRatio=function(t){return Math.pow(2,t/12)},a.prototype.now=function(){return a.context.now()},a.now=function(){return a.context.now()},a.extend=function(t,e){function n(){}a.prototype.isUndef(e)&&(e=a),n.prototype=e.prototype,t.prototype=new n,(t.prototype.constructor=t)._super=e},Object.defineProperty(a,\"context\",{get:function(){return e},set:function(t){e=a.Context&&t instanceof a.Context?t:new a.Context(t),a.Context&&a.Context.emit(\"init\",e)}}),Object.defineProperty(a.prototype,\"context\",{get:function(){return a.context}}),a.setContext=function(t){a.context=t},Object.defineProperty(a.prototype,\"blockTime\",{get:function(){return 128/this.context.sampleRate}}),Object.defineProperty(a.prototype,\"sampleTime\",{get:function(){return 1/this.context.sampleRate}}),Object.defineProperty(a,\"supported\",{get:function(){var t=window.hasOwnProperty(\"AudioContext\")||window.hasOwnProperty(\"webkitAudioContext\"),e=window.hasOwnProperty(\"Promise\"),n=window.hasOwnProperty(\"Worker\");return t&&e&&n}}),a.version=\"r10\",window.TONE_SILENCE_VERSION_LOGGING||console.log(\"%c * Tone.js \"+a.version+\" * \",\"background: #000; color: #fff\"),a}).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(2),__webpack_require__(10)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(i){\"use strict\";return i.Multiply=function(t){this.createInsOuts(2,0),this._mult=this.input[0]=this.output=new i.Gain,this._param=this.input[1]=this.output.gain,this._param.value=this.defaultArg(t,0)},i.extend(i.Multiply,i.Signal),i.Multiply.prototype.dispose=function(){return i.prototype.dispose.call(this),this._mult.dispose(),this._mult=null,this._param=null,this},i.Multiply}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(6),__webpack_require__(9),__webpack_require__(18),__webpack_require__(10)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(n){\"use strict\";return n.Signal=function(){var t=this.optionsObject(arguments,[\"value\",\"units\"],n.Signal.defaults);this.output=this._gain=this.context.createGain(),t.param=this._gain.gain,n.Param.call(this,t),this.input=this._param=this._gain.gain,this.context.getConstant(1).chain(this._gain)},n.extend(n.Signal,n.Param),n.Signal.defaults={value:0,units:n.Type.Default,convert:!0},n.Signal.prototype.connect=n.SignalBase.prototype.connect,n.Signal.prototype.dispose=function(){return n.Param.prototype.dispose.call(this),this._param=null,this._gain.disconnect(),this._gain=null,this},n.Signal}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n(function(global) { __webpack_require__.d(__webpack_exports__, \"b\", function() { return getAudioContext; });\n __webpack_require__.d(__webpack_exports__, \"c\", function() { return userStartAudio; });\n var startaudiocontext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(22);\n var startaudiocontext__WEBPACK_IMPORTED_MODULE_0___default = __webpack_require__.n(startaudiocontext__WEBPACK_IMPORTED_MODULE_0__);\n var Tone_core_Tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(0);\n var Tone_core_Tone__WEBPACK_IMPORTED_MODULE_1___default = __webpack_require__.n(Tone_core_Tone__WEBPACK_IMPORTED_MODULE_1__);\n var Tone_core_Context__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(12);\n var Tone_core_Context__WEBPACK_IMPORTED_MODULE_2___default = __webpack_require__.n(Tone_core_Context__WEBPACK_IMPORTED_MODULE_2__);\nglobal.TONE_SILENCE_VERSION_LOGGING = true;\n\n\n\nvar audiocontext = new window.AudioContext(); \n\nTone_core_Tone__WEBPACK_IMPORTED_MODULE_1___default.a.setContext(audiocontext);\n/**\n * <p>Returns the Audio Context for this sketch. Useful for users\n * who would like to dig deeper into the <a target='_blank' href=\n * 'http://webaudio.github.io/web-audio-api/'>Web Audio API\n * </a>.</p>\n *\n * <p>Some browsers require users to startAudioContext\n * with a user gesture, such as touchStarted in the example below.</p>\n *\n * @for p5\n * @method getAudioContext\n * @return {Object}    AudioContext for this sketch\n * @example\n * <div><code>\n *  function draw() {\n *    background(255);\n *    textAlign(CENTER);\n *\n *    if (getAudioContext().state !== 'running') {\n *      text('click to start audio', width/2, height/2);\n *    } else {\n *      text('audio is enabled', width/2, height/2);\n *    }\n *  }\n *\n *  function touchStarted() {\n *    if (getAudioContext().state !== 'running') {\n *      getAudioContext().resume();\n *    }\n *    var synth = new p5.MonoSynth();\n *    synth.play('A4', 0.5, 0, 0.2);\n *  }\n *\n * </div></code>\n */\n\nfunction getAudioContext() {\n  return audiocontext;\n}\n/**\n *  <p>It is not only a good practice to give users control over starting\n *  audio. This policy is enforced by many web browsers, including iOS and\n *  <a href=\"https://goo.gl/7K7WLu\" title=\"Google Chrome's autoplay\n *  policy\">Google Chrome</a>, which create the Web Audio API's\n *  <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\"\n *  title=\"Audio Context @ MDN\">Audio Context</a>\n *  in a suspended state.</p>\n *\n *  <p>In these browser-specific policies, sound will not play until a user\n *  interaction event (i.e. <code>mousePressed()</code>) explicitly resumes\n *  the AudioContext, or starts an audio node. This can be accomplished by\n *  calling <code>start()</code> on a <code>p5.Oscillator</code>,\n *  <code> play()</code> on a <code>p5.SoundFile</code>, or simply\n *  <code>userStartAudio()</code>.</p>\n *\n *  <p><code>userStartAudio()</code> starts the AudioContext on a user\n *  gesture. The default behavior will enable audio on any\n *  mouseUp or touchEnd event. It can also be placed in a specific\n *  interaction function, such as <code>mousePressed()</code> as in the\n *  example below. This method utilizes\n *  <a href=\"https://github.com/tambien/StartAudioContext\">StartAudioContext\n *  </a>, a library by Yotam Mann (MIT Licence, 2016).</p>\n *  @param  {Element|Array}   [element(s)] This argument can be an Element,\n *                                Selector String, NodeList, p5.Element,\n *                                jQuery Element, or an Array of any of those.\n *  @param  {Function} [callback] Callback to invoke when the AudioContext\n *                                has started\n *  @return {Promise}            Returns a Promise that resolves when\n *                                       the AudioContext state is 'running'\n *  @method userStartAudio\n *  @for p5\n *  @example\n *  <div><code>\n *  function setup() {\n *    // mimics the autoplay policy\n *    getAudioContext().suspend();\n *\n *    let mySynth = new p5.MonoSynth();\n *\n *    // This won't play until the context has resumed\n *    mySynth.play('A6');\n *  }\n *  function draw() {\n *    background(220);\n *    textAlign(CENTER, CENTER);\n *    text(getAudioContext().state, width/2, height/2);\n *  }\n *  function mousePressed() {\n *    userStartAudio();\n *  }\n *  </code></div>\n */\n\nfunction userStartAudio(elements, callback) {\n  var elt = elements;\n\n  if (elements instanceof p5.Element) {\n    elt = elements.elt;\n  } else if (elements instanceof Array && elements[0] instanceof p5.Element) {\n    elt = elements.map(function (e) {\n      return e.elt;\n    });\n  }\n\n  return startaudiocontext__WEBPACK_IMPORTED_MODULE_0___default()(audiocontext, elt, callback);\n}\n __webpack_exports__[\"a\"] = (audiocontext);\n}.call(this, __webpack_require__(26)))\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(2),__webpack_require__(10)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(i){\"use strict\";return i.Add=function(t){this.createInsOuts(2,0),this._sum=this.input[0]=this.input[1]=this.output=new i.Gain,this._param=this.input[1]=new i.Signal(t),this._param.connect(this._sum)},i.extend(i.Add,i.Signal),i.Add.prototype.dispose=function(){return i.prototype.dispose.call(this),this._sum.dispose(),this._sum=null,this._param.dispose(),this._param=null,this},i.Add}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports) {\n\nmodule.exports = {\n  recorderProcessor: 'recorder-processor',\n  soundFileProcessor: 'sound-file-processor',\n  amplitudeProcessor: 'amplitude-processor'\n};\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(15)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(e){\"use strict\";return e.WaveShaper=function(e,t){this._shaper=this.input=this.output=this.context.createWaveShaper(),this._curve=null,Array.isArray(e)?this.curve=e:isFinite(e)||this.isUndef(e)?this._curve=new Float32Array(this.defaultArg(e,1024)):this.isFunction(e)&&(this._curve=new Float32Array(this.defaultArg(t,1024)),this.setMap(e))},e.extend(e.WaveShaper,e.SignalBase),e.WaveShaper.prototype.setMap=function(e){for(var t=0,r=this._curve.length;t<r;t++){var s=t/(r-1)*2-1;this._curve[t]=e(s,t)}return this._shaper.curve=this._curve,this},Object.defineProperty(e.WaveShaper.prototype,\"curve\",{get:function(){return this._shaper.curve},set:function(e){this._curve=new Float32Array(e),this._shaper.curve=this._curve}}),Object.defineProperty(e.WaveShaper.prototype,\"oversample\",{get:function(){return this._shaper.oversample},set:function(e){if(-1===[\"none\",\"2x\",\"4x\"].indexOf(e))throw new RangeError(\"Tone.WaveShaper: oversampling must be either 'none', '2x', or '4x'\");this._shaper.oversample=e}}),e.WaveShaper.prototype.dispose=function(){return e.prototype.dispose.call(this),this._shaper.disconnect(),this._shaper=null,this._curve=null,this},e.WaveShaper}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(2),__webpack_require__(19)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(o){\"use strict\";return o.TimelineSignal=function(){var e=this.optionsObject(arguments,[\"value\",\"units\"],o.Signal.defaults);this._events=new o.Timeline(10),o.Signal.apply(this,e),e.param=this._param,o.Param.call(this,e),this._initial=this._fromUnits(this._param.value)},o.extend(o.TimelineSignal,o.Param),o.TimelineSignal.Type={Linear:\"linear\",Exponential:\"exponential\",Target:\"target\",Curve:\"curve\",Set:\"set\"},Object.defineProperty(o.TimelineSignal.prototype,\"value\",{get:function(){var e=this.now(),t=this.getValueAtTime(e);return this._toUnits(t)},set:function(e){var t=this._fromUnits(e);this._initial=t,this.cancelScheduledValues(),this._param.value=t}}),o.TimelineSignal.prototype.setValueAtTime=function(e,t){return e=this._fromUnits(e),t=this.toSeconds(t),this._events.add({type:o.TimelineSignal.Type.Set,value:e,time:t}),this._param.setValueAtTime(e,t),this},o.TimelineSignal.prototype.linearRampToValueAtTime=function(e,t){return e=this._fromUnits(e),t=this.toSeconds(t),this._events.add({type:o.TimelineSignal.Type.Linear,value:e,time:t}),this._param.linearRampToValueAtTime(e,t),this},o.TimelineSignal.prototype.exponentialRampToValueAtTime=function(e,t){t=this.toSeconds(t);var i=this._searchBefore(t);i&&0===i.value&&this.setValueAtTime(this._minOutput,i.time),e=this._fromUnits(e);var n=Math.max(e,this._minOutput);return this._events.add({type:o.TimelineSignal.Type.Exponential,value:n,time:t}),e<this._minOutput?(this._param.exponentialRampToValueAtTime(this._minOutput,t-this.sampleTime),this.setValueAtTime(0,t)):this._param.exponentialRampToValueAtTime(e,t),this},o.TimelineSignal.prototype.setTargetAtTime=function(e,t,i){return e=this._fromUnits(e),e=Math.max(this._minOutput,e),i=Math.max(this._minOutput,i),t=this.toSeconds(t),this._events.add({type:o.TimelineSignal.Type.Target,value:e,time:t,constant:i}),this._param.setTargetAtTime(e,t,i),this},o.TimelineSignal.prototype.setValueCurveAtTime=function(e,t,i,n){n=this.defaultArg(n,1);for(var a=new Array(e.length),l=0;l<a.length;l++)a[l]=this._fromUnits(e[l])*n;t=this.toSeconds(t),i=this.toSeconds(i),this._events.add({type:o.TimelineSignal.Type.Curve,value:a,time:t,duration:i}),this._param.setValueAtTime(a[0],t);for(var s=1;s<a.length;s++){var r=t+s/(a.length-1)*i;this._param.linearRampToValueAtTime(a[s],r)}return this},o.TimelineSignal.prototype.cancelScheduledValues=function(e){return e=this.toSeconds(e),this._events.cancel(e),this._param.cancelScheduledValues(e),this},o.TimelineSignal.prototype.setRampPoint=function(e){e=this.toSeconds(e);var t=this._toUnits(this.getValueAtTime(e)),i=this._searchBefore(e);if(i&&i.time===e)this.cancelScheduledValues(e+this.sampleTime);else if(i&&i.type===o.TimelineSignal.Type.Curve&&i.time+i.duration>e)this.cancelScheduledValues(e),this.linearRampToValueAtTime(t,e);else{var n=this._searchAfter(e);n&&(this.cancelScheduledValues(e),n.type===o.TimelineSignal.Type.Linear?this.linearRampToValueAtTime(t,e):n.type===o.TimelineSignal.Type.Exponential&&this.exponentialRampToValueAtTime(t,e)),this.setValueAtTime(t,e)}return this},o.TimelineSignal.prototype.linearRampToValueBetween=function(e,t,i){return this.setRampPoint(t),this.linearRampToValueAtTime(e,i),this},o.TimelineSignal.prototype.exponentialRampToValueBetween=function(e,t,i){return this.setRampPoint(t),this.exponentialRampToValueAtTime(e,i),this},o.TimelineSignal.prototype._searchBefore=function(e){return this._events.get(e)},o.TimelineSignal.prototype._searchAfter=function(e){return this._events.getAfter(e)},o.TimelineSignal.prototype.getValueAtTime=function(e){e=this.toSeconds(e);var t=this._searchAfter(e),i=this._searchBefore(e),n=this._initial;if(null===i)n=this._initial;else if(i.type===o.TimelineSignal.Type.Target){var a,l=this._events.getBefore(i.time);a=null===l?this._initial:l.value,n=this._exponentialApproach(i.time,a,i.value,i.constant,e)}else n=i.type===o.TimelineSignal.Type.Curve?this._curveInterpolate(i.time,i.value,i.duration,e):null===t?i.value:t.type===o.TimelineSignal.Type.Linear?this._linearInterpolate(i.time,i.value,t.time,t.value,e):t.type===o.TimelineSignal.Type.Exponential?this._exponentialInterpolate(i.time,i.value,t.time,t.value,e):i.value;return n},o.TimelineSignal.prototype.connect=o.SignalBase.prototype.connect,o.TimelineSignal.prototype._exponentialApproach=function(e,t,i,n,a){return i+(t-i)*Math.exp(-(a-e)/n)},o.TimelineSignal.prototype._linearInterpolate=function(e,t,i,n,a){return t+(a-e)/(i-e)*(n-t)},o.TimelineSignal.prototype._exponentialInterpolate=function(e,t,i,n,a){return(t=Math.max(this._minOutput,t))*Math.pow(n/t,(a-e)/(i-e))},o.TimelineSignal.prototype._curveInterpolate=function(e,t,i,n){var a=t.length;if(e+i<=n)return t[a-1];if(n<=e)return t[0];var l=(n-e)/i,s=Math.floor((a-1)*l),r=Math.ceil((a-1)*l),o=t[s],p=t[r];return r===s?o:this._linearInterpolate(s,o,r,p,l*(a-1))},o.TimelineSignal.prototype.dispose=function(){o.Signal.prototype.dispose.call(this),o.Param.prototype.dispose.call(this),this._events.dispose(),this._events=null},o.TimelineSignal}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(4),__webpack_require__(1),__webpack_require__(2)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(i){\"use strict\";return i.Scale=function(t,e){this._outputMin=this.defaultArg(t,0),this._outputMax=this.defaultArg(e,1),this._scale=this.input=new i.Multiply(1),this._add=this.output=new i.Add(0),this._scale.connect(this._add),this._setRange()},i.extend(i.Scale,i.SignalBase),Object.defineProperty(i.Scale.prototype,\"min\",{get:function(){return this._outputMin},set:function(t){this._outputMin=t,this._setRange()}}),Object.defineProperty(i.Scale.prototype,\"max\",{get:function(){return this._outputMax},set:function(t){this._outputMax=t,this._setRange()}}),i.Scale.prototype._setRange=function(){this._add.value=this._outputMin,this._scale.value=this._outputMax-this._outputMin},i.Scale.prototype.dispose=function(){return i.prototype.dispose.call(this),this._add.dispose(),this._add=null,this._scale.dispose(),this._scale=null,this},i.Scale}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(16),__webpack_require__(30),__webpack_require__(31),__webpack_require__(12)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(t){return t.Type={Default:\"number\",Time:\"time\",Frequency:\"frequency\",TransportTime:\"transportTime\",Ticks:\"ticks\",NormalRange:\"normalRange\",AudioRange:\"audioRange\",Decibels:\"db\",Interval:\"interval\",BPM:\"bpm\",Positive:\"positive\",Cents:\"cents\",Degrees:\"degrees\",MIDI:\"midi\",BarsBeatsSixteenths:\"barsBeatsSixteenths\",Samples:\"samples\",Hertz:\"hertz\",Note:\"note\",Milliseconds:\"milliseconds\",Seconds:\"seconds\",Notation:\"notation\"},t.prototype.toSeconds=function(e){return this.isNumber(e)?e:this.isUndef(e)?this.now():this.isString(e)?new t.Time(e).toSeconds():e instanceof t.TimeBase?e.toSeconds():void 0},t.prototype.toFrequency=function(e){return this.isNumber(e)?e:this.isString(e)||this.isUndef(e)?new t.Frequency(e).valueOf():e instanceof t.TimeBase?e.toFrequency():void 0},t.prototype.toTicks=function(e){return this.isNumber(e)||this.isString(e)?new t.TransportTime(e).toTicks():this.isUndef(e)?t.Transport.ticks:e instanceof t.TimeBase?e.toTicks():void 0},t}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(18),__webpack_require__(9)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(i){\"use strict\";return window.GainNode&&!AudioContext.prototype.createGain&&(AudioContext.prototype.createGain=AudioContext.prototype.createGainNode),i.Gain=function(){var t=this.optionsObject(arguments,[\"gain\",\"units\"],i.Gain.defaults);this.input=this.output=this._gainNode=this.context.createGain(),this.gain=new i.Param({param:this._gainNode.gain,units:t.units,value:t.gain,convert:t.convert}),this._readOnly(\"gain\")},i.extend(i.Gain),i.Gain.defaults={gain:1,convert:!0},i.Gain.prototype.dispose=function(){i.Param.prototype.dispose.call(this),this._gainNode.disconnect(),this._gainNode=null,this._writable(\"gain\"),this.gain.dispose(),this.gain=null},i.prototype.createInsOuts=function(t,n){1===t?this.input=new i.Gain:1<t&&(this.input=new Array(t)),1===n?this.output=new i.Gain:1<n&&(this.output=new Array(t))},i.Gain}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(7),__webpack_require__(39),__webpack_require__(14),__webpack_require__(12)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(o){\"use strict\";return o.Clock=function(){o.Emitter.call(this);var t=this.optionsObject(arguments,[\"callback\",\"frequency\"],o.Clock.defaults);this.callback=t.callback,this._nextTick=0,this._lastState=o.State.Stopped,this.frequency=new o.TimelineSignal(t.frequency,o.Type.Frequency),this._readOnly(\"frequency\"),this.ticks=0,this._state=new o.TimelineState(o.State.Stopped),this._boundLoop=this._loop.bind(this),this.context.on(\"tick\",this._boundLoop)},o.extend(o.Clock,o.Emitter),o.Clock.defaults={callback:o.noOp,frequency:1,lookAhead:\"auto\"},Object.defineProperty(o.Clock.prototype,\"state\",{get:function(){return this._state.getValueAtTime(this.now())}}),o.Clock.prototype.start=function(t,e){return t=this.toSeconds(t),this._state.getValueAtTime(t)!==o.State.Started&&this._state.add({state:o.State.Started,time:t,offset:e}),this},o.Clock.prototype.stop=function(t){return t=this.toSeconds(t),this._state.cancel(t),this._state.setStateAtTime(o.State.Stopped,t),this},o.Clock.prototype.pause=function(t){return t=this.toSeconds(t),this._state.getValueAtTime(t)===o.State.Started&&this._state.setStateAtTime(o.State.Paused,t),this},o.Clock.prototype._loop=function(){for(var t=this.now()+this.context.lookAhead+this.context.updateInterval+2*this.context.lag;t>this._nextTick&&this._state;){var e=this._state.getValueAtTime(this._nextTick);if(e!==this._lastState){this._lastState=e;var i=this._state.get(this._nextTick);e===o.State.Started?(this._nextTick=i.time,this.isUndef(i.offset)||(this.ticks=i.offset),this.emit(\"start\",i.time,this.ticks)):e===o.State.Stopped?(this.ticks=0,this.emit(\"stop\",i.time)):e===o.State.Paused&&this.emit(\"pause\",i.time)}var s=this._nextTick;this.frequency&&(this._nextTick+=1/this.frequency.getValueAtTime(this._nextTick),e===o.State.Started&&(this.callback(s),this.ticks++))}},o.Clock.prototype.getStateAtTime=function(t){return t=this.toSeconds(t),this._state.getValueAtTime(t)},o.Clock.prototype.dispose=function(){o.Emitter.prototype.dispose.call(this),this.context.off(\"tick\",this._boundLoop),this._writable(\"frequency\"),this.frequency.dispose(),this.frequency=null,this._boundLoop=null,this._nextTick=1/0,this.callback=null,this._state.dispose(),this._state=null},o.Clock}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(14)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(o){function t(e,t,n){if(e.input)Array.isArray(e.input)?(o.prototype.isUndef(n)&&(n=0),this.connect(e.input[n])):this.connect(e.input,t,n);else try{e instanceof AudioNode?i.call(this,e,t,n):i.call(this,e,t)}catch(t){throw new Error(\"error connecting to node: \"+e+\"\\n\"+t)}}var i,r;return!window.hasOwnProperty(\"AudioContext\")&&window.hasOwnProperty(\"webkitAudioContext\")&&(window.AudioContext=window.webkitAudioContext),o.Context=function(t){for(var e in o.Emitter.call(this),t=t||new window.AudioContext,this._context=t,this._context)this._defineProperty(this._context,e);this._latencyHint=\"interactive\",this._lookAhead=.1,this._updateInterval=this._lookAhead/3,this._computedUpdateInterval=0,this._worker=this._createWorker(),this._constants={}},o.extend(o.Context,o.Emitter),o.Emitter.mixin(o.Context),o.Context.prototype._defineProperty=function(e,n){this.isUndef(this[n])&&Object.defineProperty(this,n,{get:function(){return\"function\"==typeof e[n]?e[n].bind(e):e[n]},set:function(t){e[n]=t}})},o.Context.prototype.now=function(){return this._context.currentTime},o.Context.prototype._createWorker=function(){window.URL=window.URL||window.webkitURL;var t=new Blob([\"var timeoutTime = \"+(1e3*this._updateInterval).toFixed(1)+\";self.onmessage = function(msg){\\ttimeoutTime = parseInt(msg.data);};function tick(){\\tsetTimeout(tick, timeoutTime);\\tself.postMessage('tick');}tick();\"]),e=URL.createObjectURL(t),n=new Worker(e);return n.addEventListener(\"message\",function(){this.emit(\"tick\")}.bind(this)),n.addEventListener(\"message\",function(){var t=this.now();if(this.isNumber(this._lastUpdate)){var e=t-this._lastUpdate;this._computedUpdateInterval=Math.max(e,.97*this._computedUpdateInterval)}this._lastUpdate=t}.bind(this)),n},o.Context.prototype.getConstant=function(t){if(this._constants[t])return this._constants[t];for(var e=this._context.createBuffer(1,128,this._context.sampleRate),n=e.getChannelData(0),o=0;o<n.length;o++)n[o]=t;var i=this._context.createBufferSource();return i.channelCount=1,i.channelCountMode=\"explicit\",i.buffer=e,i.loop=!0,i.start(0),this._constants[t]=i},Object.defineProperty(o.Context.prototype,\"lag\",{get:function(){var t=this._computedUpdateInterval-this._updateInterval;return t=Math.max(t,0)}}),Object.defineProperty(o.Context.prototype,\"lookAhead\",{get:function(){return this._lookAhead},set:function(t){this._lookAhead=t}}),Object.defineProperty(o.Context.prototype,\"updateInterval\",{get:function(){return this._updateInterval},set:function(t){this._updateInterval=Math.max(t,o.prototype.blockTime),this._worker.postMessage(Math.max(1e3*t,1))}}),Object.defineProperty(o.Context.prototype,\"latencyHint\",{get:function(){return this._latencyHint},set:function(t){var e=t;if(this._latencyHint=t,this.isString(t))switch(t){case\"interactive\":e=.1,this._context.latencyHint=t;break;case\"playback\":e=.8,this._context.latencyHint=t;break;case\"balanced\":e=.25,this._context.latencyHint=t;break;case\"fastest\":e=.01}this.lookAhead=e,this.updateInterval=e/3}}),o.supported?(i=AudioNode.prototype.connect,r=AudioNode.prototype.disconnect,AudioNode.prototype.connect!==t&&(AudioNode.prototype.connect=t,AudioNode.prototype.disconnect=function(e,t,n){if(e&&e.input&&Array.isArray(e.input))o.prototype.isUndef(n)&&(n=0),this.disconnect(e.input[n],t,n);else if(e&&e.input)this.disconnect(e.input,t,n);else try{r.apply(this,arguments)}catch(t){throw new Error(\"error disconnecting node: \"+e+\"\\n\"+t)}}),o.context=new o.Context):console.warn(\"This browser does not support Tone.js\"),o.Context}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(4),__webpack_require__(20),__webpack_require__(2),__webpack_require__(10)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(n){\"use strict\";return n.Subtract=function(t){this.createInsOuts(2,0),this._sum=this.input[0]=this.output=new n.Gain,this._neg=new n.Negate,this._param=this.input[1]=new n.Signal(t),this._param.chain(this._neg,this._sum)},n.extend(n.Subtract,n.Signal),n.Subtract.prototype.dispose=function(){return n.prototype.dispose.call(this),this._neg.dispose(),this._neg=null,this._sum.disconnect(),this._sum=null,this._param.dispose(),this._param=null,this},n.Subtract}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(o){\"use strict\";return o.Emitter=function(){this._events={}},o.extend(o.Emitter),o.Emitter.prototype.on=function(t,e){for(var i=t.split(/\\W+/),r=0;r<i.length;r++){var n=i[r];this._events.hasOwnProperty(n)||(this._events[n]=[]),this._events[n].push(e)}return this},o.Emitter.prototype.off=function(t,e){for(var i=t.split(/\\W+/),r=0;r<i.length;r++)if(t=i[r],this._events.hasOwnProperty(t))if(o.prototype.isUndef(e))this._events[t]=[];else for(var n=this._events[t],s=0;s<n.length;s++)n[s]===e&&n.splice(s,1);return this},o.Emitter.prototype.emit=function(t){if(this._events){var e=Array.apply(null,arguments).slice(1);if(this._events.hasOwnProperty(t))for(var i=this._events[t],r=0,n=i.length;r<n;r++)i[r].apply(this,e)}return this},o.Emitter.mixin=function(t){var e=[\"on\",\"off\",\"emit\"];t._events={};for(var i=0;i<e.length;i++){var r=e[i],n=o.Emitter.prototype[r];t[r]=n}},o.Emitter.prototype.dispose=function(){return o.prototype.dispose.call(this),this._events=null,this},o.Emitter}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(c){\"use strict\";return c.SignalBase=function(){},c.extend(c.SignalBase),c.SignalBase.prototype.connect=function(e,n,a){return c.Signal&&c.Signal===e.constructor||c.Param&&c.Param===e.constructor||c.TimelineSignal&&c.TimelineSignal===e.constructor?(e._param.cancelScheduledValues(0),e._param.value=0,e.overridden=!0):e instanceof AudioParam&&(e.cancelScheduledValues(0),e.value=0),c.prototype.connect.call(this,e,n,a),this},c.SignalBase}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(17)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(o){return o.Time=function(t,e){if(!(this instanceof o.Time))return new o.Time(t,e);this._plusNow=!1,o.TimeBase.call(this,t,e)},o.extend(o.Time,o.TimeBase),o.Time.prototype._unaryExpressions=Object.create(o.TimeBase.prototype._unaryExpressions),o.Time.prototype._unaryExpressions.quantize={regexp:/^@/,method:function(t){return o.Transport.nextSubdivision(t())}},o.Time.prototype._unaryExpressions.now={regexp:/^\\+/,method:function(t){return this._plusNow=!0,t()}},o.Time.prototype.quantize=function(t,e){return e=this.defaultArg(e,1),this._expr=function(t,e,o){return t=t(),e=e.toSeconds(),t+(Math.round(t/e)*e-t)*o}.bind(this,this._expr,new this.constructor(t),e),this},o.Time.prototype.addNow=function(){return this._plusNow=!0,this},o.Time.prototype._defaultExpr=function(){return this._plusNow=!0,this._noOp},o.Time.prototype.copy=function(t){return o.TimeBase.prototype.copy.call(this,t),this._plusNow=t._plusNow,this},o.Time.prototype.toNotation=function(){var t=this.toSeconds(),e=this._toNotationHelper(t,[\"1m\",\"2n\",\"4n\",\"8n\",\"16n\",\"32n\",\"64n\",\"128n\"]),o=this._toNotationHelper(t,[\"1m\",\"2n\",\"2t\",\"4n\",\"4t\",\"8n\",\"8t\",\"16n\",\"16t\",\"32n\",\"32t\",\"64n\",\"64t\",\"128n\"]);return o.split(\"+\").length<e.split(\"+\").length?o:e},o.Time.prototype._toNotationHelper=function(t,e){for(var o=this._notationToUnits(e[e.length-1]),n=\"\",i=0;i<e.length;i++){var r=this._notationToUnits(e[i]),s=t/r;if(1-s%1<1e-6&&(s+=1e-6),0<(s=Math.floor(s))){if(n+=1===s?e[i]:s.toString()+\"*\"+e[i],(t-=s*r)<o)break;n+=\" + \"}}return\"\"===n&&(n=\"0\"),n},o.Time.prototype._notationToUnits=function(t){for(var e=this._primaryExpressions,o=[e.n,e.t,e.m],n=0;n<o.length;n++){var i=o[n],r=t.match(i.regexp);if(r)return i.method.call(this,r[1])}},o.Time.prototype.toBarsBeatsSixteenths=function(){var t=this._beatsToUnits(1),e=this.toSeconds()/t,o=Math.floor(e/this._timeSignature()),n=e%1*4;return e=Math.floor(e)%this._timeSignature(),3<(n=n.toString()).length&&(n=parseFloat(n).toFixed(3)),[o,e,n].join(\":\")},o.Time.prototype.toTicks=function(){var t=this._beatsToUnits(1),e=this.valueOf()/t;return Math.floor(e*o.Transport.PPQ)},o.Time.prototype.toSamples=function(){return this.toSeconds()*this.context.sampleRate},o.Time.prototype.toFrequency=function(){return 1/this.toSeconds()},o.Time.prototype.toSeconds=function(){return this.valueOf()},o.Time.prototype.toMilliseconds=function(){return 1e3*this.toSeconds()},o.Time.prototype.valueOf=function(){return this._expr()+(this._plusNow?this.now():0)},o.Time}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(n){return n.TimeBase=function(e,t){if(!(this instanceof n.TimeBase))return new n.TimeBase(e,t);if(this._expr=this._noOp,e instanceof n.TimeBase)this.copy(e);else if(!this.isUndef(t)||this.isNumber(e)){t=this.defaultArg(t,this._defaultUnits);var r=this._primaryExpressions[t].method;this._expr=r.bind(this,e)}else this.isString(e)?this.set(e):this.isUndef(e)&&(this._expr=this._defaultExpr())},n.extend(n.TimeBase),n.TimeBase.prototype.set=function(e){return this._expr=this._parseExprString(e),this},n.TimeBase.prototype.clone=function(){var e=new this.constructor;return e.copy(this),e},n.TimeBase.prototype.copy=function(e){var t=e._expr();return this.set(t)},n.TimeBase.prototype._primaryExpressions={n:{regexp:/^(\\d+)n/i,method:function(e){return 1===(e=parseInt(e))?this._beatsToUnits(this._timeSignature()):this._beatsToUnits(4/e)}},t:{regexp:/^(\\d+)t/i,method:function(e){return e=parseInt(e),this._beatsToUnits(8/(3*parseInt(e)))}},m:{regexp:/^(\\d+)m/i,method:function(e){return this._beatsToUnits(parseInt(e)*this._timeSignature())}},i:{regexp:/^(\\d+)i/i,method:function(e){return this._ticksToUnits(parseInt(e))}},hz:{regexp:/^(\\d+(?:\\.\\d+)?)hz/i,method:function(e){return this._frequencyToUnits(parseFloat(e))}},tr:{regexp:/^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?/,method:function(e,t,r){var n=0;return e&&\"0\"!==e&&(n+=this._beatsToUnits(this._timeSignature()*parseFloat(e))),t&&\"0\"!==t&&(n+=this._beatsToUnits(parseFloat(t))),r&&\"0\"!==r&&(n+=this._beatsToUnits(parseFloat(r)/4)),n}},s:{regexp:/^(\\d+(?:\\.\\d+)?s)/,method:function(e){return this._secondsToUnits(parseFloat(e))}},samples:{regexp:/^(\\d+)samples/,method:function(e){return parseInt(e)/this.context.sampleRate}},default:{regexp:/^(\\d+(?:\\.\\d+)?)/,method:function(e){return this._primaryExpressions[this._defaultUnits].method.call(this,e)}}},n.TimeBase.prototype._binaryExpressions={\"+\":{regexp:/^\\+/,precedence:2,method:function(e,t){return e()+t()}},\"-\":{regexp:/^\\-/,precedence:2,method:function(e,t){return e()-t()}},\"*\":{regexp:/^\\*/,precedence:1,method:function(e,t){return e()*t()}},\"/\":{regexp:/^\\//,precedence:1,method:function(e,t){return e()/t()}}},n.TimeBase.prototype._unaryExpressions={neg:{regexp:/^\\-/,method:function(e){return-e()}}},n.TimeBase.prototype._syntaxGlue={\"(\":{regexp:/^\\(/},\")\":{regexp:/^\\)/}},n.TimeBase.prototype._tokenize=function(e){for(var t=-1,r=[];0<e.length;){var n=i(e=e.trim(),this);r.push(n),e=e.substr(n.value.length)}function i(e,t){for(var r=[\"_binaryExpressions\",\"_unaryExpressions\",\"_primaryExpressions\",\"_syntaxGlue\"],n=0;n<r.length;n++){var i=t[r[n]];for(var s in i){var o=i[s],p=o.regexp,a=e.match(p);if(null!==a)return{method:o.method,precedence:o.precedence,regexp:o.regexp,value:a[0]}}}throw new SyntaxError(\"Tone.TimeBase: Unexpected token \"+e)}return{next:function(){return r[++t]},peek:function(){return r[t+1]}}},n.TimeBase.prototype._matchGroup=function(e,t,r){if(!this.isUndef(e))for(var n in t){var i=t[n];if(i.regexp.test(e.value)){if(this.isUndef(r))return i;if(i.precedence===r)return i}}return!1},n.TimeBase.prototype._parseBinary=function(e,t){var r;this.isUndef(t)&&(t=2),r=t<0?this._parseUnary(e):this._parseBinary(e,t-1);for(var n=e.peek();n&&this._matchGroup(n,this._binaryExpressions,t);)r=(n=e.next()).method.bind(this,r,this._parseBinary(e,t-1)),n=e.peek();return r},n.TimeBase.prototype._parseUnary=function(e){var t,r;t=e.peek();var n=this._matchGroup(t,this._unaryExpressions);return n?(t=e.next(),r=this._parseUnary(e),n.method.bind(this,r)):this._parsePrimary(e)},n.TimeBase.prototype._parsePrimary=function(e){var t,r;if(t=e.peek(),this.isUndef(t))throw new SyntaxError(\"Tone.TimeBase: Unexpected end of expression\");if(this._matchGroup(t,this._primaryExpressions)){var n=(t=e.next()).value.match(t.regexp);return t.method.bind(this,n[1],n[2],n[3])}if(t&&\"(\"===t.value){if(e.next(),r=this._parseBinary(e),!(t=e.next())||\")\"!==t.value)throw new SyntaxError(\"Expected )\");return r}throw new SyntaxError(\"Tone.TimeBase: Cannot process token \"+t.value)},n.TimeBase.prototype._parseExprString=function(e){this.isString(e)||(e=e.toString());var t=this._tokenize(e);return this._parseBinary(t)},n.TimeBase.prototype._noOp=function(){return 0},n.TimeBase.prototype._defaultExpr=function(){return this._noOp},n.TimeBase.prototype._defaultUnits=\"s\",n.TimeBase.prototype._frequencyToUnits=function(e){return 1/e},n.TimeBase.prototype._beatsToUnits=function(e){return 60/n.Transport.bpm.value*e},n.TimeBase.prototype._secondsToUnits=function(e){return e},n.TimeBase.prototype._ticksToUnits=function(e){return e*(this._beatsToUnits(1)/n.Transport.PPQ)},n.TimeBase.prototype._timeSignature=function(){return n.Transport.timeSignature},n.TimeBase.prototype._pushExpr=function(e,t,r){return e instanceof n.TimeBase||(e=new this.constructor(e,r)),this._expr=this._binaryExpressions[t].method.bind(this,this._expr,e._expr),this},n.TimeBase.prototype.add=function(e,t){return this._pushExpr(e,\"+\",t)},n.TimeBase.prototype.sub=function(e,t){return this._pushExpr(e,\"-\",t)},n.TimeBase.prototype.mult=function(e,t){return this._pushExpr(e,\"*\",t)},n.TimeBase.prototype.div=function(e,t){return this._pushExpr(e,\"/\",t)},n.TimeBase.prototype.valueOf=function(){return this._expr()},n.TimeBase.prototype.dispose=function(){this._expr=null},n.TimeBase}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(9)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(a){\"use strict\";return a.Param=function(){var t=this.optionsObject(arguments,[\"param\",\"units\",\"convert\"],a.Param.defaults);this._param=this.input=t.param,this.units=t.units,this.convert=t.convert,this.overridden=!1,this._lfo=null,this.isObject(t.lfo)?this.value=t.lfo:this.isUndef(t.value)||(this.value=t.value)},a.extend(a.Param),a.Param.defaults={units:a.Type.Default,convert:!0,param:void 0},Object.defineProperty(a.Param.prototype,\"value\",{get:function(){return this._toUnits(this._param.value)},set:function(t){if(this.isObject(t)){if(this.isUndef(a.LFO))throw new Error(\"Include 'Tone.LFO' to use an LFO as a Param value.\");this._lfo&&this._lfo.dispose(),this._lfo=new a.LFO(t).start(),this._lfo.connect(this.input)}else{var e=this._fromUnits(t);this._param.cancelScheduledValues(0),this._param.value=e}}}),a.Param.prototype._fromUnits=function(t){if(!this.convert&&!this.isUndef(this.convert))return t;switch(this.units){case a.Type.Time:return this.toSeconds(t);case a.Type.Frequency:return this.toFrequency(t);case a.Type.Decibels:return this.dbToGain(t);case a.Type.NormalRange:return Math.min(Math.max(t,0),1);case a.Type.AudioRange:return Math.min(Math.max(t,-1),1);case a.Type.Positive:return Math.max(t,0);default:return t}},a.Param.prototype._toUnits=function(t){if(!this.convert&&!this.isUndef(this.convert))return t;switch(this.units){case a.Type.Decibels:return this.gainToDb(t);default:return t}},a.Param.prototype._minOutput=1e-5,a.Param.prototype.setValueAtTime=function(t,e){return t=this._fromUnits(t),(e=this.toSeconds(e))<=this.now()+this.blockTime?this._param.value=t:this._param.setValueAtTime(t,e),this},a.Param.prototype.setRampPoint=function(t){t=this.defaultArg(t,this.now());var e=this._param.value;return 0===e&&(e=this._minOutput),this._param.setValueAtTime(e,t),this},a.Param.prototype.linearRampToValueAtTime=function(t,e){return t=this._fromUnits(t),this._param.linearRampToValueAtTime(t,this.toSeconds(e)),this},a.Param.prototype.exponentialRampToValueAtTime=function(t,e){return t=this._fromUnits(t),t=Math.max(this._minOutput,t),this._param.exponentialRampToValueAtTime(t,this.toSeconds(e)),this},a.Param.prototype.exponentialRampToValue=function(t,e,i){return i=this.toSeconds(i),this.setRampPoint(i),this.exponentialRampToValueAtTime(t,i+this.toSeconds(e)),this},a.Param.prototype.linearRampToValue=function(t,e,i){return i=this.toSeconds(i),this.setRampPoint(i),this.linearRampToValueAtTime(t,i+this.toSeconds(e)),this},a.Param.prototype.setTargetAtTime=function(t,e,i){return t=this._fromUnits(t),t=Math.max(this._minOutput,t),i=Math.max(this._minOutput,i),this._param.setTargetAtTime(t,this.toSeconds(e),i),this},a.Param.prototype.setValueCurveAtTime=function(t,e,i){for(var a=0;a<t.length;a++)t[a]=this._fromUnits(t[a]);return this._param.setValueCurveAtTime(t,this.toSeconds(e),this.toSeconds(i)),this},a.Param.prototype.cancelScheduledValues=function(t){return this._param.cancelScheduledValues(this.toSeconds(t)),this},a.Param.prototype.rampTo=function(t,e,i){return e=this.defaultArg(e,0),this.units===a.Type.Frequency||this.units===a.Type.BPM||this.units===a.Type.Decibels?this.exponentialRampToValue(t,e,i):this.linearRampToValue(t,e,i),this},Object.defineProperty(a.Param.prototype,\"lfo\",{get:function(){return this._lfo}}),a.Param.prototype.dispose=function(){return a.prototype.dispose.call(this),this._param=null,this._lfo&&(this._lfo.dispose(),this._lfo=null),this},a.Param}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(9)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(i){\"use strict\";return i.Timeline=function(){var e=this.optionsObject(arguments,[\"memory\"],i.Timeline.defaults);this._timeline=[],this._toRemove=[],this._iterating=!1,this.memory=e.memory},i.extend(i.Timeline),i.Timeline.defaults={memory:1/0},Object.defineProperty(i.Timeline.prototype,\"length\",{get:function(){return this._timeline.length}}),i.Timeline.prototype.add=function(e){if(this.isUndef(e.time))throw new Error(\"Tone.Timeline: events must have a time attribute\");if(this._timeline.length){var i=this._search(e.time);this._timeline.splice(i+1,0,e)}else this._timeline.push(e);if(this.length>this.memory){var t=this.length-this.memory;this._timeline.splice(0,t)}return this},i.Timeline.prototype.remove=function(e){if(this._iterating)this._toRemove.push(e);else{var i=this._timeline.indexOf(e);-1!==i&&this._timeline.splice(i,1)}return this},i.Timeline.prototype.get=function(e){var i=this._search(e);return-1!==i?this._timeline[i]:null},i.Timeline.prototype.peek=function(){return this._timeline[0]},i.Timeline.prototype.shift=function(){return this._timeline.shift()},i.Timeline.prototype.getAfter=function(e){var i=this._search(e);return i+1<this._timeline.length?this._timeline[i+1]:null},i.Timeline.prototype.getBefore=function(e){var i=this._timeline.length;if(0<i&&this._timeline[i-1].time<e)return this._timeline[i-1];var t=this._search(e);return 0<=t-1?this._timeline[t-1]:null},i.Timeline.prototype.cancel=function(e){if(1<this._timeline.length){var i=this._search(e);if(0<=i)if(this._timeline[i].time===e){for(var t=i;0<=t&&this._timeline[t].time===e;t--)i=t;this._timeline=this._timeline.slice(0,i)}else this._timeline=this._timeline.slice(0,i+1);else this._timeline=[]}else 1===this._timeline.length&&this._timeline[0].time>=e&&(this._timeline=[]);return this},i.Timeline.prototype.cancelBefore=function(e){if(this._timeline.length){var i=this._search(e);0<=i&&(this._timeline=this._timeline.slice(i+1))}return this},i.Timeline.prototype._search=function(e){var i=0,t=this._timeline.length,n=t;if(0<t&&this._timeline[t-1].time<=e)return t-1;for(;i<n;){var r=Math.floor(i+(n-i)/2),s=this._timeline[r],h=this._timeline[r+1];if(s.time===e){for(var l=r;l<this._timeline.length;l++){this._timeline[l].time===e&&(r=l)}return r}if(s.time<e&&h.time>e)return r;s.time>e?n=r:s.time<e&&(i=r+1)}return-1},i.Timeline.prototype._iterate=function(e,i,t){this._iterating=!0,i=this.defaultArg(i,0),t=this.defaultArg(t,this._timeline.length-1);for(var n=i;n<=t;n++)e(this._timeline[n]);if(this._iterating=!1,0<this._toRemove.length){for(var r=0;r<this._toRemove.length;r++){var s=this._timeline.indexOf(this._toRemove[r]);-1!==s&&this._timeline.splice(s,1)}this._toRemove=[]}},i.Timeline.prototype.forEach=function(e){return this._iterate(e),this},i.Timeline.prototype.forEachBefore=function(e,i){var t=this._search(e);return-1!==t&&this._iterate(i,0,t),this},i.Timeline.prototype.forEachAfter=function(e,i){var t=this._search(e);return this._iterate(i,t+1),this},i.Timeline.prototype.forEachFrom=function(e,i){for(var t=this._search(e);0<=t&&this._timeline[t].time>=e;)t--;return this._iterate(i,t+1),this},i.Timeline.prototype.forEachAtTime=function(i,t){var e=this._search(i);return-1!==e&&this._iterate(function(e){e.time===i&&t(e)},0,e),this},i.Timeline.prototype.dispose=function(){i.prototype.dispose.call(this),this._timeline=null,this._toRemove=null},i.Timeline}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(1),__webpack_require__(2)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(t){\"use strict\";return t.Negate=function(){this._multiply=this.input=this.output=new t.Multiply(-1)},t.extend(t.Negate,t.SignalBase),t.Negate.prototype.dispose=function(){return t.prototype.dispose.call(this),this._multiply.dispose(),this._multiply=null,this},t.Negate}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(2),__webpack_require__(1),__webpack_require__(6)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(e){\"use strict\";return e.GreaterThanZero=function(){this._thresh=this.output=new e.WaveShaper(function(e){return e<=0?0:1},127),this._scale=this.input=new e.Multiply(1e4),this._scale.connect(this._thresh)},e.extend(e.GreaterThanZero,e.SignalBase),e.GreaterThanZero.prototype.dispose=function(){return e.prototype.dispose.call(this),this._scale.dispose(),this._scale=null,this._thresh.dispose(),this._thresh=null,this},e.GreaterThanZero}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!function(e,t){ true?!(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (t),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?\n\t\t\t\t(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__)):undefined}(this,function(){var r=function(e,t){this._dragged=!1,this._element=e,this._bindedMove=this._moved.bind(this),this._bindedEnd=this._ended.bind(this,t),e.addEventListener(\"touchstart\",this._bindedEnd),e.addEventListener(\"touchmove\",this._bindedMove),e.addEventListener(\"touchend\",this._bindedEnd),e.addEventListener(\"mouseup\",this._bindedEnd)};function o(e){return\"running\"===e.state}return r.prototype._moved=function(e){this._dragged=!0},r.prototype._ended=function(e){this._dragged||function(e){var t=e.createBuffer(1,1,e.sampleRate),n=e.createBufferSource();n.buffer=t,n.connect(e.destination),n.start(0),e.resume&&e.resume()}(e),this._dragged=!1},r.prototype.dispose=function(){this._element.removeEventListener(\"touchstart\",this._bindedEnd),this._element.removeEventListener(\"touchmove\",this._bindedMove),this._element.removeEventListener(\"touchend\",this._bindedEnd),this._element.removeEventListener(\"mouseup\",this._bindedEnd),this._bindedMove=null,this._bindedEnd=null,this._element=null},function(t,e,n){var i=new Promise(function(e){!function(t,n){o(t)?n():function e(){o(t)?n():(requestAnimationFrame(e),t.resume&&t.resume())}()}(t,e)}),d=[];return function e(t,n,i){if(Array.isArray(t)||NodeList&&t instanceof NodeList)for(var d=0;d<t.length;d++)e(t[d],n,i);else if(\"string\"==typeof t)e(document.querySelectorAll(t),n,i);else if(t.jquery&&\"function\"==typeof t.toArray)e(t.toArray(),n,i);else if(Element&&t instanceof Element){var o=new r(t,i);n.push(o)}}(e=e||document.body,d,t),i.then(function(){for(var e=0;e<d.length;e++)d[e].dispose();d=null,n&&n()}),i}});\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(2),__webpack_require__(32),__webpack_require__(38),__webpack_require__(10)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(i){\"use strict\";return i.CrossFade=function(e){this.createInsOuts(2,1),this.a=this.input[0]=new i.Gain,this.b=this.input[1]=new i.Gain,this.fade=new i.Signal(this.defaultArg(e,.5),i.Type.NormalRange),this._equalPowerA=new i.EqualPowerGain,this._equalPowerB=new i.EqualPowerGain,this._invert=new i.Expr(\"1 - $0\"),this.a.connect(this.output),this.b.connect(this.output),this.fade.chain(this._equalPowerB,this.b.gain),this.fade.chain(this._invert,this._equalPowerA,this.a.gain),this._readOnly(\"fade\")},i.extend(i.CrossFade),i.CrossFade.prototype.dispose=function(){return i.prototype.dispose.call(this),this._writable(\"fade\"),this._equalPowerA.dispose(),this._equalPowerA=null,this._equalPowerB.dispose(),this._equalPowerB=null,this.fade.dispose(),this.fade=null,this._invert.dispose(),this._invert=null,this.a.dispose(),this.a=null,this.b.dispose(),this.b=null,this},i.CrossFade}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports) {\n\n!function(){var l,s=[];function p(e){var o=this,n={},i=-1;this.parameters.forEach(function(e,t){var r=s[++i]||(s[i]=new Float32Array(o.bufferSize));r.fill(e.value),n[t]=r}),this.processor.realm.exec(\"self.sampleRate=sampleRate=\"+this.context.sampleRate+\";self.currentTime=currentTime=\"+this.context.currentTime);var t=a(e.inputBuffer),r=a(e.outputBuffer);this.instance.process([t],[r],n)}function a(e){for(var t=[],r=0;r<e.numberOfChannels;r++)t[r]=e.getChannelData(r);return t}function f(e){return e.$$processors||(e.$$processors={})}function e(e){this.$$context=e}\"function\"!=typeof AudioWorkletNode&&(self.AudioWorkletNode=function(e,t,r){var o=f(e)[t],n=e.createScriptProcessor(void 0,2,r&&r.outputChannelCount?r.outputChannelCount[0]:2);if(n.parameters=new Map,o.properties)for(var i=0;i<o.properties.length;i++){var s=o.properties[i],a=e.createGain().gain;a.value=s.defaultValue,n.parameters.set(s.name,a)}var u=new MessageChannel;l=u.port2;var c=new o.Processor(r||{});return l=null,n.port=u.port1,n.processor=o,n.instance=c,n.onaudioprocess=p,n},Object.defineProperty((self.AudioContext||self.webkitAudioContext).prototype,\"audioWorklet\",{get:function(){return this.$$audioWorklet||(this.$$audioWorklet=new self.AudioWorklet(this))}}),self.AudioWorklet=(e.prototype.addModule=function(e,t){var n=this;return fetch(e).then(function(e){if(!e.ok)throw Error(e.status);return e.text()}).then(function(e){var r={sampleRate:0,currentTime:0,AudioWorkletProcessor:function(){this.port=l},registerProcessor:function(e,t){f(n.$$context)[e]={realm:o,context:r,Processor:t,properties:t.parameterDescriptors||[]}}},o=new function(e,t){var r=document.createElement(\"iframe\");r.style.cssText=\"position:absolute;left:0;top:-999px;width:1px;height:1px;\",t.appendChild(r);var o=r.contentWindow,n=o.document,i=\"var window,$hook\";for(var s in o)s in e||\"eval\"===s||(i+=\",\",i+=s);for(var a in e)i+=\",\",i+=a,i+=\"=self.\",i+=a;var u=n.createElement(\"script\");u.appendChild(n.createTextNode('function $hook(self,console) {\"use strict\";\\n        '+i+\";return function() {return eval(arguments[0])}}\")),n.body.appendChild(u),this.exec=o.$hook(e,console)}(r.self=r,document.documentElement);return o.exec((t&&t.transpile||String)(e)),null})},e))}();\n\n }),\n (function(module, exports) {\n\n/**\n * This module has shims\n */\n\n(function () {\n  function fixSetTarget(param) {\n    if (!param) \n      return;\n    if (!param.setTargetAtTime) param.setTargetAtTime = param.setTargetValueAtTime;\n  }\n\n  if (window.hasOwnProperty('webkitAudioContext') && !window.hasOwnProperty('AudioContext')) {\n    window.AudioContext = window.webkitAudioContext;\n    if (typeof AudioContext.prototype.createGain !== 'function') AudioContext.prototype.createGain = AudioContext.prototype.createGainNode;\n    if (typeof AudioContext.prototype.createDelay !== 'function') AudioContext.prototype.createDelay = AudioContext.prototype.createDelayNode;\n    if (typeof AudioContext.prototype.createScriptProcessor !== 'function') AudioContext.prototype.createScriptProcessor = AudioContext.prototype.createJavaScriptNode;\n    if (typeof AudioContext.prototype.createPeriodicWave !== 'function') AudioContext.prototype.createPeriodicWave = AudioContext.prototype.createWaveTable;\n    AudioContext.prototype.internal_createGain = AudioContext.prototype.createGain;\n\n    AudioContext.prototype.createGain = function () {\n      var node = this.internal_createGain();\n      fixSetTarget(node.gain);\n      return node;\n    };\n\n    AudioContext.prototype.internal_createDelay = AudioContext.prototype.createDelay;\n\n    AudioContext.prototype.createDelay = function (maxDelayTime) {\n      var node = maxDelayTime ? this.internal_createDelay(maxDelayTime) : this.internal_createDelay();\n      fixSetTarget(node.delayTime);\n      return node;\n    };\n\n    AudioContext.prototype.internal_createBufferSource = AudioContext.prototype.createBufferSource;\n\n    AudioContext.prototype.createBufferSource = function () {\n      var node = this.internal_createBufferSource();\n\n      if (!node.start) {\n        node.start = function (when, offset, duration) {\n          if (offset || duration) this.noteGrainOn(when || 0, offset, duration);else this.noteOn(when || 0);\n        };\n      } else {\n        node.internal_start = node.start;\n\n        node.start = function (when, offset, duration) {\n          if (typeof duration !== 'undefined') node.internal_start(when || 0, offset, duration);else node.internal_start(when || 0, offset || 0);\n        };\n      }\n\n      if (!node.stop) {\n        node.stop = function (when) {\n          this.noteOff(when || 0);\n        };\n      } else {\n        node.internal_stop = node.stop;\n\n        node.stop = function (when) {\n          node.internal_stop(when || 0);\n        };\n      }\n\n      fixSetTarget(node.playbackRate);\n      return node;\n    };\n\n    AudioContext.prototype.internal_createDynamicsCompressor = AudioContext.prototype.createDynamicsCompressor;\n\n    AudioContext.prototype.createDynamicsCompressor = function () {\n      var node = this.internal_createDynamicsCompressor();\n      fixSetTarget(node.threshold);\n      fixSetTarget(node.knee);\n      fixSetTarget(node.ratio);\n      fixSetTarget(node.reduction);\n      fixSetTarget(node.attack);\n      fixSetTarget(node.release);\n      return node;\n    };\n\n    AudioContext.prototype.internal_createBiquadFilter = AudioContext.prototype.createBiquadFilter;\n\n    AudioContext.prototype.createBiquadFilter = function () {\n      var node = this.internal_createBiquadFilter();\n      fixSetTarget(node.frequency);\n      fixSetTarget(node.detune);\n      fixSetTarget(node.Q);\n      fixSetTarget(node.gain);\n      return node;\n    };\n\n    if (typeof AudioContext.prototype.createOscillator !== 'function') {\n      AudioContext.prototype.internal_createOscillator = AudioContext.prototype.createOscillator;\n\n      AudioContext.prototype.createOscillator = function () {\n        var node = this.internal_createOscillator();\n\n        if (!node.start) {\n          node.start = function (when) {\n            this.noteOn(when || 0);\n          };\n        } else {\n          node.internal_start = node.start;\n\n          node.start = function (when) {\n            node.internal_start(when || 0);\n          };\n        }\n\n        if (!node.stop) {\n          node.stop = function (when) {\n            this.noteOff(when || 0);\n          };\n        } else {\n          node.internal_stop = node.stop;\n\n          node.stop = function (when) {\n            node.internal_stop(when || 0);\n          };\n        }\n\n        if (!node.setPeriodicWave) node.setPeriodicWave = node.setWaveTable;\n        fixSetTarget(node.frequency);\n        fixSetTarget(node.detune);\n        return node;\n      };\n    }\n  }\n\n  if (window.hasOwnProperty('webkitOfflineAudioContext') && !window.hasOwnProperty('OfflineAudioContext')) {\n    window.OfflineAudioContext = window.webkitOfflineAudioContext;\n  }\n})(window); \n\n\nnavigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;\n/**\n * Determine which filetypes are supported (inspired by buzz.js)\n * The audio element (el) will only be used to test browser support for various audio formats\n */\n\nvar el = document.createElement('audio');\n\np5.prototype.isSupported = function () {\n  return !!el.canPlayType;\n};\n\nvar isOGGSupported = function isOGGSupported() {\n  return !!el.canPlayType && el.canPlayType('audio/ogg; codecs=\"vorbis\"');\n};\n\nvar isMP3Supported = function isMP3Supported() {\n  return !!el.canPlayType && el.canPlayType('audio/mpeg;');\n};\n\nvar isWAVSupported = function isWAVSupported() {\n  return !!el.canPlayType && el.canPlayType('audio/wav; codecs=\"1\"');\n};\n\nvar isAACSupported = function isAACSupported() {\n  return !!el.canPlayType && (el.canPlayType('audio/x-m4a;') || el.canPlayType('audio/aac;'));\n};\n\nvar isAIFSupported = function isAIFSupported() {\n  return !!el.canPlayType && el.canPlayType('audio/x-aiff;');\n};\n\np5.prototype.isFileSupported = function (extension) {\n  switch (extension.toLowerCase()) {\n    case 'mp3':\n      return isMP3Supported();\n\n    case 'wav':\n      return isWAVSupported();\n\n    case 'ogg':\n      return isOGGSupported();\n\n    case 'aac':\n    case 'm4a':\n    case 'mp4':\n      return isAACSupported();\n\n    case 'aif':\n    case 'aiff':\n      return isAIFSupported();\n\n    default:\n      return false;\n  }\n};\n\n }),\n (function(module, exports) {\n\nvar g;g=function(){return this}();try{g=g||new Function(\"return this\")()}catch(t){\"object\"==typeof window&&(g=window)}module.exports=g;\n\n }),\n (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n __webpack_exports__[\"default\"] = (\"function _typeof(obj) { if (typeof Symbol === \\\"function\\\" && typeof Symbol.iterator === \\\"symbol\\\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \\\"function\\\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \\\"symbol\\\" : typeof obj; }; } return _typeof(obj); }\\n\\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \\\"object\\\" || typeof call === \\\"function\\\")) { return call; } return _assertThisInitialized(self); }\\n\\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\\\"this hasn't been initialised - super() hasn't been called\\\"); } return self; }\\n\\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \\\"function\\\" && superClass !== null) { throw new TypeError(\\\"Super expression must either be null or a function\\\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\\n\\nfunction _wrapNativeSuper(Class) { var _cache = typeof Map === \\\"function\\\" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== \\\"function\\\") { throw new TypeError(\\\"Super expression must either be null or a function\\\"); } if (typeof _cache !== \\\"undefined\\\") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }\\n\\nfunction isNativeReflectConstruct() { if (typeof Reflect === \\\"undefined\\\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \\\"function\\\") return true; try { Date.prototype.toString.call(Reflect.construct(Date, [], function () {})); return true; } catch (e) { return false; } }\\n\\nfunction _construct(Parent, args, Class) { if (isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }\\n\\nfunction _isNativeFunction(fn) { return Function.toString.call(fn).indexOf(\\\"[native code]\\\") !== -1; }\\n\\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\\n\\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\\n\\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\\\"Cannot call a class as a function\\\"); } }\\n\\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\\\"value\\\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\\n\\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\\n\\n// import dependencies via preval.require so that they're available as values at compile time\\nvar processorNames = {\\n  \\\"recorderProcessor\\\": \\\"recorder-processor\\\",\\n  \\\"soundFileProcessor\\\": \\\"sound-file-processor\\\",\\n  \\\"amplitudeProcessor\\\": \\\"amplitude-processor\\\"\\n};\\nvar RingBuffer = {\\n  \\\"default\\\":\\n  /*#__PURE__*/\\n  function () {\\n    /**\\n     * @constructor\\n     * @param  {number} length Buffer length in frames.\\n     * @param  {number} channelCount Buffer channel count.\\n     */\\n    function RingBuffer(length, channelCount) {\\n      _classCallCheck(this, RingBuffer);\\n\\n      this._readIndex = 0;\\n      this._writeIndex = 0;\\n      this._framesAvailable = 0;\\n      this._channelCount = channelCount;\\n      this._length = length;\\n      this._channelData = [];\\n\\n      for (var i = 0; i < this._channelCount; ++i) {\\n        this._channelData[i] = new Float32Array(length);\\n      }\\n    }\\n    /**\\n     * Getter for Available frames in buffer.\\n     *\\n     * @return {number} Available frames in buffer.\\n     */\\n\\n\\n    _createClass(RingBuffer, [{\\n      key: \\\"push\\\",\\n\\n      /**\\n       * Push a sequence of Float32Arrays to buffer.\\n       *\\n       * @param  {array} arraySequence A sequence of Float32Arrays.\\n       */\\n      value: function push(arraySequence) {\\n        // The channel count of arraySequence and the length of each channel must\\n        // match with this buffer obejct.\\n        // Transfer data from the |arraySequence| storage to the internal buffer.\\n        var sourceLength = arraySequence[0] ? arraySequence[0].length : 0;\\n\\n        for (var i = 0; i < sourceLength; ++i) {\\n          var writeIndex = (this._writeIndex + i) % this._length;\\n\\n          for (var channel = 0; channel < this._channelCount; ++channel) {\\n            this._channelData[channel][writeIndex] = arraySequence[channel][i];\\n          }\\n        }\\n\\n        this._writeIndex += sourceLength;\\n\\n        if (this._writeIndex >= this._length) {\\n          this._writeIndex = 0;\\n        } // For excessive frames, the buffer will be overwritten.\\n\\n\\n        this._framesAvailable += sourceLength;\\n\\n        if (this._framesAvailable > this._length) {\\n          this._framesAvailable = this._length;\\n        }\\n      }\\n      /**\\n       * Pull data out of buffer and fill a given sequence of Float32Arrays.\\n       *\\n       * @param  {array} arraySequence An array of Float32Arrays.\\n       */\\n\\n    }, {\\n      key: \\\"pull\\\",\\n      value: function pull(arraySequence) {\\n        // The channel count of arraySequence and the length of each channel must\\n        // match with this buffer obejct.\\n        // If the FIFO is completely empty, do nothing.\\n        if (this._framesAvailable === 0) {\\n          return;\\n        }\\n\\n        var destinationLength = arraySequence[0].length; // Transfer data from the internal buffer to the |arraySequence| storage.\\n\\n        for (var i = 0; i < destinationLength; ++i) {\\n          var readIndex = (this._readIndex + i) % this._length;\\n\\n          for (var channel = 0; channel < this._channelCount; ++channel) {\\n            arraySequence[channel][i] = this._channelData[channel][readIndex];\\n          }\\n        }\\n\\n        this._readIndex += destinationLength;\\n\\n        if (this._readIndex >= this._length) {\\n          this._readIndex = 0;\\n        }\\n\\n        this._framesAvailable -= destinationLength;\\n\\n        if (this._framesAvailable < 0) {\\n          this._framesAvailable = 0;\\n        }\\n      }\\n    }, {\\n      key: \\\"framesAvailable\\\",\\n      get: function get() {\\n        return this._framesAvailable;\\n      }\\n    }]);\\n\\n    return RingBuffer;\\n  }()\\n}[\\\"default\\\"];\\n\\nvar RecorderProcessor =\\n/*#__PURE__*/\\nfunction (_AudioWorkletProcesso) {\\n  _inherits(RecorderProcessor, _AudioWorkletProcesso);\\n\\n  function RecorderProcessor(options) {\\n    var _this;\\n\\n    _classCallCheck(this, RecorderProcessor);\\n\\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(RecorderProcessor).call(this));\\n    var processorOptions = options.processorOptions || {};\\n    _this.numOutputChannels = options.outputChannelCount || 2;\\n    _this.numInputChannels = processorOptions.numInputChannels || 2;\\n    _this.bufferSize = processorOptions.bufferSize || 1024;\\n    _this.recording = false;\\n\\n    _this.clear();\\n\\n    _this.port.onmessage = function (event) {\\n      var data = event.data;\\n\\n      if (data.name === 'start') {\\n        _this.record(data.duration);\\n      } else if (data.name === 'stop') {\\n        _this.stop();\\n      }\\n    };\\n\\n    return _this;\\n  }\\n\\n  _createClass(RecorderProcessor, [{\\n    key: \\\"process\\\",\\n    value: function process(inputs) {\\n      if (!this.recording) {\\n        return true;\\n      } else if (this.sampleLimit && this.recordedSamples >= this.sampleLimit) {\\n        this.stop();\\n        return true;\\n      }\\n\\n      var input = inputs[0];\\n      this.inputRingBuffer.push(input);\\n\\n      if (this.inputRingBuffer.framesAvailable >= this.bufferSize) {\\n        this.inputRingBuffer.pull(this.inputRingBufferArraySequence);\\n\\n        for (var channel = 0; channel < this.numOutputChannels; ++channel) {\\n          var inputChannelCopy = this.inputRingBufferArraySequence[channel].slice();\\n\\n          if (channel === 0) {\\n            this.leftBuffers.push(inputChannelCopy);\\n\\n            if (this.numInputChannels === 1) {\\n              this.rightBuffers.push(inputChannelCopy);\\n            }\\n          } else if (channel === 1 && this.numInputChannels > 1) {\\n            this.rightBuffers.push(inputChannelCopy);\\n          }\\n        }\\n\\n        this.recordedSamples += this.bufferSize;\\n      }\\n\\n      return true;\\n    }\\n  }, {\\n    key: \\\"record\\\",\\n    value: function record(duration) {\\n      if (duration) {\\n        this.sampleLimit = Math.round(duration * sampleRate);\\n      }\\n\\n      this.recording = true;\\n    }\\n  }, {\\n    key: \\\"stop\\\",\\n    value: function stop() {\\n      this.recording = false;\\n      var buffers = this.getBuffers();\\n      var leftBuffer = buffers[0].buffer;\\n      var rightBuffer = buffers[1].buffer;\\n      this.port.postMessage({\\n        name: 'buffers',\\n        leftBuffer: leftBuffer,\\n        rightBuffer: rightBuffer\\n      }, [leftBuffer, rightBuffer]);\\n      this.clear();\\n    }\\n  }, {\\n    key: \\\"getBuffers\\\",\\n    value: function getBuffers() {\\n      var buffers = [];\\n      buffers.push(this.mergeBuffers(this.leftBuffers));\\n      buffers.push(this.mergeBuffers(this.rightBuffers));\\n      return buffers;\\n    }\\n  }, {\\n    key: \\\"mergeBuffers\\\",\\n    value: function mergeBuffers(channelBuffer) {\\n      var result = new Float32Array(this.recordedSamples);\\n      var offset = 0;\\n      var lng = channelBuffer.length;\\n\\n      for (var i = 0; i < lng; i++) {\\n        var buffer = channelBuffer[i];\\n        result.set(buffer, offset);\\n        offset += buffer.length;\\n      }\\n\\n      return result;\\n    }\\n  }, {\\n    key: \\\"clear\\\",\\n    value: function clear() {\\n      var _this2 = this;\\n\\n      this.leftBuffers = [];\\n      this.rightBuffers = [];\\n      this.inputRingBuffer = new RingBuffer(this.bufferSize, this.numInputChannels);\\n      this.inputRingBufferArraySequence = new Array(this.numInputChannels).fill(null).map(function () {\\n        return new Float32Array(_this2.bufferSize);\\n      });\\n      this.recordedSamples = 0;\\n      this.sampleLimit = null;\\n    }\\n  }]);\\n\\n  return RecorderProcessor;\\n}(_wrapNativeSuper(AudioWorkletProcessor));\\n\\nregisterProcessor(processorNames.recorderProcessor, RecorderProcessor);\");\n\n }),\n (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n __webpack_exports__[\"default\"] = (\"function _typeof(obj) { if (typeof Symbol === \\\"function\\\" && typeof Symbol.iterator === \\\"symbol\\\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \\\"function\\\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \\\"symbol\\\" : typeof obj; }; } return _typeof(obj); }\\n\\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \\\"object\\\" || typeof call === \\\"function\\\")) { return call; } return _assertThisInitialized(self); }\\n\\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\\\"this hasn't been initialised - super() hasn't been called\\\"); } return self; }\\n\\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \\\"function\\\" && superClass !== null) { throw new TypeError(\\\"Super expression must either be null or a function\\\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\\n\\nfunction _wrapNativeSuper(Class) { var _cache = typeof Map === \\\"function\\\" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== \\\"function\\\") { throw new TypeError(\\\"Super expression must either be null or a function\\\"); } if (typeof _cache !== \\\"undefined\\\") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }\\n\\nfunction isNativeReflectConstruct() { if (typeof Reflect === \\\"undefined\\\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \\\"function\\\") return true; try { Date.prototype.toString.call(Reflect.construct(Date, [], function () {})); return true; } catch (e) { return false; } }\\n\\nfunction _construct(Parent, args, Class) { if (isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }\\n\\nfunction _isNativeFunction(fn) { return Function.toString.call(fn).indexOf(\\\"[native code]\\\") !== -1; }\\n\\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\\n\\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\\n\\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\\\"Cannot call a class as a function\\\"); } }\\n\\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\\\"value\\\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\\n\\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\\n\\n// import dependencies via preval.require so that they're available as values at compile time\\nvar processorNames = {\\n  \\\"recorderProcessor\\\": \\\"recorder-processor\\\",\\n  \\\"soundFileProcessor\\\": \\\"sound-file-processor\\\",\\n  \\\"amplitudeProcessor\\\": \\\"amplitude-processor\\\"\\n};\\nvar RingBuffer = {\\n  \\\"default\\\":\\n  /*#__PURE__*/\\n  function () {\\n    /**\\n     * @constructor\\n     * @param  {number} length Buffer length in frames.\\n     * @param  {number} channelCount Buffer channel count.\\n     */\\n    function RingBuffer(length, channelCount) {\\n      _classCallCheck(this, RingBuffer);\\n\\n      this._readIndex = 0;\\n      this._writeIndex = 0;\\n      this._framesAvailable = 0;\\n      this._channelCount = channelCount;\\n      this._length = length;\\n      this._channelData = [];\\n\\n      for (var i = 0; i < this._channelCount; ++i) {\\n        this._channelData[i] = new Float32Array(length);\\n      }\\n    }\\n    /**\\n     * Getter for Available frames in buffer.\\n     *\\n     * @return {number} Available frames in buffer.\\n     */\\n\\n\\n    _createClass(RingBuffer, [{\\n      key: \\\"push\\\",\\n\\n      /**\\n       * Push a sequence of Float32Arrays to buffer.\\n       *\\n       * @param  {array} arraySequence A sequence of Float32Arrays.\\n       */\\n      value: function push(arraySequence) {\\n        // The channel count of arraySequence and the length of each channel must\\n        // match with this buffer obejct.\\n        // Transfer data from the |arraySequence| storage to the internal buffer.\\n        var sourceLength = arraySequence[0] ? arraySequence[0].length : 0;\\n\\n        for (var i = 0; i < sourceLength; ++i) {\\n          var writeIndex = (this._writeIndex + i) % this._length;\\n\\n          for (var channel = 0; channel < this._channelCount; ++channel) {\\n            this._channelData[channel][writeIndex] = arraySequence[channel][i];\\n          }\\n        }\\n\\n        this._writeIndex += sourceLength;\\n\\n        if (this._writeIndex >= this._length) {\\n          this._writeIndex = 0;\\n        } // For excessive frames, the buffer will be overwritten.\\n\\n\\n        this._framesAvailable += sourceLength;\\n\\n        if (this._framesAvailable > this._length) {\\n          this._framesAvailable = this._length;\\n        }\\n      }\\n      /**\\n       * Pull data out of buffer and fill a given sequence of Float32Arrays.\\n       *\\n       * @param  {array} arraySequence An array of Float32Arrays.\\n       */\\n\\n    }, {\\n      key: \\\"pull\\\",\\n      value: function pull(arraySequence) {\\n        // The channel count of arraySequence and the length of each channel must\\n        // match with this buffer obejct.\\n        // If the FIFO is completely empty, do nothing.\\n        if (this._framesAvailable === 0) {\\n          return;\\n        }\\n\\n        var destinationLength = arraySequence[0].length; // Transfer data from the internal buffer to the |arraySequence| storage.\\n\\n        for (var i = 0; i < destinationLength; ++i) {\\n          var readIndex = (this._readIndex + i) % this._length;\\n\\n          for (var channel = 0; channel < this._channelCount; ++channel) {\\n            arraySequence[channel][i] = this._channelData[channel][readIndex];\\n          }\\n        }\\n\\n        this._readIndex += destinationLength;\\n\\n        if (this._readIndex >= this._length) {\\n          this._readIndex = 0;\\n        }\\n\\n        this._framesAvailable -= destinationLength;\\n\\n        if (this._framesAvailable < 0) {\\n          this._framesAvailable = 0;\\n        }\\n      }\\n    }, {\\n      key: \\\"framesAvailable\\\",\\n      get: function get() {\\n        return this._framesAvailable;\\n      }\\n    }]);\\n\\n    return RingBuffer;\\n  }()\\n}[\\\"default\\\"];\\n\\nvar SoundFileProcessor =\\n/*#__PURE__*/\\nfunction (_AudioWorkletProcesso) {\\n  _inherits(SoundFileProcessor, _AudioWorkletProcesso);\\n\\n  function SoundFileProcessor(options) {\\n    var _this;\\n\\n    _classCallCheck(this, SoundFileProcessor);\\n\\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(SoundFileProcessor).call(this));\\n    var processorOptions = options.processorOptions || {};\\n    _this.bufferSize = processorOptions.bufferSize || 256;\\n    _this.inputRingBuffer = new RingBuffer(_this.bufferSize, 1);\\n    _this.inputRingBufferArraySequence = [new Float32Array(_this.bufferSize)];\\n    return _this;\\n  }\\n\\n  _createClass(SoundFileProcessor, [{\\n    key: \\\"process\\\",\\n    value: function process(inputs) {\\n      var input = inputs[0]; // we only care about the first input channel, because that contains the position data\\n\\n      this.inputRingBuffer.push([input[0]]);\\n\\n      if (this.inputRingBuffer.framesAvailable >= this.bufferSize) {\\n        this.inputRingBuffer.pull(this.inputRingBufferArraySequence);\\n        var inputChannel = this.inputRingBufferArraySequence[0];\\n        var position = inputChannel[inputChannel.length - 1] || 0;\\n        this.port.postMessage({\\n          name: 'position',\\n          position: position\\n        });\\n      }\\n\\n      return true;\\n    }\\n  }]);\\n\\n  return SoundFileProcessor;\\n}(_wrapNativeSuper(AudioWorkletProcessor));\\n\\nregisterProcessor(processorNames.soundFileProcessor, SoundFileProcessor);\");\n\n }),\n (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n __webpack_exports__[\"default\"] = (\"function _typeof(obj) { if (typeof Symbol === \\\"function\\\" && typeof Symbol.iterator === \\\"symbol\\\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \\\"function\\\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \\\"symbol\\\" : typeof obj; }; } return _typeof(obj); }\\n\\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \\\"object\\\" || typeof call === \\\"function\\\")) { return call; } return _assertThisInitialized(self); }\\n\\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\\\"this hasn't been initialised - super() hasn't been called\\\"); } return self; }\\n\\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \\\"function\\\" && superClass !== null) { throw new TypeError(\\\"Super expression must either be null or a function\\\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\\n\\nfunction _wrapNativeSuper(Class) { var _cache = typeof Map === \\\"function\\\" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== \\\"function\\\") { throw new TypeError(\\\"Super expression must either be null or a function\\\"); } if (typeof _cache !== \\\"undefined\\\") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }\\n\\nfunction isNativeReflectConstruct() { if (typeof Reflect === \\\"undefined\\\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \\\"function\\\") return true; try { Date.prototype.toString.call(Reflect.construct(Date, [], function () {})); return true; } catch (e) { return false; } }\\n\\nfunction _construct(Parent, args, Class) { if (isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }\\n\\nfunction _isNativeFunction(fn) { return Function.toString.call(fn).indexOf(\\\"[native code]\\\") !== -1; }\\n\\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\\n\\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\\n\\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\\\"Cannot call a class as a function\\\"); } }\\n\\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\\\"value\\\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\\n\\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\\n\\n// import dependencies via preval.require so that they're available as values at compile time\\nvar processorNames = {\\n  \\\"recorderProcessor\\\": \\\"recorder-processor\\\",\\n  \\\"soundFileProcessor\\\": \\\"sound-file-processor\\\",\\n  \\\"amplitudeProcessor\\\": \\\"amplitude-processor\\\"\\n};\\nvar RingBuffer = {\\n  \\\"default\\\":\\n  /*#__PURE__*/\\n  function () {\\n    /**\\n     * @constructor\\n     * @param  {number} length Buffer length in frames.\\n     * @param  {number} channelCount Buffer channel count.\\n     */\\n    function RingBuffer(length, channelCount) {\\n      _classCallCheck(this, RingBuffer);\\n\\n      this._readIndex = 0;\\n      this._writeIndex = 0;\\n      this._framesAvailable = 0;\\n      this._channelCount = channelCount;\\n      this._length = length;\\n      this._channelData = [];\\n\\n      for (var i = 0; i < this._channelCount; ++i) {\\n        this._channelData[i] = new Float32Array(length);\\n      }\\n    }\\n    /**\\n     * Getter for Available frames in buffer.\\n     *\\n     * @return {number} Available frames in buffer.\\n     */\\n\\n\\n    _createClass(RingBuffer, [{\\n      key: \\\"push\\\",\\n\\n      /**\\n       * Push a sequence of Float32Arrays to buffer.\\n       *\\n       * @param  {array} arraySequence A sequence of Float32Arrays.\\n       */\\n      value: function push(arraySequence) {\\n        // The channel count of arraySequence and the length of each channel must\\n        // match with this buffer obejct.\\n        // Transfer data from the |arraySequence| storage to the internal buffer.\\n        var sourceLength = arraySequence[0] ? arraySequence[0].length : 0;\\n\\n        for (var i = 0; i < sourceLength; ++i) {\\n          var writeIndex = (this._writeIndex + i) % this._length;\\n\\n          for (var channel = 0; channel < this._channelCount; ++channel) {\\n            this._channelData[channel][writeIndex] = arraySequence[channel][i];\\n          }\\n        }\\n\\n        this._writeIndex += sourceLength;\\n\\n        if (this._writeIndex >= this._length) {\\n          this._writeIndex = 0;\\n        } // For excessive frames, the buffer will be overwritten.\\n\\n\\n        this._framesAvailable += sourceLength;\\n\\n        if (this._framesAvailable > this._length) {\\n          this._framesAvailable = this._length;\\n        }\\n      }\\n      /**\\n       * Pull data out of buffer and fill a given sequence of Float32Arrays.\\n       *\\n       * @param  {array} arraySequence An array of Float32Arrays.\\n       */\\n\\n    }, {\\n      key: \\\"pull\\\",\\n      value: function pull(arraySequence) {\\n        // The channel count of arraySequence and the length of each channel must\\n        // match with this buffer obejct.\\n        // If the FIFO is completely empty, do nothing.\\n        if (this._framesAvailable === 0) {\\n          return;\\n        }\\n\\n        var destinationLength = arraySequence[0].length; // Transfer data from the internal buffer to the |arraySequence| storage.\\n\\n        for (var i = 0; i < destinationLength; ++i) {\\n          var readIndex = (this._readIndex + i) % this._length;\\n\\n          for (var channel = 0; channel < this._channelCount; ++channel) {\\n            arraySequence[channel][i] = this._channelData[channel][readIndex];\\n          }\\n        }\\n\\n        this._readIndex += destinationLength;\\n\\n        if (this._readIndex >= this._length) {\\n          this._readIndex = 0;\\n        }\\n\\n        this._framesAvailable -= destinationLength;\\n\\n        if (this._framesAvailable < 0) {\\n          this._framesAvailable = 0;\\n        }\\n      }\\n    }, {\\n      key: \\\"framesAvailable\\\",\\n      get: function get() {\\n        return this._framesAvailable;\\n      }\\n    }]);\\n\\n    return RingBuffer;\\n  }()\\n}[\\\"default\\\"];\\n\\nvar AmplitudeProcessor =\\n/*#__PURE__*/\\nfunction (_AudioWorkletProcesso) {\\n  _inherits(AmplitudeProcessor, _AudioWorkletProcesso);\\n\\n  function AmplitudeProcessor(options) {\\n    var _this;\\n\\n    _classCallCheck(this, AmplitudeProcessor);\\n\\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(AmplitudeProcessor).call(this));\\n    var processorOptions = options.processorOptions || {};\\n    _this.numOutputChannels = options.outputChannelCount || 1;\\n    _this.numInputChannels = processorOptions.numInputChannels || 2;\\n    _this.normalize = processorOptions.normalize || false;\\n    _this.smoothing = processorOptions.smoothing || 0;\\n    _this.bufferSize = processorOptions.bufferSize || 2048;\\n    _this.inputRingBuffer = new RingBuffer(_this.bufferSize, _this.numInputChannels);\\n    _this.outputRingBuffer = new RingBuffer(_this.bufferSize, _this.numOutputChannels);\\n    _this.inputRingBufferArraySequence = new Array(_this.numInputChannels).fill(null).map(function () {\\n      return new Float32Array(_this.bufferSize);\\n    });\\n    _this.stereoVol = [0, 0];\\n    _this.stereoVolNorm = [0, 0];\\n    _this.volMax = 0.001;\\n\\n    _this.port.onmessage = function (event) {\\n      var data = event.data;\\n\\n      if (data.name === 'toggleNormalize') {\\n        _this.normalize = data.normalize;\\n      } else if (data.name === 'smoothing') {\\n        _this.smoothing = Math.max(0, Math.min(1, data.smoothing));\\n      }\\n    };\\n\\n    return _this;\\n  } // TO DO make this stereo / dependent on # of audio channels\\n\\n\\n  _createClass(AmplitudeProcessor, [{\\n    key: \\\"process\\\",\\n    value: function process(inputs, outputs) {\\n      var input = inputs[0];\\n      var output = outputs[0];\\n      var smoothing = this.smoothing;\\n      this.inputRingBuffer.push(input);\\n\\n      if (this.inputRingBuffer.framesAvailable >= this.bufferSize) {\\n        this.inputRingBuffer.pull(this.inputRingBufferArraySequence);\\n\\n        for (var channel = 0; channel < this.numInputChannels; ++channel) {\\n          var inputBuffer = this.inputRingBufferArraySequence[channel];\\n          var bufLength = inputBuffer.length;\\n          var sum = 0;\\n\\n          for (var i = 0; i < bufLength; i++) {\\n            var x = inputBuffer[i];\\n\\n            if (this.normalize) {\\n              sum += Math.max(Math.min(x / this.volMax, 1), -1) * Math.max(Math.min(x / this.volMax, 1), -1);\\n            } else {\\n              sum += x * x;\\n            }\\n          } // ... then take the square root of the sum.\\n\\n\\n          var rms = Math.sqrt(sum / bufLength);\\n          this.stereoVol[channel] = Math.max(rms, this.stereoVol[channel] * smoothing);\\n          this.volMax = Math.max(this.stereoVol[channel], this.volMax);\\n        } // calculate stero normalized volume and add volume from all channels together\\n\\n\\n        var volSum = 0;\\n\\n        for (var index = 0; index < this.stereoVol.length; index++) {\\n          this.stereoVolNorm[index] = Math.max(Math.min(this.stereoVol[index] / this.volMax, 1), 0);\\n          volSum += this.stereoVol[index];\\n        } // volume is average of channels\\n\\n\\n        var volume = volSum / this.stereoVol.length; // normalized value\\n\\n        var volNorm = Math.max(Math.min(volume / this.volMax, 1), 0);\\n        this.port.postMessage({\\n          name: 'amplitude',\\n          volume: volume,\\n          volNorm: volNorm,\\n          stereoVol: this.stereoVol,\\n          stereoVolNorm: this.stereoVolNorm\\n        }); // pass input through to output\\n\\n        this.outputRingBuffer.push(this.inputRingBufferArraySequence);\\n      } // pull 128 frames out of the ring buffer\\n      // if the ring buffer does not have enough frames, the output will be silent\\n\\n\\n      this.outputRingBuffer.pull(output);\\n      return true;\\n    }\\n  }]);\\n\\n  return AmplitudeProcessor;\\n}(_wrapNativeSuper(AudioWorkletProcessor));\\n\\nregisterProcessor(processorNames.amplitudeProcessor, AmplitudeProcessor);\");\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(17)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(o){o.Frequency=function(e,t){if(!(this instanceof o.Frequency))return new o.Frequency(e,t);o.TimeBase.call(this,e,t)},o.extend(o.Frequency,o.TimeBase),o.Frequency.prototype._primaryExpressions=Object.create(o.TimeBase.prototype._primaryExpressions),o.Frequency.prototype._primaryExpressions.midi={regexp:/^(\\d+(?:\\.\\d+)?midi)/,method:function(e){return this.midiToFrequency(e)}},o.Frequency.prototype._primaryExpressions.note={regexp:/^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,method:function(e,t){var r=n[e.toLowerCase()]+12*(parseInt(t)+1);return this.midiToFrequency(r)}},o.Frequency.prototype._primaryExpressions.tr={regexp:/^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?/,method:function(e,t,r){var n=1;return e&&\"0\"!==e&&(n*=this._beatsToUnits(this._timeSignature()*parseFloat(e))),t&&\"0\"!==t&&(n*=this._beatsToUnits(parseFloat(t))),r&&\"0\"!==r&&(n*=this._beatsToUnits(parseFloat(r)/4)),n}},o.Frequency.prototype.transpose=function(e){return this._expr=function(e,t){return e()*this.intervalToFrequencyRatio(t)}.bind(this,this._expr,e),this},o.Frequency.prototype.harmonize=function(e){return this._expr=function(e,t){for(var r=e(),n=[],o=0;o<t.length;o++)n[o]=r*this.intervalToFrequencyRatio(t[o]);return n}.bind(this,this._expr,e),this},o.Frequency.prototype.toMidi=function(){return this.frequencyToMidi(this.valueOf())},o.Frequency.prototype.toNote=function(){var e=this.valueOf(),t=Math.log(e/o.Frequency.A4)/Math.LN2,r=Math.round(12*t)+57,n=Math.floor(r/12);return n<0&&(r+=-12*n),i[r%12]+n.toString()},o.Frequency.prototype.toSeconds=function(){return 1/this.valueOf()},o.Frequency.prototype.toFrequency=function(){return this.valueOf()},o.Frequency.prototype.toTicks=function(){var e=this._beatsToUnits(1),t=this.valueOf()/e;return Math.floor(t*o.Transport.PPQ)},o.Frequency.prototype._frequencyToUnits=function(e){return e},o.Frequency.prototype._ticksToUnits=function(e){return 1/(60*e/(o.Transport.bpm.value*o.Transport.PPQ))},o.Frequency.prototype._beatsToUnits=function(e){return 1/o.TimeBase.prototype._beatsToUnits.call(this,e)},o.Frequency.prototype._secondsToUnits=function(e){return 1/e},o.Frequency.prototype._defaultUnits=\"hz\";var n={cbb:-2,cb:-1,c:0,\"c#\":1,cx:2,dbb:0,db:1,d:2,\"d#\":3,dx:4,ebb:2,eb:3,e:4,\"e#\":5,ex:6,fbb:3,fb:4,f:5,\"f#\":6,fx:7,gbb:5,gb:6,g:7,\"g#\":8,gx:9,abb:7,ab:8,a:9,\"a#\":10,ax:11,bbb:9,bb:10,b:11,\"b#\":12,bx:13},i=[\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"];return o.Frequency.A4=440,o.Frequency.prototype.midiToFrequency=function(e){return o.Frequency.A4*Math.pow(2,(e-69)/12)},o.Frequency.prototype.frequencyToMidi=function(e){return 69+12*Math.log(e/o.Frequency.A4)/Math.LN2},o.Frequency}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(16)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(o){return o.TransportTime=function(t,r){if(!(this instanceof o.TransportTime))return new o.TransportTime(t,r);o.Time.call(this,t,r)},o.extend(o.TransportTime,o.Time),o.TransportTime.prototype._unaryExpressions=Object.create(o.Time.prototype._unaryExpressions),o.TransportTime.prototype._unaryExpressions.quantize={regexp:/^@/,method:function(t){var r=this._secondsToTicks(t()),e=Math.ceil(o.Transport.ticks/r);return this._ticksToUnits(e*r)}},o.TransportTime.prototype._secondsToTicks=function(t){var r=t/this._beatsToUnits(1);return Math.round(r*o.Transport.PPQ)},o.TransportTime.prototype.valueOf=function(){return this._secondsToTicks(this._expr())+(this._plusNow?o.Transport.ticks:0)},o.TransportTime.prototype.toTicks=function(){return this.valueOf()},o.TransportTime.prototype.toSeconds=function(){return this._expr()+(this._plusNow?o.Transport.seconds:0)},o.TransportTime.prototype.toFrequency=function(){return 1/this.toSeconds()},o.TransportTime}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(4),__webpack_require__(13),__webpack_require__(1),__webpack_require__(33),__webpack_require__(21),__webpack_require__(34),__webpack_require__(20),__webpack_require__(35),__webpack_require__(36),__webpack_require__(37)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(p){\"use strict\";function r(e,n,r){var t=new e;return r._eval(n[0]).connect(t,0,0),r._eval(n[1]).connect(t,0,1),t}function t(e,n,r){var t=new e;return r._eval(n[0]).connect(t,0,0),t}function o(e){return e?parseFloat(e):void 0}function i(e){return e&&e.args?parseFloat(e.args):void 0}return p.Expr=function(){var n=this._replacements(Array.prototype.slice.call(arguments)),e=this._parseInputs(n);this._nodes=[],this.input=new Array(e);for(var r=0;r<e;r++)this.input[r]=this.context.createGain();var t,o=this._parseTree(n);try{t=this._eval(o)}catch(e){throw this._disposeNodes(),new Error(\"Tone.Expr: Could evaluate expression: \"+n)}this.output=t},p.extend(p.Expr,p.SignalBase),p.Expr._Expressions={value:{signal:{regexp:/^\\d+\\.\\d+|^\\d+/,method:function(e){return new p.Signal(o(e))}},input:{regexp:/^\\$\\d/,method:function(e,n){return n.input[o(e.substr(1))]}}},glue:{\"(\":{regexp:/^\\(/},\")\":{regexp:/^\\)/},\",\":{regexp:/^,/}},func:{abs:{regexp:/^abs/,method:t.bind(this,p.Abs)},mod:{regexp:/^mod/,method:function(e,n){var r=i(e[1]),t=new p.Modulo(r);return n._eval(e[0]).connect(t),t}},pow:{regexp:/^pow/,method:function(e,n){var r=i(e[1]),t=new p.Pow(r);return n._eval(e[0]).connect(t),t}},a2g:{regexp:/^a2g/,method:function(e,n){var r=new p.AudioToGain;return n._eval(e[0]).connect(r),r}}},binary:{\"+\":{regexp:/^\\+/,precedence:1,method:r.bind(this,p.Add)},\"-\":{regexp:/^\\-/,precedence:1,method:function(e,n){return 1===e.length?t(p.Negate,e,n):r(p.Subtract,e,n)}},\"*\":{regexp:/^\\*/,precedence:0,method:r.bind(this,p.Multiply)}},unary:{\"-\":{regexp:/^\\-/,method:t.bind(this,p.Negate)},\"!\":{regexp:/^\\!/,method:t.bind(this,p.NOT)}}},p.Expr.prototype._parseInputs=function(e){var n=e.match(/\\$\\d/g),r=0;if(null!==n)for(var t=0;t<n.length;t++){var o=parseInt(n[t].substr(1))+1;r=Math.max(r,o)}return r},p.Expr.prototype._replacements=function(e){for(var n=e.shift(),r=0;r<e.length;r++)n=n.replace(/\\%/i,e[r]);return n},p.Expr.prototype._tokenize=function(e){for(var n=-1,r=[];0<e.length;){var t=o(e=e.trim());r.push(t),e=e.substr(t.value.length)}function o(e){for(var n in p.Expr._Expressions){var r=p.Expr._Expressions[n];for(var t in r){var o=r[t],i=o.regexp,a=e.match(i);if(null!==a)return{type:n,value:a[0],method:o.method}}}throw new SyntaxError(\"Tone.Expr: Unexpected token \"+e)}return{next:function(){return r[++n]},peek:function(){return r[n+1]}}},p.Expr.prototype._parseTree=function(e){var t=this._tokenize(e),a=this.isUndef.bind(this);function r(e,n){return!a(e)&&\"glue\"===e.type&&e.value===n}function o(e,n,r){var t=p.Expr._Expressions[n];if(!a(e))for(var o in t){var i=t[o];if(i.regexp.test(e.value)){if(a(r))return!0;if(i.precedence===r)return!0}}return!1}function i(e){var n;a(e)&&(e=5),n=e<0?function e(){var n,r;n=t.peek();if(o(n,\"unary\"))return n=t.next(),r=e(),{operator:n.value,method:n.method,args:[r]};return s()}():i(e-1);for(var r=t.peek();o(r,\"binary\",e);)n={operator:(r=t.next()).value,method:r.method,args:[n,i(e-1)]},r=t.peek();return n}function s(){var e,n;if(e=t.peek(),a(e))throw new SyntaxError(\"Tone.Expr: Unexpected termination of expression\");if(\"func\"===e.type)return function(e){var n=[];if(!r(t.next(),\"(\"))throw new SyntaxError('Tone.Expr: Expected ( in a function call \"'+e.value+'\"');r(t.peek(),\")\")||(n=function(){var e,n=[];for(;e=i(),!a(e)&&(n.push(e),r(t.peek(),\",\"));)t.next();return n}());if(r(t.next(),\")\"))return{method:e.method,args:n,name:name};throw new SyntaxError('Tone.Expr: Expected ) in a function call \"'+e.value+'\"')}(e=t.next());if(\"value\"===e.type)return{method:(e=t.next()).method,args:e.value};if(r(e,\"(\")){if(t.next(),n=i(),!r(e=t.next(),\")\"))throw new SyntaxError(\"Expected )\");return n}throw new SyntaxError(\"Tone.Expr: Parse error, cannot process token \"+e.value)}return i()},p.Expr.prototype._eval=function(e){if(!this.isUndef(e)){var n=e.method(e.args,this);return this._nodes.push(n),n}},p.Expr.prototype._disposeNodes=function(){for(var e=0;e<this._nodes.length;e++){var n=this._nodes[e];this.isFunction(n.dispose)?n.dispose():this.isFunction(n.disconnect)&&n.disconnect(),n=null,this._nodes[e]=null}this._nodes=null},p.Expr.prototype.dispose=function(){p.prototype.dispose.call(this),this._disposeNodes()},p.Expr}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(21),__webpack_require__(13),__webpack_require__(2)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(e){\"use strict\";return e.GreaterThan=function(t){this.createInsOuts(2,0),this._param=this.input[0]=new e.Subtract(t),this.input[1]=this._param.input[1],this._gtz=this.output=new e.GreaterThanZero,this._param.connect(this._gtz)},e.extend(e.GreaterThan,e.Signal),e.GreaterThan.prototype.dispose=function(){return e.prototype.dispose.call(this),this._param.dispose(),this._param=null,this._gtz.dispose(),this._gtz=null,this},e.GreaterThan}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(6),__webpack_require__(15)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(s){\"use strict\";return s.Abs=function(){this._abs=this.input=this.output=new s.WaveShaper(function(s){return 0===s?0:Math.abs(s)},127)},s.extend(s.Abs,s.SignalBase),s.Abs.prototype.dispose=function(){return s.prototype.dispose.call(this),this._abs.dispose(),this._abs=null,this},s.Abs}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(6),__webpack_require__(1),__webpack_require__(13)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(i){\"use strict\";return i.Modulo=function(t){this.createInsOuts(1,0),this._shaper=new i.WaveShaper(Math.pow(2,16)),this._multiply=new i.Multiply,this._subtract=this.output=new i.Subtract,this._modSignal=new i.Signal(t),this.input.fan(this._shaper,this._subtract),this._modSignal.connect(this._multiply,0,0),this._shaper.connect(this._multiply,0,1),this._multiply.connect(this._subtract,0,1),this._setWaveShaper(t)},i.extend(i.Modulo,i.SignalBase),i.Modulo.prototype._setWaveShaper=function(i){this._shaper.setMap(function(t){return Math.floor((t+1e-4)/i)})},Object.defineProperty(i.Modulo.prototype,\"value\",{get:function(){return this._modSignal.value},set:function(t){this._modSignal.value=t,this._setWaveShaper(t)}}),i.Modulo.prototype.dispose=function(){return i.prototype.dispose.call(this),this._shaper.dispose(),this._shaper=null,this._multiply.dispose(),this._multiply=null,this._subtract.dispose(),this._subtract=null,this._modSignal.dispose(),this._modSignal=null,this},i.Modulo}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(6)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(t){\"use strict\";return t.Pow=function(e){this._exp=this.defaultArg(e,1),this._expScaler=this.input=this.output=new t.WaveShaper(this._expFunc(this._exp),8192)},t.extend(t.Pow,t.SignalBase),Object.defineProperty(t.Pow.prototype,\"value\",{get:function(){return this._exp},set:function(e){this._exp=e,this._expScaler.setMap(this._expFunc(this._exp))}}),t.Pow.prototype._expFunc=function(t){return function(e){return Math.pow(Math.abs(e),t)}},t.Pow.prototype.dispose=function(){return t.prototype.dispose.call(this),this._expScaler.dispose(),this._expScaler=null,this},t.Pow}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(6),__webpack_require__(2)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(n){\"use strict\";return n.AudioToGain=function(){this._norm=this.input=this.output=new n.WaveShaper(function(n){return(n+1)/2})},n.extend(n.AudioToGain,n.SignalBase),n.AudioToGain.prototype.dispose=function(){return n.prototype.dispose.call(this),this._norm.dispose(),this._norm=null,this},n.AudioToGain}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(6)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(e){\"use strict\";return e.EqualPowerGain=function(){this._eqPower=this.input=this.output=new e.WaveShaper(function(e){return Math.abs(e)<.001?0:this.equalPowerScale(e)}.bind(this),4096)},e.extend(e.EqualPowerGain,e.SignalBase),e.EqualPowerGain.prototype.dispose=function(){return e.prototype.dispose.call(this),this._eqPower.dispose(),this._eqPower=null,this},e.EqualPowerGain}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, exports, __webpack_require__) {\n\nvar __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(0),__webpack_require__(19),__webpack_require__(9)], __WEBPACK_AMD_DEFINE_RESULT__ = (function(t){\"use strict\";return t.TimelineState=function(e){t.Timeline.call(this),this._initial=e},t.extend(t.TimelineState,t.Timeline),t.TimelineState.prototype.getValueAtTime=function(e){var t=this.get(e);return null!==t?t.state:this._initial},t.TimelineState.prototype.setStateAtTime=function(e,t){this.add({state:e,time:t})},t.TimelineState}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n }),\n (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n\nvar audioworklet_polyfill = __webpack_require__(24);\n\nvar shims = __webpack_require__(25);\n\nvar audiocontext = __webpack_require__(3);\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\nvar main_Main = function Main() {\n  _classCallCheck(this, Main);\n\n  this.input = audiocontext[\"a\" ].createGain();\n  this.output = audiocontext[\"a\" ].createGain(); \n\n  this.limiter = audiocontext[\"a\" ].createDynamicsCompressor();\n  this.limiter.threshold.value = -3;\n  this.limiter.ratio.value = 20;\n  this.limiter.knee.value = 1;\n  this.audiocontext = audiocontext[\"a\" ];\n  this.output.disconnect(); \n\n  this.input.connect(this.limiter); \n\n  this.limiter.connect(this.output); \n\n  this.meter = audiocontext[\"a\" ].createGain();\n  this.fftMeter = audiocontext[\"a\" ].createGain();\n  this.output.connect(this.meter);\n  this.output.connect(this.fftMeter); \n\n  this.output.connect(this.audiocontext.destination); \n\n  this.soundArray = []; \n\n  this.parts = []; \n\n  this.extensions = [];\n}; \n\n\nvar p5sound = new main_Main();\n/**\n * Returns a number representing the output volume for sound\n * in this sketch.\n *\n * @method getOutputVolume\n * @return {Number} Output volume for sound in this sketch.\n *                  Should be between 0.0 (silence) and 1.0.\n */\n\np5.prototype.getOutputVolume = function () {\n  return p5sound.output.gain.value;\n};\n/**\n *  <p>Scale the output of all sound in this sketch</p>\n *  Scaled between 0.0 (silence) and 1.0 (full volume).\n *  1.0 is the maximum amplitude of a digital sound, so multiplying\n *  by greater than 1.0 may cause digital distortion. To\n *  fade, provide a <code>rampTime</code> parameter. For more\n *  complex fades, see the Envelope class.\n *\n *  Alternately, you can pass in a signal source such as an\n *  oscillator to modulate the amplitude with an audio signal.\n *\n *  <p><b>How This Works</b>: When you load the p5.sound module, it\n *  creates a single instance of p5sound. All sound objects in this\n *  module output to p5sound before reaching your computer's output.\n *  So if you change the amplitude of p5sound, it impacts all of the\n *  sound in this module.</p>\n *\n *  <p>If no value is provided, returns a Web Audio API Gain Node</p>\n *\n *  @method  outputVolume\n *  @param {Number|Object} volume  Volume (amplitude) between 0.0\n *                                     and 1.0 or modulating signal/oscillator\n *  @param {Number} [rampTime]  Fade for t seconds\n *  @param {Number} [timeFromNow]  Schedule this event to happen at\n *                                 t seconds in the future\n */\n\n\np5.prototype.outputVolume = function (vol) {\n  var rampTime = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  var tFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n\n  if (typeof vol === 'number') {\n    var now = p5sound.audiocontext.currentTime;\n    var currentVol = p5sound.output.gain.value;\n    p5sound.output.gain.cancelScheduledValues(now + tFromNow);\n    p5sound.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow);\n    p5sound.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);\n  } else if (vol) {\n    vol.connect(p5sound.output.gain);\n  } else {\n    return p5sound.output.gain;\n  }\n};\n/**\n *  `p5.soundOut` is the p5.sound final output bus. It sends output to\n *  the destination of this window's web audio context. It contains\n *  Web Audio API nodes including a dyanmicsCompressor (<code>.limiter</code>),\n *  and Gain Nodes for <code>.input</code> and <code>.output</code>.\n *\n *  @property {Object} soundOut\n */\n\n\np5.prototype.soundOut = p5.soundOut = p5sound; \n\np5.soundOut._silentNode = p5sound.audiocontext.createGain();\np5.soundOut._silentNode.gain.value = 0;\n\np5.soundOut._silentNode.connect(p5sound.audiocontext.destination);\n\n var main = (p5sound);\nvar processorNames = __webpack_require__(5);\nvar processorNames_default = __webpack_require__.n(processorNames);\n\nfunction _typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\n\n\n/**\n * @for p5\n */\n\n/**\n * Returns a number representing the sample rate, in samples per second,\n * of all sound objects in this audio context. It is determined by the\n * sampling rate of your operating system's sound card, and it is not\n * currently possile to change.\n * It is often 44100, or twice the range of human hearing.\n *\n * @method sampleRate\n * @return {Number} samplerate samples per second\n */\n\nfunction sampleRate() {\n  return main.audiocontext.sampleRate;\n}\n/**\n *  Returns the closest MIDI note value for\n *  a given frequency.\n *\n *  @method freqToMidi\n *  @param  {Number} frequency A freqeuncy, for example, the \"A\"\n *                             above Middle C is 440Hz\n *  @return {Number}   MIDI note value\n */\n\n\nfunction freqToMidi(f) {\n  var mathlog2 = Math.log(f / 440) / Math.log(2);\n  var m = Math.round(12 * mathlog2) + 69;\n  return m;\n}\n/**\n *  Returns the frequency value of a MIDI note value.\n *  General MIDI treats notes as integers where middle C\n *  is 60, C# is 61, D is 62 etc. Useful for generating\n *  musical frequencies with oscillators.\n *\n *  @method  midiToFreq\n *  @param  {Number} midiNote The number of a MIDI note\n *  @return {Number} Frequency value of the given MIDI note\n *  @example\n *  <div><code>\n *  let midiNotes = [60, 64, 67, 72];\n *  let noteIndex = 0;\n *  let midiVal, freq;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(startSound);\n *    osc = new p5.TriOsc();\n *    env = new p5.Envelope();\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap to play', 10, 20);\n *    if (midiVal) {\n *      text('MIDI: ' + midiVal, 10, 40);\n *      text('Freq: ' + freq, 10, 60);\n *    }\n *  }\n *\n *  function startSound() {\n *    // see also: userStartAudio();\n *    osc.start();\n *\n *    midiVal = midiNotes[noteIndex % midiNotes.length];\n *    freq = midiToFreq(midiVal);\n *    osc.freq(freq);\n *    env.ramp(osc, 0, 1.0, 0);\n *\n *    noteIndex++;\n *  }\n *  </code></div>\n */\n\n\nfunction midiToFreq(m) {\n  return 440 * Math.pow(2, (m - 69) / 12.0);\n} \n\n\nfunction noteToFreq(note) {\n  if (typeof note !== 'string') {\n    return note;\n  }\n\n  var wholeNotes = {\n    A: 21,\n    B: 23,\n    C: 24,\n    D: 26,\n    E: 28,\n    F: 29,\n    G: 31\n  };\n  var value = wholeNotes[note[0].toUpperCase()];\n  var octave = ~~note.slice(-1);\n  value += 12 * (octave - 1);\n\n  switch (note[1]) {\n    case '#':\n      value += 1;\n      break;\n\n    case 'b':\n      value -= 1;\n      break;\n\n    default:\n      break;\n  }\n\n  return midiToFreq(value);\n}\n/**\n *  List the SoundFile formats that you will include. LoadSound\n *  will search your directory for these extensions, and will pick\n *  a format that is compatable with the client's web browser.\n *  <a href=\"http://media.io/\">Here</a> is a free online file\n *  converter.\n *\n *  @method soundFormats\n *  @param {String} [...formats] i.e. 'mp3', 'wav', 'ogg'\n *  @example\n *  <div><code>\n *  function preload() {\n *    // set the global sound formats\n *    soundFormats('mp3', 'ogg');\n *\n *    // load either beatbox.mp3, or .ogg, depending on browser\n *    mySound = loadSound('assets/beatbox.mp3');\n *  }\n *\n *  function setup() {\n *       let cnv = createCanvas(100, 100);\n *       background(220);\n *       text('sound loaded! tap to play', 10, 20, width - 20);\n *       cnv.mousePressed(function() {\n *         mySound.play();\n *       });\n *     }\n *  </code></div>\n */\n\n\nfunction soundFormats() {\n  main.extensions = []; \n\n  for (var i = 0; i < arguments.length; i++) {\n    arguments[i] = arguments[i].toLowerCase();\n\n    if (['mp3', 'wav', 'ogg', 'm4a', 'aac'].indexOf(arguments[i]) > -1) {\n      main.extensions.push(arguments[i]);\n    } else {\n      throw arguments[i] + ' is not a valid sound format!';\n    }\n  }\n}\n\nfunction disposeSound() {\n  for (var i = 0; i < main.soundArray.length; i++) {\n    main.soundArray[i].dispose();\n  }\n}\n\nfunction _checkFileFormats(paths) {\n  var path; \n\n  if (typeof paths === 'string') {\n    path = paths; \n\n    var extTest = path.split('.').pop(); \n\n    if (['mp3', 'wav', 'ogg', 'm4a', 'aac'].indexOf(extTest) > -1) {\n      if (!p5.prototype.isFileSupported(extTest)) {\n        var pathSplit = path.split('.');\n        var pathCore = pathSplit[pathSplit.length - 1];\n\n        for (var _i = 0; _i < main.extensions.length; _i++) {\n          var _extension = main.extensions[_i];\n\n          var _supported = p5.prototype.isFileSupported(_extension);\n\n          if (_supported) {\n            pathCore = '';\n\n            if (pathSplit.length === 2) {\n              pathCore += pathSplit[0];\n            }\n\n            for (var _i2 = 1; _i2 <= pathSplit.length - 2; _i2++) {\n              var p = pathSplit[_i2];\n              pathCore += '.' + p;\n            }\n\n            path = pathCore += '.';\n            path = path += _extension;\n            break;\n          }\n        }\n      }\n    } \n    else {\n        for (var _i3 = 0; _i3 < main.extensions.length; _i3++) {\n          var _extension2 = main.extensions[_i3];\n\n          var _supported2 = p5.prototype.isFileSupported(_extension2);\n\n          if (_supported2) {\n            path = path + '.' + _extension2;\n            break;\n          }\n        }\n      }\n  } \n  else if (_typeof(paths) === 'object') {\n      for (var i = 0; i < paths.length; i++) {\n        var extension = paths[i].split('.').pop();\n        var supported = p5.prototype.isFileSupported(extension);\n\n        if (supported) {\n          path = paths[i];\n          break;\n        }\n      }\n    }\n\n  return path;\n}\n/**\n *  Used by Osc and Envelope to chain signal math\n */\n\n\nfunction _mathChain(o, math, thisChain, nextChain, type) {\n  for (var i in o.mathOps) {\n    if (o.mathOps[i] instanceof type) {\n      o.mathOps[i].dispose();\n      thisChain = i;\n\n      if (thisChain < o.mathOps.length - 1) {\n        nextChain = o.mathOps[i + 1];\n      }\n    }\n  }\n\n  o.mathOps[thisChain - 1].disconnect();\n  o.mathOps[thisChain - 1].connect(math);\n  math.connect(nextChain);\n  o.mathOps[thisChain] = math;\n  return o;\n} \n\n\nfunction convertToWav(audioBuffer) {\n  var leftChannel, rightChannel;\n  leftChannel = audioBuffer.getChannelData(0); \n\n  if (audioBuffer.numberOfChannels > 1) {\n    rightChannel = audioBuffer.getChannelData(1);\n  } else {\n    rightChannel = leftChannel;\n  }\n\n  var interleaved = interleave(leftChannel, rightChannel); \n\n  var buffer = new window.ArrayBuffer(44 + interleaved.length * 2);\n  var view = new window.DataView(buffer); \n\n  writeUTFBytes(view, 0, 'RIFF');\n  view.setUint32(4, 36 + interleaved.length * 2, true);\n  writeUTFBytes(view, 8, 'WAVE'); \n\n  writeUTFBytes(view, 12, 'fmt ');\n  view.setUint32(16, 16, true);\n  view.setUint16(20, 1, true); \n\n  view.setUint16(22, 2, true);\n  view.setUint32(24, main.audiocontext.sampleRate, true);\n  view.setUint32(28, main.audiocontext.sampleRate * 4, true);\n  view.setUint16(32, 4, true);\n  view.setUint16(34, 16, true); \n\n  writeUTFBytes(view, 36, 'data');\n  view.setUint32(40, interleaved.length * 2, true); \n\n  var lng = interleaved.length;\n  var index = 44;\n  var volume = 1;\n\n  for (var i = 0; i < lng; i++) {\n    view.setInt16(index, interleaved[i] * (0x7fff * volume), true);\n    index += 2;\n  }\n\n  return view;\n} \n\n\nfunction interleave(leftChannel, rightChannel) {\n  var length = leftChannel.length + rightChannel.length;\n  var result = new Float32Array(length);\n  var inputIndex = 0;\n\n  for (var index = 0; index < length;) {\n    result[index++] = leftChannel[inputIndex];\n    result[index++] = rightChannel[inputIndex];\n    inputIndex++;\n  }\n\n  return result;\n}\n\nfunction writeUTFBytes(view, offset, string) {\n  var lng = string.length;\n\n  for (var i = 0; i < lng; i++) {\n    view.setUint8(offset + i, string.charCodeAt(i));\n  }\n}\n\nfunction safeBufferSize(idealBufferSize) {\n  var bufferSize = idealBufferSize; \n\n  var tempAudioWorkletNode = new AudioWorkletNode(main.audiocontext, processorNames_default.a.soundFileProcessor);\n\n  if (tempAudioWorkletNode instanceof ScriptProcessorNode) {\n    bufferSize = tempAudioWorkletNode.bufferSize;\n  }\n\n  tempAudioWorkletNode.disconnect();\n  tempAudioWorkletNode = null;\n  return bufferSize;\n}\n/**\n * Save a p5.SoundFile as a .wav file. The browser will prompt the user\n * to download the file to their device.\n * For uploading audio to a server, use\n * <a href=\"/docs/reference/#/p5.SoundFile/saveBlob\">`p5.SoundFile.saveBlob`</a>.\n *\n *  @for p5\n *  @method saveSound\n *  @param  {p5.SoundFile} soundFile p5.SoundFile that you wish to save\n *  @param  {String} fileName      name of the resulting .wav file.\n */\n\n\nfunction saveSound(soundFile, fileName) {\n  var dataView = convertToWav(soundFile.buffer);\n  p5.prototype.writeFile([dataView], fileName, 'wav');\n}\n\n\nvar CustomError = function CustomError(name, errorTrace, failedPath) {\n  var err = new Error();\n  var tempStack, splitStack;\n  err.name = name;\n  err.originalStack = err.stack + errorTrace;\n  tempStack = err.stack + errorTrace;\n  err.failedPath = failedPath; \n\n  splitStack = tempStack.split('\\n').filter(function (ln) {\n    return !ln.match(/(p5.|native code|globalInit)/g);\n  });\n  err.stack = splitStack.join('\\n');\n  return err; \n};\n\n var errorHandler = (CustomError);\n\nvar moduleSources = [__webpack_require__(27)[\"default\"], __webpack_require__(28)[\"default\"], __webpack_require__(29)[\"default\"]];\nvar audioWorklet_ac = main.audiocontext;\nvar initializedAudioWorklets = false;\n\nfunction loadAudioWorkletModules() {\n  return Promise.all(moduleSources.map(function (moduleSrc) {\n    var blob = new Blob([moduleSrc], {\n      type: 'application/javascript'\n    });\n    var objectURL = URL.createObjectURL(blob);\n    return audioWorklet_ac.audioWorklet.addModule(objectURL);\n  }));\n}\n\np5.prototype.registerMethod('init', function () {\n  if (initializedAudioWorklets) return; \n\n  if (!this.preload && !window.preload) {\n    this.preload = function () {};\n  } \n\n\n  this._incrementPreload();\n\n  var onWorkletModulesLoad = function () {\n    initializedAudioWorklets = true;\n\n    this._decrementPreload();\n  }.bind(this);\n\n  loadAudioWorkletModules().then(onWorkletModulesLoad);\n});\nfunction panner_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\nvar panner_ac = main.audiocontext;\nvar panner; \n\nif (typeof panner_ac.createStereoPanner !== 'undefined') {\n  var Panner =\n  function () {\n    function Panner(input, output) {\n      panner_classCallCheck(this, Panner);\n\n      this.stereoPanner = this.input = panner_ac.createStereoPanner();\n      input.connect(this.stereoPanner);\n      this.stereoPanner.connect(output);\n    }\n\n    _createClass(Panner, [{\n      key: \"pan\",\n      value: function pan(val, tFromNow) {\n        var time = tFromNow || 0;\n        var t = panner_ac.currentTime + time;\n        this.stereoPanner.pan.linearRampToValueAtTime(val, t);\n      } \n\n    }, {\n      key: \"inputChannels\",\n      value: function inputChannels() {}\n    }, {\n      key: \"connect\",\n      value: function connect(obj) {\n        this.stereoPanner.connect(obj);\n      }\n    }, {\n      key: \"disconnect\",\n      value: function disconnect() {\n        if (this.stereoPanner) {\n          this.stereoPanner.disconnect();\n        }\n      }\n    }]);\n\n    return Panner;\n  }();\n\n  panner = Panner;\n} else {\n  var _Panner =\n  function () {\n    function _Panner(input, output, numInputChannels) {\n      panner_classCallCheck(this, _Panner);\n\n      this.input = panner_ac.createGain();\n      input.connect(this.input);\n      this.left = panner_ac.createGain();\n      this.right = panner_ac.createGain();\n      this.left.channelInterpretation = 'discrete';\n      this.right.channelInterpretation = 'discrete'; \n\n      if (numInputChannels > 1) {\n        this.splitter = panner_ac.createChannelSplitter(2);\n        this.input.connect(this.splitter);\n        this.splitter.connect(this.left, 1);\n        this.splitter.connect(this.right, 0);\n      } else {\n        this.input.connect(this.left);\n        this.input.connect(this.right);\n      }\n\n      this.output = panner_ac.createChannelMerger(2);\n      this.left.connect(this.output, 0, 1);\n      this.right.connect(this.output, 0, 0);\n      this.output.connect(output);\n    } \n\n\n    _createClass(_Panner, [{\n      key: \"pan\",\n      value: function pan(val, tFromNow) {\n        var time = tFromNow || 0;\n        var t = panner_ac.currentTime + time;\n        var v = (val + 1) / 2;\n        var rightVal = Math.cos(v * Math.PI / 2);\n        var leftVal = Math.sin(v * Math.PI / 2);\n        this.left.gain.linearRampToValueAtTime(leftVal, t);\n        this.right.gain.linearRampToValueAtTime(rightVal, t);\n      }\n    }, {\n      key: \"inputChannels\",\n      value: function inputChannels(numChannels) {\n        if (numChannels === 1) {\n          this.input.disconnect();\n          this.input.connect(this.left);\n          this.input.connect(this.right);\n        } else if (numChannels === 2) {\n          if (typeof this.splitter === 'undefined') {\n            this.splitter = panner_ac.createChannelSplitter(2);\n          }\n\n          this.input.disconnect();\n          this.input.connect(this.splitter);\n          this.splitter.connect(this.left, 1);\n          this.splitter.connect(this.right, 0);\n        }\n      }\n    }, {\n      key: \"connect\",\n      value: function connect(obj) {\n        this.output.connect(obj);\n      }\n    }, {\n      key: \"disconnect\",\n      value: function disconnect() {\n        if (this.output) {\n          this.output.disconnect();\n        }\n      }\n    }]);\n\n    return _Panner;\n  }();\n\n  panner = _Panner;\n}\n\n var panner_0 = (panner);\nfunction soundfile_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { soundfile_typeof = function _typeof(obj) { return typeof obj; }; } else { soundfile_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return soundfile_typeof(obj); }\n\nfunction soundfile_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction soundfile_createClass(Constructor, protoProps, staticProps) { if (protoProps) soundfile_defineProperties(Constructor.prototype, protoProps); if (staticProps) soundfile_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction soundfile_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\n\n\n\nvar soundfile_ac = main.audiocontext;\n\nvar _createCounterBuffer = function _createCounterBuffer(buffer) {\n  var len = buffer.length;\n  var audioBuf = soundfile_ac.createBuffer(1, buffer.length, soundfile_ac.sampleRate);\n  var arrayBuffer = audioBuf.getChannelData(0);\n\n  for (var index = 0; index < len; index++) {\n    arrayBuffer[index] = index;\n  }\n\n  return audioBuf;\n};\n\n\nvar Cue = function Cue(callback, time, id, val) {\n  soundfile_classCallCheck(this, Cue);\n\n  this.callback = callback;\n  this.time = time;\n  this.id = id;\n  this.val = val;\n}; \n\n\nfunction _clearOnEnd(e) {\n  var thisBufferSourceNode = e.target;\n  var soundFile = this; \n\n  thisBufferSourceNode._playing = false;\n  thisBufferSourceNode.removeEventListener('ended', soundFile._clearOnEnd); \n\n  soundFile._onended(soundFile); \n\n\n  soundFile.bufferSourceNodes.map(function (_, i) {\n    return i;\n  }).reverse().forEach(function (i) {\n    var n = soundFile.bufferSourceNodes[i];\n\n    if (n._playing === false) {\n      soundFile.bufferSourceNodes.splice(i, 1);\n    }\n  });\n\n  if (soundFile.bufferSourceNodes.length === 0) {\n    soundFile._playing = false;\n  }\n}\n/**\n *  <p>SoundFile object with a path to a file.</p>\n *\n *  <p>The p5.SoundFile may not be available immediately because\n *  it loads the file information asynchronously.</p>\n *\n *  <p>To do something with the sound as soon as it loads\n *  pass the name of a function as the second parameter.</p>\n *\n *  <p>Only one file path is required. However, audio file formats\n *  (i.e. mp3, ogg, wav and m4a/aac) are not supported by all\n *  web browsers. If you want to ensure compatability, instead of a single\n *  file path, you may include an Array of filepaths, and the browser will\n *  choose a format that works.</p>\n *\n *  @class p5.SoundFile\n *  @constructor\n *  @param {String|Array} path   path to a sound file (String). Optionally,\n *                               you may include multiple file formats in\n *                               an array. Alternately, accepts an object\n *                               from the HTML5 File API, or a p5.File.\n *  @param {Function} [successCallback]   Name of a function to call once file loads\n *  @param {Function} [errorCallback]   Name of a function to call if file fails to\n *                                      load. This function will receive an error or\n *                                     XMLHttpRequest object with information\n *                                     about what went wrong.\n *  @param {Function} [whileLoadingCallback]   Name of a function to call while file\n *                                             is loading. That function will\n *                                             receive progress of the request to\n *                                             load the sound file\n *                                             (between 0 and 1) as its first\n *                                             parameter. This progress\n *                                             does not account for the additional\n *                                             time needed to decode the audio data.\n *\n *  @example\n *  <div><code>\n *  let mySound;\n *  function preload() {\n *    soundFormats('mp3', 'ogg');\n *    mySound = loadSound('assets/doorbell');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(canvasPressed);\n *    background(220);\n *    text('tap here to play', 10, 20);\n *  }\n *\n *  function canvasPressed() {\n *    // playing a sound file on a user gesture\n *    // is equivalent to `userStartAudio()`\n *    mySound.play();\n *  }\n * </code></div>\n */\n\n\nvar soundfile_SoundFile =\nfunction () {\n  function SoundFile(paths, onload, onerror, whileLoading) {\n    soundfile_classCallCheck(this, SoundFile);\n\n    if (typeof paths !== 'undefined') {\n      if (typeof paths === 'string' || typeof paths[0] === 'string') {\n        var path = p5.prototype._checkFileFormats(paths);\n\n        this.url = path;\n      } else if (soundfile_typeof(paths) === 'object') {\n        if (!(window.File && window.FileReader && window.FileList && window.Blob)) {\n          throw 'Unable to load file because the File API is not supported';\n        }\n      } \n\n\n      if (paths.file) {\n        paths = paths.file;\n      }\n\n      this.file = paths;\n    } \n\n\n    this._onended = function () {};\n\n    this._looping = false;\n    this._playing = false;\n    this._paused = false;\n    this._pauseTime = 0; \n\n    this._cues = [];\n    this._cueIDCounter = 0; \n\n    this._lastPos = 0;\n    this._counterNode = null;\n    this._workletNode = null; \n\n    this.bufferSourceNodes = []; \n\n    this.bufferSourceNode = null;\n    this.buffer = null;\n    this.playbackRate = 1;\n    this.input = main.audiocontext.createGain();\n    this.output = main.audiocontext.createGain();\n    this.reversed = false; \n\n    this.startTime = 0;\n    this.endTime = null;\n    this.pauseTime = 0; \n\n    this.mode = 'sustain'; \n\n    this.startMillis = null; \n\n    this.panPosition = 0.0;\n    this.panner = new panner_0(this.output, main.input, 2); \n\n    if (this.url || this.file) {\n      this.load(onload, onerror);\n    } \n\n\n    main.soundArray.push(this);\n\n    if (typeof whileLoading === 'function') {\n      this._whileLoading = whileLoading;\n    } else {\n      this._whileLoading = function () {};\n    }\n\n    this._clearOnEnd = _clearOnEnd.bind(this); \n\n    this.amp = this.setVolume; \n\n    this.fade = this.setVolume;\n  }\n  /**\n   * This is a helper function that the p5.SoundFile calls to load\n   * itself. Accepts a callback (the name of another function)\n   * as an optional parameter.\n   *\n   * @private\n   * @for p5.SoundFile\n   * @param {Function} [successCallback]   Name of a function to call once file loads\n   * @param {Function} [errorCallback]   Name of a function to call if there is an error\n   */\n\n\n  soundfile_createClass(SoundFile, [{\n    key: \"load\",\n    value: function load(callback, errorCallback) {\n      var self = this;\n      var errorTrace = new Error().stack;\n\n      if (this.url !== undefined && this.url !== '') {\n        var request = new XMLHttpRequest();\n        request.addEventListener('progress', function (evt) {\n          self._updateProgress(evt);\n        }, false);\n        request.open('GET', this.url, true);\n        request.responseType = 'arraybuffer';\n\n        request.onload = function () {\n          if (request.status === 200) {\n            if (!self.panner) return;\n            soundfile_ac.decodeAudioData(request.response, \n            function (buff) {\n              if (!self.panner) return;\n              self.buffer = buff;\n              self.panner.inputChannels(buff.numberOfChannels);\n\n              if (callback) {\n                callback(self);\n              }\n            }, \n            function () {\n              if (!self.panner) return;\n              var err = new errorHandler('decodeAudioData', errorTrace, self.url);\n              var msg = 'AudioContext error at decodeAudioData for ' + self.url;\n\n              if (errorCallback) {\n                err.msg = msg;\n                errorCallback(err);\n              } else {\n                console.error(msg + '\\n The error stack trace includes: \\n' + err.stack);\n              }\n            });\n          } \n          else {\n              if (!self.panner) return;\n              var err = new errorHandler('loadSound', errorTrace, self.url);\n              var msg = 'Unable to load ' + self.url + '. The request status was: ' + request.status + ' (' + request.statusText + ')';\n\n              if (errorCallback) {\n                err.message = msg;\n                errorCallback(err);\n              } else {\n                console.error(msg + '\\n The error stack trace includes: \\n' + err.stack);\n              }\n            }\n        }; \n\n\n        request.onerror = function () {\n          var err = new errorHandler('loadSound', errorTrace, self.url);\n          var msg = 'There was no response from the server at ' + self.url + '. Check the url and internet connectivity.';\n\n          if (errorCallback) {\n            err.message = msg;\n            errorCallback(err);\n          } else {\n            console.error(msg + '\\n The error stack trace includes: \\n' + err.stack);\n          }\n        };\n\n        request.send();\n      } else if (this.file !== undefined) {\n        var reader = new FileReader();\n\n        reader.onload = function () {\n          if (!self.panner) return;\n          soundfile_ac.decodeAudioData(reader.result, function (buff) {\n            if (!self.panner) return;\n            self.buffer = buff;\n            self.panner.inputChannels(buff.numberOfChannels);\n\n            if (callback) {\n              callback(self);\n            }\n          });\n        };\n\n        reader.onerror = function (e) {\n          if (!self.panner) return;\n\n          if (onerror) {\n            onerror(e);\n          }\n        };\n\n        reader.readAsArrayBuffer(this.file);\n      }\n    } \n\n  }, {\n    key: \"_updateProgress\",\n    value: function _updateProgress(evt) {\n      if (evt.lengthComputable) {\n        var percentComplete = evt.loaded / evt.total * 0.99;\n\n        this._whileLoading(percentComplete, evt); \n\n      } else {\n        this._whileLoading('size unknown');\n      }\n    }\n    /**\n     *  Returns true if the sound file finished loading successfully.\n     *\n     *  @method  isLoaded\n     *  @for p5.SoundFile\n     *  @return {Boolean}\n     */\n\n  }, {\n    key: \"isLoaded\",\n    value: function isLoaded() {\n      if (this.buffer) {\n        return true;\n      } else {\n        return false;\n      }\n    }\n    /**\n     * Play the p5.SoundFile\n     *\n     * @method play\n     * @for p5.SoundFile\n     * @param {Number} [startTime]            (optional) schedule playback to start (in seconds from now).\n     * @param {Number} [rate]             (optional) playback rate\n     * @param {Number} [amp]              (optional) amplitude (volume)\n     *                                     of playback\n     * @param {Number} [cueStart]        (optional) cue start time in seconds\n     * @param {Number} [duration]          (optional) duration of playback in seconds\n     */\n\n  }, {\n    key: \"play\",\n    value: function play(startTime, rate, amp, _cueStart, duration) {\n      if (!this.output) {\n        console.warn('SoundFile.play() called after dispose');\n        return;\n      }\n\n      var now = main.audiocontext.currentTime;\n      var cueStart, cueEnd;\n      var time = startTime || 0;\n\n      if (time < 0) {\n        time = 0;\n      }\n\n      time = time + now;\n\n      if (typeof rate !== 'undefined') {\n        this.rate(rate);\n      }\n\n      if (typeof amp !== 'undefined') {\n        this.setVolume(amp);\n      } \n\n\n      if (this.buffer) {\n        this._pauseTime = 0; \n\n        if (this.mode === 'restart' && this.buffer && this.bufferSourceNode) {\n          this.bufferSourceNode.stop(time);\n\n          this._counterNode.stop(time);\n        } \n\n\n        if (this.mode === 'untildone' && this.isPlaying()) {\n          return;\n        } \n\n\n        this.bufferSourceNode = this._initSourceNode(); \n\n        delete this._counterNode;\n        this._counterNode = this._initCounterNode();\n\n        if (_cueStart) {\n          if (_cueStart >= 0 && _cueStart < this.buffer.duration) {\n            cueStart = _cueStart;\n          } else {\n            throw 'start time out of range';\n          }\n        } else {\n          cueStart = 0;\n        }\n\n        if (duration) {\n          duration = duration <= this.buffer.duration - cueStart ? duration : this.buffer.duration;\n        } \n\n\n        if (this._paused) {\n          this.bufferSourceNode.start(time, this.pauseTime, duration);\n\n          this._counterNode.start(time, this.pauseTime, duration);\n        } else {\n          this.bufferSourceNode.start(time, cueStart, duration);\n\n          this._counterNode.start(time, cueStart, duration);\n        }\n\n        this._playing = true;\n        this._paused = false; \n\n        this.bufferSourceNodes.push(this.bufferSourceNode);\n        this.bufferSourceNode._arrayIndex = this.bufferSourceNodes.length - 1;\n        this.bufferSourceNode.addEventListener('ended', this._clearOnEnd);\n      } \n      else {\n          throw 'not ready to play file, buffer has yet to load. Try preload()';\n        } \n\n\n      this.bufferSourceNode.loop = this._looping;\n      this._counterNode.loop = this._looping;\n\n      if (this._looping === true) {\n        cueEnd = duration ? duration : cueStart - 0.000000000000001;\n        this.bufferSourceNode.loopStart = cueStart;\n        this.bufferSourceNode.loopEnd = cueEnd;\n        this._counterNode.loopStart = cueStart;\n        this._counterNode.loopEnd = cueEnd;\n      }\n    }\n    /**\n     *  p5.SoundFile has two play modes: <code>restart</code> and\n     *  <code>sustain</code>. Play Mode determines what happens to a\n     *  p5.SoundFile if it is triggered while in the middle of playback.\n     *  In sustain mode, playback will continue simultaneous to the\n     *  new playback. In restart mode, play() will stop playback\n     *  and start over. With untilDone, a sound will play only if it's\n     *  not already playing. Sustain is the default mode.\n     *\n     *  @method  playMode\n     *  @for p5.SoundFile\n     *  @param  {String} str 'restart' or 'sustain' or 'untilDone'\n     *  @example\n     *  <div><code>\n     *  let mySound;\n     *  function preload(){\n     *    mySound = loadSound('assets/Damscray_DancingTiger.mp3');\n     *  }\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *    noFill();\n     *    rect(0, height/2, width - 1, height/2 - 1);\n     *    rect(0, 0, width - 1, height/2);\n     *    textAlign(CENTER, CENTER);\n     *    fill(20);\n     *    text('restart', width/2, 1 * height/4);\n     *    text('sustain', width/2, 3 * height/4);\n     *  }\n     *  function canvasPressed() {\n     *    if (mouseX < height/2) {\n     *      mySound.playMode('restart');\n     *    } else {\n     *      mySound.playMode('sustain');\n     *    }\n     *    mySound.play();\n     *  }\n     *\n     * </code></div>\n     */\n\n  }, {\n    key: \"playMode\",\n    value: function playMode(str) {\n      var s = str.toLowerCase(); \n\n      if (s === 'restart' && this.buffer && this.bufferSourceNode) {\n        for (var i = 0; i < this.bufferSourceNodes.length - 1; i++) {\n          var now = main.audiocontext.currentTime;\n          this.bufferSourceNodes[i].stop(now);\n        }\n      } \n\n\n      if (s === 'restart' || s === 'sustain' || s === 'untildone') {\n        this.mode = s;\n      } else {\n        throw 'Invalid play mode. Must be either \"restart\" or \"sustain\"';\n      }\n    }\n    /**\n     *  Pauses a file that is currently playing. If the file is not\n     *  playing, then nothing will happen.\n     *\n     *  After pausing, .play() will resume from the paused\n     *  position.\n     *  If p5.SoundFile had been set to loop before it was paused,\n     *  it will continue to loop after it is unpaused with .play().\n     *\n     *  @method pause\n     *  @for p5.SoundFile\n     *  @param {Number} [startTime] (optional) schedule event to occur\n     *                               seconds from now\n     *  @example\n     *  <div><code>\n     *  let soundFile;\n     *  function preload() {\n     *    soundFormats('ogg', 'mp3');\n     *    soundFile = loadSound('assets/Damscray_-_Dancing_Tiger_02.mp3');\n     *  }\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *    background(220);\n     *    text('tap to play, release to pause', 10, 20, width - 20);\n     *  }\n     *  function canvasPressed() {\n     *    soundFile.loop();\n     *    background(0, 200, 50);\n     *  }\n     *  function mouseReleased() {\n     *    soundFile.pause();\n     *    background(220);\n     *  }\n     *  </code>\n     *  </div>\n     */\n\n  }, {\n    key: \"pause\",\n    value: function pause(startTime) {\n      var now = main.audiocontext.currentTime;\n      var time = startTime || 0;\n      var pTime = time + now;\n\n      if (this.isPlaying() && this.buffer && this.bufferSourceNode) {\n        this._paused = true;\n        this._playing = false;\n        this.pauseTime = this.currentTime();\n        this.bufferSourceNode.stop(pTime);\n\n        this._counterNode.stop(pTime);\n\n        this._pauseTime = this.currentTime(); \n      } else {\n        this._pauseTime = 0;\n      }\n    }\n    /**\n     * Loop the p5.SoundFile. Accepts optional parameters to set the\n     * playback rate, playback volume, loopStart, loopEnd.\n     *\n     * @method loop\n     * @for p5.SoundFile\n     * @param {Number} [startTime] (optional) schedule event to occur\n     *                             seconds from now\n     * @param {Number} [rate]        (optional) playback rate\n     * @param {Number} [amp]         (optional) playback volume\n     * @param {Number} [cueLoopStart] (optional) startTime in seconds\n     * @param {Number} [duration]  (optional) loop duration in seconds\n     * @example\n     *  <div><code>\n     *  let soundFile;\n     *  let loopStart = 0.5;\n     *  let loopDuration = 0.2;\n     *  function preload() {\n     *    soundFormats('ogg', 'mp3');\n     *    soundFile = loadSound('assets/Damscray_-_Dancing_Tiger_02.mp3');\n     *  }\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *    background(220);\n     *    text('tap to play, release to pause', 10, 20, width - 20);\n     *  }\n     *  function canvasPressed() {\n     *    soundFile.loop();\n     *    background(0, 200, 50);\n     *  }\n     *  function mouseReleased() {\n     *    soundFile.pause();\n     *    background(220);\n     *  }\n     *  </code>\n     *  </div>\n     */\n\n  }, {\n    key: \"loop\",\n    value: function loop(startTime, rate, amp, loopStart, duration) {\n      this._looping = true;\n      this.play(startTime, rate, amp, loopStart, duration);\n    }\n    /**\n     * Set a p5.SoundFile's looping flag to true or false. If the sound\n     * is currently playing, this change will take effect when it\n     * reaches the end of the current playback.\n     *\n     * @method setLoop\n     * @for p5.SoundFile\n     * @param {Boolean} Boolean   set looping to true or false\n     */\n\n  }, {\n    key: \"setLoop\",\n    value: function setLoop(bool) {\n      if (bool === true) {\n        this._looping = true;\n      } else if (bool === false) {\n        this._looping = false;\n      } else {\n        throw 'Error: setLoop accepts either true or false';\n      }\n\n      if (this.bufferSourceNode) {\n        this.bufferSourceNode.loop = this._looping;\n        this._counterNode.loop = this._looping;\n      }\n    }\n    /**\n     * Returns 'true' if a p5.SoundFile is currently looping and playing, 'false' if not.\n     *\n     * @method isLooping\n     * @for p5.SoundFile\n     * @return {Boolean}\n     */\n\n  }, {\n    key: \"isLooping\",\n    value: function isLooping() {\n      if (!this.bufferSourceNode) {\n        return false;\n      }\n\n      if (this._looping === true && this.isPlaying() === true) {\n        return true;\n      }\n\n      return false;\n    }\n    /**\n     *  Returns true if a p5.SoundFile is playing, false if not (i.e.\n     *  paused or stopped).\n     *\n     *  @method isPlaying\n     *  @for p5.SoundFile\n     *  @return {Boolean}\n     */\n\n  }, {\n    key: \"isPlaying\",\n    value: function isPlaying() {\n      return this._playing;\n    }\n    /**\n     *  Returns true if a p5.SoundFile is paused, false if not (i.e.\n     *  playing or stopped).\n     *\n     *  @method  isPaused\n     *  @for p5.SoundFile\n     *  @return {Boolean}\n     */\n\n  }, {\n    key: \"isPaused\",\n    value: function isPaused() {\n      return this._paused;\n    }\n    /**\n     * Stop soundfile playback.\n     *\n     * @method stop\n     * @for p5.SoundFile\n     * @param {Number} [startTime] (optional) schedule event to occur\n     *                             in seconds from now\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop(timeFromNow) {\n      var time = timeFromNow || 0;\n\n      if (this.mode === 'sustain' || this.mode === 'untildone') {\n        this.stopAll(time);\n        this._playing = false;\n        this.pauseTime = 0;\n        this._paused = false;\n      } else if (this.buffer && this.bufferSourceNode) {\n        var now = main.audiocontext.currentTime;\n        var t = time || 0;\n        this.pauseTime = 0;\n        this.bufferSourceNode.stop(now + t);\n\n        this._counterNode.stop(now + t);\n\n        this._playing = false;\n        this._paused = false;\n      }\n    }\n    /**\n     *  Stop playback on all of this soundfile's sources.\n     *  @private\n     */\n\n  }, {\n    key: \"stopAll\",\n    value: function stopAll(_time) {\n      var now = main.audiocontext.currentTime;\n      var time = _time || 0;\n\n      if (this.buffer && this.bufferSourceNode) {\n        for (var i in this.bufferSourceNodes) {\n          var bufferSourceNode = this.bufferSourceNodes[i];\n\n          if (bufferSourceNode) {\n            try {\n              bufferSourceNode.stop(now + time);\n            } catch (e) {\n            }\n          }\n        }\n\n        this._counterNode.stop(now + time);\n      }\n    }\n  }, {\n    key: \"getVolume\",\n    value: function getVolume() {\n      return this.output.gain.value;\n    }\n    /**\n     * Set the stereo panning of a p5.sound object to\n     * a floating point number between -1.0 (left) and 1.0 (right).\n     * Default is 0.0 (center).\n     *\n     * @method pan\n     * @for p5.SoundFile\n     * @param {Number} [panValue]     Set the stereo panner\n     * @param {Number} [timeFromNow]  schedule this event to happen\n     *                                 seconds from now\n     * @example\n     * <div><code>\n     *  let ballX = 0;\n     *  let soundFile;\n     *\n     *  function preload() {\n     *    soundFormats('ogg', 'mp3');\n     *    soundFile = loadSound('assets/beatbox.mp3');\n     *  }\n     *\n     *  function draw() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *    background(220);\n     *    ballX = constrain(mouseX, 0, width);\n     *    ellipse(ballX, height/2, 20, 20);\n     *  }\n     *\n     *  function canvasPressed(){\n     *    // map the ball's x location to a panning degree\n     *    // between -1.0 (left) and 1.0 (right)\n     *    let panning = map(ballX, 0., width,-1.0, 1.0);\n     *    soundFile.pan(panning);\n     *    soundFile.play();\n     *  }\n     *  </div></code>\n     */\n\n  }, {\n    key: \"pan\",\n    value: function pan(pval, tFromNow) {\n      this.panPosition = pval;\n      this.panner.pan(pval, tFromNow);\n    }\n    /**\n     * Returns the current stereo pan position (-1.0 to 1.0)\n     *\n     * @method getPan\n     * @for p5.SoundFile\n     * @return {Number} Returns the stereo pan setting of the Oscillator\n     *                          as a number between -1.0 (left) and 1.0 (right).\n     *                          0.0 is center and default.\n     */\n\n  }, {\n    key: \"getPan\",\n    value: function getPan() {\n      return this.panPosition;\n    }\n    /**\n     *  Set the playback rate of a sound file. Will change the speed and the pitch.\n     *  Values less than zero will reverse the audio buffer.\n     *\n     *  @method rate\n     *  @for p5.SoundFile\n     *  @param {Number} [playbackRate]     Set the playback rate. 1.0 is normal,\n     *                                     .5 is half-speed, 2.0 is twice as fast.\n     *                                     Values less than zero play backwards.\n     *  @example\n     *  <div><code>\n     *  let mySound;\n     *\n     *  function preload() {\n     *    mySound = loadSound('assets/Damscray_DancingTiger.mp3');\n     *  }\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *  }\n     *  function canvasPressed() {\n     *    mySound.loop();\n     *  }\n     *  function mouseReleased() {\n     *    mySound.pause();\n     *  }\n     *  function draw() {\n     *    background(220);\n     *\n     *    // Set the rate to a range between 0.1 and 4\n     *    // Changing the rate also alters the pitch\n     *    let playbackRate = map(mouseY, 0.1, height, 2, 0);\n     *    playbackRate = constrain(playbackRate, 0.01, 4);\n     *    mySound.rate(playbackRate);\n     *\n     *    line(0, mouseY, width, mouseY);\n     *    text('rate: ' + round(playbackRate * 100) + '%', 10, 20);\n     *  }\n     *\n     * </code>\n     * </div>\n     *\n     */\n\n  }, {\n    key: \"rate\",\n    value: function rate(playbackRate) {\n      var reverse = false;\n\n      if (typeof playbackRate === 'undefined') {\n        return this.playbackRate;\n      }\n\n      this.playbackRate = playbackRate;\n\n      if (playbackRate === 0) {\n        playbackRate = 0.0000000000001;\n      } else if (playbackRate < 0 && !this.reversed) {\n        playbackRate = Math.abs(playbackRate);\n        reverse = true;\n      } else if (playbackRate > 0 && this.reversed) {\n        reverse = true;\n      }\n\n      if (this.bufferSourceNode) {\n        var now = main.audiocontext.currentTime;\n        this.bufferSourceNode.playbackRate.cancelScheduledValues(now);\n        this.bufferSourceNode.playbackRate.linearRampToValueAtTime(Math.abs(playbackRate), now);\n\n        this._counterNode.playbackRate.cancelScheduledValues(now);\n\n        this._counterNode.playbackRate.linearRampToValueAtTime(Math.abs(playbackRate), now);\n      }\n\n      if (reverse) {\n        this.reverseBuffer();\n      }\n\n      return this.playbackRate;\n    } \n\n  }, {\n    key: \"setPitch\",\n    value: function setPitch(num) {\n      var newPlaybackRate = midiToFreq(num) / midiToFreq(60);\n      this.rate(newPlaybackRate);\n    }\n  }, {\n    key: \"getPlaybackRate\",\n    value: function getPlaybackRate() {\n      return this.playbackRate;\n    }\n    /**\n     *  Multiply the output volume (amplitude) of a sound file\n     *  between 0.0 (silence) and 1.0 (full volume).\n     *  1.0 is the maximum amplitude of a digital sound, so multiplying\n     *  by greater than 1.0 may cause digital distortion. To\n     *  fade, provide a <code>rampTime</code> parameter. For more\n     *  complex fades, see the Envelope class.\n     *\n     *  Alternately, you can pass in a signal source such as an\n     *  oscillator to modulate the amplitude with an audio signal.\n     *\n     *  @method  setVolume\n     *  @for p5.SoundFile\n     *  @param {Number|Object} volume  Volume (amplitude) between 0.0\n     *                                     and 1.0 or modulating signal/oscillator\n     *  @param {Number} [rampTime]  Fade for t seconds\n     *  @param {Number} [timeFromNow]  Schedule this event to happen at\n     *                                 t seconds in the future\n     */\n\n  }, {\n    key: \"setVolume\",\n    value: function setVolume(vol, _rampTime, _tFromNow) {\n      if (typeof vol === 'number') {\n        var rampTime = _rampTime || 0;\n        var tFromNow = _tFromNow || 0;\n        var now = main.audiocontext.currentTime;\n        var currentVol = this.output.gain.value;\n        this.output.gain.cancelScheduledValues(now + tFromNow);\n        this.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow);\n        this.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);\n      } else if (vol) {\n        vol.connect(this.output.gain);\n      } else {\n        return this.output.gain;\n      }\n    }\n    /**\n     * Returns the duration of a sound file in seconds.\n     *\n     * @method duration\n     * @for p5.SoundFile\n     * @return {Number} The duration of the soundFile in seconds.\n     */\n\n  }, {\n    key: \"duration\",\n    value: function duration() {\n      if (this.buffer) {\n        return this.buffer.duration;\n      } else {\n        return 0;\n      }\n    }\n    /**\n     * Return the current position of the p5.SoundFile playhead, in seconds.\n     * Time is relative to the normal buffer direction, so if `reverseBuffer`\n     * has been called, currentTime will count backwards.\n     *\n     * @method currentTime\n     * @for p5.SoundFile\n     * @return {Number}   currentTime of the soundFile in seconds.\n     */\n\n  }, {\n    key: \"currentTime\",\n    value: function currentTime() {\n      return this.reversed ? Math.abs(this._lastPos - this.buffer.length) / soundfile_ac.sampleRate : this._lastPos / soundfile_ac.sampleRate;\n    }\n    /**\n     * Move the playhead of a soundfile that is currently playing to a\n     * new position and a new duration, in seconds.\n     * If none are given, will reset the file to play entire duration\n     * from start to finish. To set the position of a soundfile that is\n     * not currently playing, use the `play` or `loop` methods.\n     *\n     * @method jump\n     * @for p5.SoundFile\n     * @param {Number} cueTime    cueTime of the soundFile in seconds.\n     * @param {Number} duration    duration in seconds.\n     */\n\n  }, {\n    key: \"jump\",\n    value: function jump(cueTime, duration) {\n      if (cueTime < 0 || cueTime > this.buffer.duration) {\n        throw 'jump time out of range';\n      }\n\n      if (duration > this.buffer.duration - cueTime) {\n        throw 'end time out of range';\n      }\n\n      var cTime = cueTime || 0;\n      var dur = duration || undefined;\n\n      if (this.isPlaying()) {\n        this.stop(0);\n        this.play(0, this.playbackRate, this.output.gain.value, cTime, dur);\n      }\n    }\n    /**\n     * Return the number of channels in a sound file.\n     * For example, Mono = 1, Stereo = 2.\n     *\n     * @method channels\n     * @for p5.SoundFile\n     * @return {Number} [channels]\n     */\n\n  }, {\n    key: \"channels\",\n    value: function channels() {\n      return this.buffer.numberOfChannels;\n    }\n    /**\n     * Return the sample rate of the sound file.\n     *\n     * @method sampleRate\n     * @for p5.SoundFile\n     * @return {Number} [sampleRate]\n     */\n\n  }, {\n    key: \"sampleRate\",\n    value: function sampleRate() {\n      return this.buffer.sampleRate;\n    }\n    /**\n     * Return the number of samples in a sound file.\n     * Equal to sampleRate * duration.\n     *\n     * @method frames\n     * @for p5.SoundFile\n     * @return {Number} [sampleCount]\n     */\n\n  }, {\n    key: \"frames\",\n    value: function frames() {\n      return this.buffer.length;\n    }\n    /**\n     * Returns an array of amplitude peaks in a p5.SoundFile that can be\n     * used to draw a static waveform. Scans through the p5.SoundFile's\n     * audio buffer to find the greatest amplitudes. Accepts one\n     * parameter, 'length', which determines size of the array.\n     * Larger arrays result in more precise waveform visualizations.\n     *\n     * Inspired by Wavesurfer.js.\n     *\n     * @method  getPeaks\n     * @for p5.SoundFile\n     * @params {Number} [length] length is the size of the returned array.\n     *                          Larger length results in more precision.\n     *                          Defaults to 5*width of the browser window.\n     * @returns {Float32Array} Array of peaks.\n     */\n\n  }, {\n    key: \"getPeaks\",\n    value: function getPeaks(length) {\n      if (this.buffer) {\n        if (!length) {\n          length = window.width * 5;\n        }\n\n        if (this.buffer) {\n          var buffer = this.buffer;\n          var sampleSize = buffer.length / length;\n          var sampleStep = ~~(sampleSize / 10) || 1;\n          var channels = buffer.numberOfChannels;\n          var peaks = new Float32Array(Math.round(length));\n\n          for (var c = 0; c < channels; c++) {\n            var chan = buffer.getChannelData(c);\n\n            for (var i = 0; i < length; i++) {\n              var start = ~~(i * sampleSize);\n              var end = ~~(start + sampleSize);\n              var max = 0;\n\n              for (var j = start; j < end; j += sampleStep) {\n                var value = chan[j];\n\n                if (value > max) {\n                  max = value; \n                } else if (-value > max) {\n                  max = value;\n                }\n              }\n\n              if (c === 0 || Math.abs(max) > peaks[i]) {\n                peaks[i] = max;\n              }\n            }\n          }\n\n          return peaks;\n        }\n      } else {\n        throw 'Cannot load peaks yet, buffer is not loaded';\n      }\n    }\n    /**\n     *  Reverses the p5.SoundFile's buffer source.\n     *  Playback must be handled separately (see example).\n     *\n     *  @method  reverseBuffer\n     *  @for p5.SoundFile\n     *  @example\n     *  <div><code>\n     *  let drum;\n     *  function preload() {\n     *    drum = loadSound('assets/drum.mp3');\n     *  }\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *    background(220);\n     *    text('tap to play', 20, 20);\n     *  }\n     *\n     *  function canvasPressed() {\n     *    drum.stop();\n     *    drum.reverseBuffer();\n     *    drum.play();\n     *  }\n     * </code>\n     * </div>\n     */\n\n  }, {\n    key: \"reverseBuffer\",\n    value: function reverseBuffer() {\n      if (this.buffer) {\n        var currentPos = this._lastPos / soundfile_ac.sampleRate;\n        var curVol = this.getVolume();\n        this.setVolume(0, 0.001);\n        var numChannels = this.buffer.numberOfChannels;\n\n        for (var i = 0; i < numChannels; i++) {\n          this.buffer.getChannelData(i).reverse();\n        } \n\n\n        this.reversed = !this.reversed;\n\n        if (this.isPlaying() && currentPos) {\n          this.jump(this.duration() - currentPos);\n        }\n\n        this.setVolume(curVol, 0.001);\n      } else {\n        throw 'SoundFile is not done loading';\n      }\n    }\n    /**\n     *  Schedule an event to be called when the soundfile\n     *  reaches the end of a buffer. If the soundfile is\n     *  playing through once, this will be called when it\n     *  ends. If it is looping, it will be called when\n     *  stop is called.\n     *\n     *  @method  onended\n     *  @for p5.SoundFile\n     *  @param  {Function} callback function to call when the\n     *                              soundfile has ended.\n     */\n\n  }, {\n    key: \"onended\",\n    value: function onended(callback) {\n      this._onended = callback;\n      return this;\n    }\n  }, {\n    key: \"add\",\n    value: function add() {\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var now = main.audiocontext.currentTime; \n\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n      this.stop(now);\n\n      if (this.buffer && this.bufferSourceNode) {\n        for (var i = 0; i < this.bufferSourceNodes.length - 1; i++) {\n          if (this.bufferSourceNodes[i] !== null) {\n            this.bufferSourceNodes[i].disconnect();\n\n            try {\n              this.bufferSourceNodes[i].stop(now);\n            } catch (e) {\n              console.warn('no buffer source node to dispose');\n            }\n\n            this.bufferSourceNodes[i] = null;\n          }\n        }\n\n        if (this.isPlaying()) {\n          try {\n            this._counterNode.stop(now);\n          } catch (e) {\n            console.log(e);\n          }\n\n          this._counterNode = null;\n        }\n      }\n\n      if (this.output) {\n        this.output.disconnect();\n        this.output = null;\n      }\n\n      if (this.panner) {\n        this.panner.disconnect();\n        this.panner = null;\n      }\n    }\n    /**\n     * Connects the output of a p5sound object to input of another\n     * p5.sound object. For example, you may connect a p5.SoundFile to an\n     * FFT or an Effect. If no parameter is given, it will connect to\n     * the main output. Most p5sound objects connect to the master\n     * output when they are created.\n     *\n     * @method connect\n     * @for p5.SoundFile\n     * @param {Object} [object] Audio object that accepts an input\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      if (!unit) {\n        this.panner.connect(main.input);\n      } else {\n        if (unit.hasOwnProperty('input')) {\n          this.panner.connect(unit.input);\n        } else {\n          this.panner.connect(unit);\n        }\n      }\n    }\n    /**\n     * Disconnects the output of this p5sound object.\n     *\n     * @method disconnect\n     * @for p5.SoundFile\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.panner) {\n        this.panner.disconnect();\n      }\n    }\n    /**\n     */\n\n  }, {\n    key: \"getLevel\",\n    value: function getLevel() {\n      console.warn('p5.SoundFile.getLevel has been removed from the library. Use p5.Amplitude instead');\n    }\n    /**\n     *  Reset the source for this SoundFile to a\n     *  new path (URL).\n     *\n     *  @method  setPath\n     *  @for p5.SoundFile\n     *  @param {String}   path     path to audio file\n     *  @param {Function} callback Callback\n     */\n\n  }, {\n    key: \"setPath\",\n    value: function setPath(p, callback) {\n      var path = p5.prototype._checkFileFormats(p);\n\n      this.url = path;\n      this.load(callback);\n    }\n    /**\n     *  Replace the current Audio Buffer with a new Buffer.\n     *\n     *  @method setBuffer\n     *  @for p5.SoundFile\n     *  @param {Array} buf Array of Float32 Array(s). 2 Float32 Arrays\n     *                     will create a stereo source. 1 will create\n     *                     a mono source.\n     */\n\n  }, {\n    key: \"setBuffer\",\n    value: function setBuffer(buf) {\n      var numChannels = buf.length;\n      var size = buf[0].length;\n      var newBuffer = soundfile_ac.createBuffer(numChannels, size, soundfile_ac.sampleRate);\n\n      if (!(buf[0] instanceof Float32Array)) {\n        buf[0] = new Float32Array(buf[0]);\n      }\n\n      for (var channelNum = 0; channelNum < numChannels; channelNum++) {\n        var channel = newBuffer.getChannelData(channelNum);\n        channel.set(buf[channelNum]);\n      }\n\n      this.buffer = newBuffer; \n\n      this.panner.inputChannels(numChannels);\n    } \n\n  }, {\n    key: \"_initCounterNode\",\n    value: function _initCounterNode() {\n      var _this = this;\n\n      var self = this;\n      var now = soundfile_ac.currentTime;\n      var cNode = soundfile_ac.createBufferSource();\n      var workletBufferSize = safeBufferSize(256); \n\n      if (self._workletNode) {\n        self._workletNode.disconnect();\n\n        delete self._workletNode;\n      }\n\n      self._workletNode = new AudioWorkletNode(soundfile_ac, processorNames_default.a.soundFileProcessor, {\n        processorOptions: {\n          bufferSize: workletBufferSize\n        }\n      });\n\n      self._workletNode.port.onmessage = function (event) {\n        if (event.data.name === 'position') {\n          if (event.data.position === 0) {\n            return;\n          }\n\n          _this._lastPos = event.data.position; \n\n          _this._onTimeUpdate(self._lastPos);\n        }\n      }; \n\n\n      cNode.buffer = _createCounterBuffer(self.buffer);\n      cNode.playbackRate.setValueAtTime(self.playbackRate, now);\n      cNode.connect(self._workletNode);\n\n      self._workletNode.connect(p5.soundOut._silentNode);\n\n      return cNode;\n    } \n\n  }, {\n    key: \"_initSourceNode\",\n    value: function _initSourceNode() {\n      var bufferSourceNode = soundfile_ac.createBufferSource();\n      bufferSourceNode.buffer = this.buffer;\n      bufferSourceNode.playbackRate.value = this.playbackRate;\n      bufferSourceNode.connect(this.output);\n      return bufferSourceNode;\n    }\n  }, {\n    key: \"processPeaks\",\n    value: function processPeaks(callback, _initThreshold, _minThreshold, _minPeaks) {\n      console.warn('processPeaks is deprecated');\n    }\n    /**\n     *  Schedule events to trigger every time a MediaElement\n     *  (audio/video) reaches a playback cue point.\n     *\n     *  Accepts a callback function, a time (in seconds) at which to trigger\n     *  the callback, and an optional parameter for the callback.\n     *\n     *  Time will be passed as the first parameter to the callback function,\n     *  and param will be the second parameter.\n     *\n     *\n     *  @method  addCue\n     *  @for p5.SoundFile\n     *  @param {Number}   time     Time in seconds, relative to this media\n     *                             element's playback. For example, to trigger\n     *                             an event every time playback reaches two\n     *                             seconds, pass in the number 2. This will be\n     *                             passed as the first parameter to\n     *                             the callback function.\n     *  @param {Function} callback Name of a function that will be\n     *                             called at the given time. The callback will\n     *                             receive time and (optionally) param as its\n     *                             two parameters.\n     *  @param {Object} [value]    An object to be passed as the\n     *                             second parameter to the\n     *                             callback function.\n     *  @return {Number} id ID of this cue,\n     *                      useful for removeCue(id)\n     *  @example\n     *  <div><code>\n     *  let mySound;\n     *  function preload() {\n     *    mySound = loadSound('assets/Damscray_DancingTiger.mp3');\n     *  }\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *    background(220);\n     *    text('tap to play', 10, 20);\n     *\n     *    // schedule calls to changeText\n     *    mySound.addCue(0, changeText, \"hello\" );\n     *    mySound.addCue(0.5, changeText, \"hello,\" );\n     *    mySound.addCue(1, changeText, \"hello, p5!\");\n     *    mySound.addCue(1.5, changeText, \"hello, p5!!\");\n     *    mySound.addCue(2, changeText, \"hello, p5!!!!!\");\n     *  }\n     *\n     *  function changeText(val) {\n     *    background(220);\n     *    text(val, 10, 20);\n     *  }\n     *\n     *  function canvasPressed() {\n     *    mySound.play();\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"addCue\",\n    value: function addCue(time, callback, val) {\n      var id = this._cueIDCounter++;\n      var cue = new Cue(callback, time, id, val);\n\n      this._cues.push(cue); \n\n\n      return id;\n    }\n    /**\n     *  Remove a callback based on its ID. The ID is returned by the\n     *  addCue method.\n     *\n     *  @method removeCue\n     *  @for p5.SoundFile\n     *  @param  {Number} id ID of the cue, as returned by addCue\n     */\n\n  }, {\n    key: \"removeCue\",\n    value: function removeCue(id) {\n      var cueLength = this._cues.length;\n\n      for (var i = 0; i < cueLength; i++) {\n        var cue = this._cues[i];\n\n        if (cue.id === id) {\n          this._cues.splice(i, 1);\n\n          break;\n        }\n      }\n\n      if (this._cues.length === 0) {\n      }\n    }\n    /**\n     *  Remove all of the callbacks that had originally been scheduled\n     *  via the addCue method.\n     *\n     *  @method  clearCues\n     */\n\n  }, {\n    key: \"clearCues\",\n    value: function clearCues() {\n      this._cues = []; \n    } \n\n  }, {\n    key: \"_onTimeUpdate\",\n    value: function _onTimeUpdate(position) {\n      var playbackTime = position / this.buffer.sampleRate;\n      var cueLength = this._cues.length;\n\n      for (var i = 0; i < cueLength; i++) {\n        var cue = this._cues[i];\n        var callbackTime = cue.time;\n        var val = cue.val;\n        var leftLimit = this._prevUpdateTime || 0;\n        var rightLimit = playbackTime;\n\n        if (leftLimit <= callbackTime && callbackTime <= rightLimit) {\n          cue.callback(val);\n        }\n      }\n\n      this._prevUpdateTime = playbackTime;\n    }\n    /**\n     * Save a p5.SoundFile as a .wav file. The browser will prompt the user\n     * to download the file to their device. To upload a file to a server, see\n     * <a href=\"/reference/#/p5.SoundFile/getBlob\">getBlob</a>\n     *\n     * @method save\n     * @for p5.SoundFile\n     * @param  {String} [fileName]      name of the resulting .wav file.\n     * @example\n     *  <div><code>\n     *  let mySound;\n     *  function preload() {\n     *    mySound = loadSound('assets/doorbell.mp3');\n     *  }\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(canvasPressed);\n     *    background(220);\n     *    text('tap to download', 10, 20);\n     *  }\n     *\n     *  function canvasPressed() {\n     *    mySound.save('my cool filename');\n     *  }\n     * </code></div>\n     */\n\n  }, {\n    key: \"save\",\n    value: function save(fileName) {\n      p5.prototype.saveSound(this, fileName, 'wav');\n    }\n    /**\n     * This method is useful for sending a SoundFile to a server. It returns the\n     * .wav-encoded audio data as a \"<a target=\"_blank\" title=\"Blob reference at\n     * MDN\" href=\"https://developer.mozilla.org/en-US/docs/Web/API/Blob\">Blob</a>\".\n     * A Blob is a file-like data object that can be uploaded to a server\n     * with an <a href=\"/reference/#/p5/httpDo\">http</a> request. We'll\n     * use the `httpDo` options object to send a POST request with some\n     * specific options: we encode the request as `multipart/form-data`,\n     * and attach the blob as one of the form values using `FormData`.\n     *\n     *\n     * @method getBlob\n     * @for p5.SoundFile\n     * @returns {Blob} A file-like data object\n     * @example\n     *  <div><code>\n     *  function preload() {\n     *    mySound = loadSound('assets/doorbell.mp3');\n     *  }\n     *\n     *  function setup() {\n     *    noCanvas();\n     *    let soundBlob = mySound.getBlob();\n     *\n     *    // Now we can send the blob to a server...\n     *    let serverUrl = 'https://jsonplaceholder.typicode.com/posts';\n     *    let httpRequestOptions = {\n     *      method: 'POST',\n     *      body: new FormData().append('soundBlob', soundBlob),\n     *      headers: new Headers({\n     *        'Content-Type': 'multipart/form-data'\n     *      })\n     *    };\n     *    httpDo(serverUrl, httpRequestOptions);\n     *\n     *    // We can also create an `ObjectURL` pointing to the Blob\n     *    let blobUrl = URL.createObjectURL(soundBlob);\n     *\n     *    // The `<Audio>` Element accepts Object URL's\n     *    createAudio(blobUrl).showControls();\n     *\n     *    createDiv();\n     *\n     *    // The ObjectURL exists as long as this tab is open\n     *    let input = createInput(blobUrl);\n     *    input.attribute('readonly', true);\n     *    input.mouseClicked(function() { input.elt.select() });\n     *  }\n     *\n     * </code></div>\n     */\n\n  }, {\n    key: \"getBlob\",\n    value: function getBlob() {\n      var dataView = convertToWav(this.buffer);\n      return new Blob([dataView], {\n        type: 'audio/wav'\n      });\n    }\n  }]);\n\n  return SoundFile;\n}();\n/**\n *  loadSound() returns a new p5.SoundFile from a specified\n *  path. If called during preload(), the p5.SoundFile will be ready\n *  to play in time for setup() and draw(). If called outside of\n *  preload, the p5.SoundFile will not be ready immediately, so\n *  loadSound accepts a callback as the second parameter. Using a\n *  <a href=\"https://github.com/processing/p5.js/wiki/Local-server\">\n *  local server</a> is recommended when loading external files.\n *\n *  @method loadSound\n *  @for p5\n *  @param  {String|Array}   path     Path to the sound file, or an array with\n *                                    paths to soundfiles in multiple formats\n *                                    i.e. ['sound.ogg', 'sound.mp3'].\n *                                    Alternately, accepts an object: either\n *                                    from the HTML5 File API, or a p5.File.\n *  @param {Function} [successCallback]   Name of a function to call once file loads\n *  @param {Function} [errorCallback]   Name of a function to call if there is\n *                                      an error loading the file.\n *  @param {Function} [whileLoading] Name of a function to call while file is loading.\n *                                 This function will receive the percentage loaded\n *                                 so far, from 0.0 to 1.0.\n *  @return {SoundFile}            Returns a p5.SoundFile\n *  @example\n *  <div><code>\n *  let mySound;\n *  function preload() {\n *    soundFormats('mp3', 'ogg');\n *    mySound = loadSound('assets/doorbell');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(canvasPressed);\n *    background(220);\n *    text('tap here to play', 10, 20);\n *  }\n *\n *  function canvasPressed() {\n *    // playing a sound file on a user gesture\n *    // is equivalent to `userStartAudio()`\n *    mySound.play();\n *  }\n *  </code></div>\n */\n\n\nfunction loadSound(path, callback, onerror, whileLoading) {\n  if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {\n    window.alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');\n  }\n\n  var self = this;\n  var s = new soundfile_SoundFile(path, function () {\n    if (typeof callback === 'function') {\n      callback.apply(self, arguments);\n    }\n\n    if (typeof self._decrementPreload === 'function') {\n      self._decrementPreload();\n    }\n  }, onerror, whileLoading);\n  return s;\n}\n\n var soundfile = (soundfile_SoundFile);\n\nfunction amplitude_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction amplitude_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction amplitude_createClass(Constructor, protoProps, staticProps) { if (protoProps) amplitude_defineProperties(Constructor.prototype, protoProps); if (staticProps) amplitude_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n\n/**\n *  Amplitude measures volume between 0.0 and 1.0.\n *  Listens to all p5sound by default, or use setInput()\n *  to listen to a specific sound source. Accepts an optional\n *  smoothing value, which defaults to 0.\n *\n *  @class p5.Amplitude\n *  @constructor\n *  @param {Number} [smoothing] between 0.0 and .999 to smooth\n *                             amplitude readings (defaults to 0)\n *  @example\n *  <div><code>\n *  let sound, amplitude;\n *\n *  function preload(){\n *    sound = loadSound('assets/beat.mp3');\n *  }\n *  function setup() {\n *    let cnv = createCanvas(100,100);\n *    cnv.mouseClicked(togglePlay);\n *    amplitude = new p5.Amplitude();\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap to play', 20, 20);\n *\n *    let level = amplitude.getLevel();\n *    let size = map(level, 0, 1, 0, 200);\n *    ellipse(width/2, height/2, size, size);\n *  }\n *\n *  function togglePlay() {\n *    if (sound.isPlaying() ){\n *      sound.pause();\n *    } else {\n *      sound.loop();\n *\t\tamplitude = new p5.Amplitude();\n *\t\tamplitude.setInput(sound);\n *    }\n *  }\n *\n *  </code></div>\n */\n\nvar amplitude_Amplitude =\nfunction () {\n  function Amplitude(smoothing) {\n    amplitude_classCallCheck(this, Amplitude);\n\n    this.bufferSize = safeBufferSize(2048); \n\n    this.audiocontext = main.audiocontext;\n    this._workletNode = new AudioWorkletNode(this.audiocontext, processorNames_default.a.amplitudeProcessor, {\n      outputChannelCount: [1],\n      parameterData: {\n        smoothing: smoothing || 0\n      },\n      processorOptions: {\n        normalize: false,\n        smoothing: smoothing || 0,\n        numInputChannels: 2,\n        bufferSize: this.bufferSize\n      }\n    });\n\n    this._workletNode.port.onmessage = function (event) {\n      if (event.data.name === 'amplitude') {\n        this.volume = event.data.volume;\n        this.volNorm = event.data.volNorm;\n        this.stereoVol = event.data.stereoVol;\n        this.stereoVolNorm = event.data.stereoVolNorm;\n      }\n    }.bind(this); \n\n\n    this.input = this._workletNode;\n    this.output = this.audiocontext.createGain(); \n\n    this.volume = 0;\n    this.volNorm = 0;\n    this.stereoVol = [0, 0];\n    this.stereoVolNorm = [0, 0];\n    this.normalize = false;\n\n    this._workletNode.connect(this.output);\n\n    this.output.gain.value = 0; \n\n    this.output.connect(this.audiocontext.destination); \n\n    main.meter.connect(this._workletNode); \n\n    main.soundArray.push(this);\n  }\n  /**\n   *  Connects to the p5sound instance (main output) by default.\n   *  Optionally, you can pass in a specific source (i.e. a soundfile).\n   *\n   *  @method setInput\n   *  @for p5.Amplitude\n   *  @param {soundObject|undefined} [snd] set the sound source\n   *                                       (optional, defaults to\n   *                                       main output)\n   *  @param {Number|undefined} [smoothing] a range between 0.0 and 1.0\n   *                                        to smooth amplitude readings\n   *  @example\n   *  <div><code>\n   *  function preload(){\n   *    sound1 = loadSound('assets/beat.mp3');\n   *    sound2 = loadSound('assets/drum.mp3');\n   *  }\n   *  function setup(){\n   *    cnv = createCanvas(100, 100);\n   *    cnv.mouseClicked(toggleSound);\n   *\n   *    amplitude = new p5.Amplitude();\n   *    amplitude.setInput(sound2);\n   *  }\n   *\n   *  function draw() {\n   *    background(220);\n   *    text('tap to play', 20, 20);\n   *\n   *    let level = amplitude.getLevel();\n   *    let size = map(level, 0, 1, 0, 200);\n   *    ellipse(width/2, height/2, size, size);\n   *  }\n   *\n   *  function toggleSound(){\n   *    if (sound1.isPlaying() && sound2.isPlaying()) {\n   *      sound1.stop();\n   *      sound2.stop();\n   *    } else {\n   *      sound1.play();\n   *      sound2.play();\n   *    }\n   *  }\n   *  </code></div>\n   */\n\n\n  amplitude_createClass(Amplitude, [{\n    key: \"setInput\",\n    value: function setInput(source, smoothing) {\n      main.meter.disconnect();\n\n      if (smoothing) {\n        this._workletNode.parameters.get('smoothing').value = smoothing;\n      } \n\n\n      if (source == null) {\n        console.log('Amplitude input source is not ready! Connecting to main output instead');\n        main.meter.connect(this._workletNode);\n      } \n      else if (source) {\n          source.connect(this._workletNode);\n\n          this._workletNode.disconnect();\n\n          this._workletNode.connect(this.output);\n        } \n        else {\n            main.meter.connect(this._workletNode);\n          }\n    }\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      if (unit) {\n        if (unit.hasOwnProperty('input')) {\n          this.output.connect(unit.input);\n        } else {\n          this.output.connect(unit);\n        }\n      } else {\n        this.output.connect(this.panner.connect(main.input));\n      }\n    }\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.output) {\n        this.output.disconnect();\n      }\n    }\n    /**\n     *  Returns a single Amplitude reading at the moment it is called.\n     *  For continuous readings, run in the draw loop.\n     *\n     *  @method getLevel\n     *  @for p5.Amplitude\n     *  @param {Number} [channel] Optionally return only channel 0 (left) or 1 (right)\n     *  @return {Number}       Amplitude as a number between 0.0 and 1.0\n     *  @example\n     *  <div><code>\n     *  function preload(){\n     *    sound = loadSound('assets/beat.mp3');\n     *  }\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mouseClicked(toggleSound);\n     *    amplitude = new p5.Amplitude();\n     *  }\n     *\n     *  function draw() {\n     *    background(220, 150);\n     *    textAlign(CENTER);\n     *    text('tap to play', width/2, 20);\n     *\n     *    let level = amplitude.getLevel();\n     *    let size = map(level, 0, 1, 0, 200);\n     *    ellipse(width/2, height/2, size, size);\n     *  }\n     *\n     *  function toggleSound(){\n     *    if (sound.isPlaying()) {\n     *      sound.stop();\n     *    } else {\n     *      sound.play();\n     *    }\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"getLevel\",\n    value: function getLevel(channel) {\n      if (typeof channel !== 'undefined') {\n        if (this.normalize) {\n          return this.stereoVolNorm[channel];\n        } else {\n          return this.stereoVol[channel];\n        }\n      } else if (this.normalize) {\n        return this.volNorm;\n      } else {\n        return this.volume;\n      }\n    }\n    /**\n     * Determines whether the results of Amplitude.process() will be\n     * Normalized. To normalize, Amplitude finds the difference the\n     * loudest reading it has processed and the maximum amplitude of\n     * 1.0. Amplitude adds this difference to all values to produce\n     * results that will reliably map between 0.0 and 1.0. However,\n     * if a louder moment occurs, the amount that Normalize adds to\n     * all the values will change. Accepts an optional boolean parameter\n     * (true or false). Normalizing is off by default.\n     *\n     * @method toggleNormalize\n     * @for p5.Amplitude\n     * @param {boolean} [boolean] set normalize to true (1) or false (0)\n     */\n\n  }, {\n    key: \"toggleNormalize\",\n    value: function toggleNormalize(bool) {\n      if (typeof bool === 'boolean') {\n        this.normalize = bool;\n      } else {\n        this.normalize = !this.normalize;\n      }\n\n      this._workletNode.port.postMessage({\n        name: 'toggleNormalize',\n        normalize: this.normalize\n      });\n    }\n    /**\n     *  Smooth Amplitude analysis by averaging with the last analysis\n     *  frame. Off by default.\n     *\n     *  @method smooth\n     *  @for p5.Amplitude\n     *  @param {Number} set smoothing from 0.0 <= 1\n     */\n\n  }, {\n    key: \"smooth\",\n    value: function smooth(s) {\n      if (s >= 0 && s < 1) {\n        this._workletNode.port.postMessage({\n          name: 'smoothing',\n          smoothing: s\n        });\n      } else {\n        console.log('Error: smoothing must be between 0 and 1');\n      }\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n\n      if (this.input) {\n        this.input.disconnect();\n        delete this.input;\n      }\n\n      if (this.output) {\n        this.output.disconnect();\n        delete this.output;\n      }\n\n      this._workletNode.disconnect();\n\n      delete this._workletNode;\n    }\n  }]);\n\n  return Amplitude;\n}();\n\n var amplitude = (amplitude_Amplitude);\nfunction fft_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction fft_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction fft_createClass(Constructor, protoProps, staticProps) { if (protoProps) fft_defineProperties(Constructor.prototype, protoProps); if (staticProps) fft_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n/**\n *  <p>FFT (Fast Fourier Transform) is an analysis algorithm that\n *  isolates individual\n *  <a href=\"https://en.wikipedia.org/wiki/Audio_frequency\">\n *  audio frequencies</a> within a waveform.</p>\n *\n *  <p>Once instantiated, a p5.FFT object can return an array based on\n *  two types of analyses: <br>  <code>FFT.waveform()</code> computes\n *  amplitude values along the time domain. The array indices correspond\n *  to samples across a brief moment in time. Each value represents\n *  amplitude of the waveform at that sample of time.<br>\n *   <code>FFT.analyze() </code> computes amplitude values along the\n *  frequency domain. The array indices correspond to frequencies (i.e.\n *  pitches), from the lowest to the highest that humans can hear. Each\n *  value represents amplitude at that slice of the frequency spectrum.\n *  Use with <code>getEnergy()</code> to measure amplitude at specific\n *  frequencies, or within a range of frequencies. </p>\n *\n *  <p>FFT analyzes a very short snapshot of sound called a sample\n *  buffer. It returns an array of amplitude measurements, referred\n *  to as <code>bins</code>. The array is 1024 bins long by default.\n *  You can change the bin array length, but it must be a power of 2\n *  between 16 and 1024 in order for the FFT algorithm to function\n *  correctly. The actual size of the FFT buffer is twice the\n *  number of bins, so given a standard sample rate, the buffer is\n *  2048/44100 seconds long.</p>\n *\n *\n *  @class p5.FFT\n *  @constructor\n *  @param {Number} [smoothing]   Smooth results of Freq Spectrum.\n *                                0.0 < smoothing < 1.0.\n *                                Defaults to 0.8.\n *  @param {Number} [bins]    Length of resulting array.\n *                            Must be a power of two between\n *                            16 and 1024. Defaults to 1024.\n *  @example\n *  <div><code>\n *  function preload(){\n *    sound = loadSound('assets/Damscray_DancingTiger.mp3');\n *  }\n *\n *  function setup(){\n *    let cnv = createCanvas(100,100);\n *    cnv.mouseClicked(togglePlay);\n *    fft = new p5.FFT();\n *    sound.amp(0.2);\n *  }\n *\n *  function draw(){\n *    background(220);\n *\n *    let spectrum = fft.analyze();\n *    noStroke();\n *    fill(255, 0, 255);\n *    for (let i = 0; i< spectrum.length; i++){\n *      let x = map(i, 0, spectrum.length, 0, width);\n *      let h = -height + map(spectrum[i], 0, 255, height, 0);\n *      rect(x, height, width / spectrum.length, h )\n *    }\n *\n *    let waveform = fft.waveform();\n *    noFill();\n *    beginShape();\n *    stroke(20);\n *    for (let i = 0; i < waveform.length; i++){\n *      let x = map(i, 0, waveform.length, 0, width);\n *      let y = map( waveform[i], -1, 1, 0, height);\n *      vertex(x,y);\n *    }\n *    endShape();\n *\n *    text('tap to play', 20, 20);\n *  }\n *\n *  function togglePlay() {\n *    if (sound.isPlaying()) {\n *      sound.pause();\n *    } else {\n *      sound.loop();\n *    }\n *  }\n *  </code></div>\n */\n\nvar fft_FFT =\nfunction () {\n  function FFT(smoothing, bins) {\n    fft_classCallCheck(this, FFT);\n\n    this.input = this.analyser = main.audiocontext.createAnalyser();\n    Object.defineProperties(this, {\n      bins: {\n        get: function get() {\n          return this.analyser.fftSize / 2;\n        },\n        set: function set(b) {\n          this.analyser.fftSize = b * 2;\n        },\n        configurable: true,\n        enumerable: true\n      },\n      smoothing: {\n        get: function get() {\n          return this.analyser.smoothingTimeConstant;\n        },\n        set: function set(s) {\n          this.analyser.smoothingTimeConstant = s;\n        },\n        configurable: true,\n        enumerable: true\n      }\n    }); \n\n    this.smooth(smoothing);\n    this.bins = bins || 1024; \n\n    main.fftMeter.connect(this.analyser);\n    this.freqDomain = new Uint8Array(this.analyser.frequencyBinCount);\n    this.timeDomain = new Uint8Array(this.analyser.frequencyBinCount); \n\n    this.bass = [20, 140];\n    this.lowMid = [140, 400];\n    this.mid = [400, 2600];\n    this.highMid = [2600, 5200];\n    this.treble = [5200, 14000]; \n\n    main.soundArray.push(this);\n  }\n  /**\n   *  Set the input source for the FFT analysis. If no source is\n   *  provided, FFT will analyze all sound in the sketch.\n   *\n   *  @method  setInput\n   *  @for p5.FFT\n   *  @param {Object} [source] p5.sound object (or web audio API source node)\n   */\n\n\n  fft_createClass(FFT, [{\n    key: \"setInput\",\n    value: function setInput(source) {\n      if (!source) {\n        main.fftMeter.connect(this.analyser);\n      } else {\n        if (source.output) {\n          source.output.connect(this.analyser);\n        } else if (source.connect) {\n          source.connect(this.analyser);\n        }\n\n        main.fftMeter.disconnect();\n      }\n    }\n    /**\n     *  Returns an array of amplitude values (between -1.0 and +1.0) that represent\n     *  a snapshot of amplitude readings in a single buffer. Length will be\n     *  equal to bins (defaults to 1024). Can be used to draw the waveform\n     *  of a sound.\n     *\n     *  @method waveform\n     *  @for p5.FFT\n     *  @param {Number} [bins]    Must be a power of two between\n     *                            16 and 1024. Defaults to 1024.\n     *  @param {String} [precision] If any value is provided, will return results\n     *                              in a Float32 Array which is more precise\n     *                              than a regular array.\n     *  @return {Array}  Array    Array of amplitude values (-1 to 1)\n     *                            over time. Array length = bins.\n     *\n     */\n\n  }, {\n    key: \"waveform\",\n    value: function waveform() {\n      var bins, mode;\n      var normalArray = new Array();\n\n      for (var i = 0; i < arguments.length; i++) {\n        if (typeof arguments[i] === 'number') {\n          bins = arguments[i];\n          this.analyser.fftSize = bins * 2;\n        }\n\n        if (typeof arguments[i] === 'string') {\n          mode = arguments[i];\n        }\n      } \n\n\n      if (mode && !p5.prototype._isSafari()) {\n        timeToFloat(this, this.timeDomain);\n        this.analyser.getFloatTimeDomainData(this.timeDomain);\n        return this.timeDomain;\n      } else {\n        timeToInt(this, this.timeDomain);\n        this.analyser.getByteTimeDomainData(this.timeDomain);\n\n        for (var j = 0; j < this.timeDomain.length; j++) {\n          var scaled = p5.prototype.map(this.timeDomain[j], 0, 255, -1, 1);\n          normalArray.push(scaled);\n        }\n\n        return normalArray;\n      }\n    }\n    /**\n     *  Returns an array of amplitude values (between 0 and 255)\n     *  across the frequency spectrum. Length is equal to FFT bins\n     *  (1024 by default). The array indices correspond to frequencies\n     *  (i.e. pitches), from the lowest to the highest that humans can\n     *  hear. Each value represents amplitude at that slice of the\n     *  frequency spectrum. Must be called prior to using\n     *  <code>getEnergy()</code>.\n     *\n     *  @method analyze\n     *  @for p5.FFT\n     *  @param {Number} [bins]    Must be a power of two between\n     *                             16 and 1024. Defaults to 1024.\n     *  @param {Number} [scale]    If \"dB,\" returns decibel\n     *                             float measurements between\n     *                             -140 and 0 (max).\n     *                             Otherwise returns integers from 0-255.\n     *  @return {Array} spectrum    Array of energy (amplitude/volume)\n     *                              values across the frequency spectrum.\n     *                              Lowest energy (silence) = 0, highest\n     *                              possible is 255.\n     *  @example\n     *  <div><code>\n     *  let osc, fft;\n     *\n     *  function setup(){\n     *    let cnv = createCanvas(100,100);\n     *    cnv.mousePressed(startSound);\n     *    osc = new p5.Oscillator();\n     *    osc.amp(0);\n     *    fft = new p5.FFT();\n     *  }\n     *\n     *  function draw(){\n     *    background(220);\n     *\n     *    let freq = map(mouseX, 0, windowWidth, 20, 10000);\n     *    freq = constrain(freq, 1, 20000);\n     *    osc.freq(freq);\n     *\n     *    let spectrum = fft.analyze();\n     *    noStroke();\n     *    fill(255, 0, 255);\n     *    for (let i = 0; i< spectrum.length; i++){\n     *      let x = map(i, 0, spectrum.length, 0, width);\n     *      let h = -height + map(spectrum[i], 0, 255, height, 0);\n     *      rect(x, height, width / spectrum.length, h );\n     *    }\n     *\n     *    stroke(255);\n     *    if (!osc.started) {\n     *      text('tap here and drag to change frequency', 10, 20, width - 20);\n     *    } else {\n     *      text(round(freq)+'Hz', 10, 20);\n     *    }\n     *  }\n     *\n     *  function startSound() {\n     *    osc.start();\n     *    osc.amp(0.5, 0.2);\n     *  }\n     *\n     *  function mouseReleased() {\n     *    osc.amp(0, 0.2);\n     *  }\n     *  </code></div>\n     *\n     *\n     */\n\n  }, {\n    key: \"analyze\",\n    value: function analyze() {\n      var mode;\n\n      for (var i = 0; i < arguments.length; i++) {\n        if (typeof arguments[i] === 'number') {\n          this.bins = arguments[i];\n          this.analyser.fftSize = this.bins * 2;\n        }\n\n        if (typeof arguments[i] === 'string') {\n          mode = arguments[i];\n        }\n      }\n\n      if (mode && mode.toLowerCase() === 'db') {\n        freqToFloat(this);\n        this.analyser.getFloatFrequencyData(this.freqDomain);\n        return this.freqDomain;\n      } else {\n        freqToInt(this, this.freqDomain);\n        this.analyser.getByteFrequencyData(this.freqDomain);\n        var normalArray = Array.apply([], this.freqDomain);\n        return normalArray;\n      }\n    }\n    /**\n     *  Returns the amount of energy (volume) at a specific\n     *  <a href=\"https://en.wikipedia.org/wiki/Audio_frequency\" target=\"_blank\">\n     *  frequency</a>, or the average amount of energy between two\n     *  frequencies. Accepts Number(s) corresponding\n     *  to frequency (in Hz), or a \"string\" corresponding to predefined\n     *  frequency ranges (\"bass\", \"lowMid\", \"mid\", \"highMid\", \"treble\").\n     *  Returns a range between 0 (no energy/volume at that frequency) and\n     *  255 (maximum energy).\n     *  <em>NOTE: analyze() must be called prior to getEnergy(). analyze()\n     *  tells the FFT to analyze frequency data, and getEnergy() uses\n     *  the results to determine the value at a specific frequency or\n     *  range of frequencies.</em></p>\n     *\n     *  @method  getEnergy\n     *  @for p5.FFT\n     *  @param  {Number|String} frequency1   Will return a value representing\n     *                                energy at this frequency. Alternately,\n     *                                the strings \"bass\", \"lowMid\" \"mid\",\n     *                                \"highMid\", and \"treble\" will return\n     *                                predefined frequency ranges.\n     *  @param  {Number} [frequency2] If a second frequency is given,\n     *                                will return average amount of\n     *                                energy that exists between the\n     *                                two frequencies.\n     *  @return {Number}   Energy   Energy (volume/amplitude) from\n     *                              0 and 255.\n     *\n     */\n\n  }, {\n    key: \"getEnergy\",\n    value: function getEnergy(frequency1, frequency2) {\n      var nyquist = main.audiocontext.sampleRate / 2;\n\n      if (frequency1 === 'bass') {\n        frequency1 = this.bass[0];\n        frequency2 = this.bass[1];\n      } else if (frequency1 === 'lowMid') {\n        frequency1 = this.lowMid[0];\n        frequency2 = this.lowMid[1];\n      } else if (frequency1 === 'mid') {\n        frequency1 = this.mid[0];\n        frequency2 = this.mid[1];\n      } else if (frequency1 === 'highMid') {\n        frequency1 = this.highMid[0];\n        frequency2 = this.highMid[1];\n      } else if (frequency1 === 'treble') {\n        frequency1 = this.treble[0];\n        frequency2 = this.treble[1];\n      }\n\n      if (typeof frequency1 !== 'number') {\n        throw 'invalid input for getEnergy()';\n      } else if (!frequency2) {\n        var index = Math.round(frequency1 / nyquist * this.freqDomain.length);\n        return this.freqDomain[index];\n      } else if (frequency1 && frequency2) {\n        if (frequency1 > frequency2) {\n          var swap = frequency2;\n          frequency2 = frequency1;\n          frequency1 = swap;\n        }\n\n        var lowIndex = Math.round(frequency1 / nyquist * this.freqDomain.length);\n        var highIndex = Math.round(frequency2 / nyquist * this.freqDomain.length);\n        var total = 0;\n        var numFrequencies = 0; \n\n        for (var i = lowIndex; i <= highIndex; i++) {\n          total += this.freqDomain[i];\n          numFrequencies += 1;\n        } \n\n\n        var toReturn = total / numFrequencies;\n        return toReturn;\n      } else {\n        throw 'invalid input for getEnergy()';\n      }\n    } \n\n  }, {\n    key: \"getFreq\",\n    value: function getFreq(freq1, freq2) {\n      console.log('getFreq() is deprecated. Please use getEnergy() instead.');\n      var x = this.getEnergy(freq1, freq2);\n      return x;\n    }\n    /**\n     *  Returns the\n     *  <a href=\"http://en.wikipedia.org/wiki/Spectral_centroid\" target=\"_blank\">\n     *  spectral centroid</a> of the input signal.\n     *  <em>NOTE: analyze() must be called prior to getCentroid(). Analyze()\n     *  tells the FFT to analyze frequency data, and getCentroid() uses\n     *  the results determine the spectral centroid.</em></p>\n     *\n     *  @method  getCentroid\n     *  @for p5.FFT\n     *  @return {Number}   Spectral Centroid Frequency  of the spectral centroid in Hz.\n     *\n     *\n     * @example\n     *  <div><code>\n     * function setup(){\n     *  cnv = createCanvas(100,100);\n     *  cnv.mousePressed(userStartAudio);\n     *  sound = new p5.AudioIn();\n     *  sound.start();\n     *  fft = new p5.FFT();\n     *  sound.connect(fft);\n     *}\n     *\n     *function draw() {\n     *  if (getAudioContext().state !== 'running') {\n     *    background(220);\n     *    text('tap here and enable mic to begin', 10, 20, width - 20);\n     *    return;\n     *  }\n     *  let centroidplot = 0.0;\n     *  let spectralCentroid = 0;\n     *\n     *  background(0);\n     *  stroke(0,255,0);\n     *  let spectrum = fft.analyze();\n     *  fill(0,255,0); // spectrum is green\n     *\n     *  //draw the spectrum\n     *  for (let i = 0; i < spectrum.length; i++){\n     *    let x = map(log(i), 0, log(spectrum.length), 0, width);\n     *    let h = map(spectrum[i], 0, 255, 0, height);\n     *    let rectangle_width = (log(i+1)-log(i))*(width/log(spectrum.length));\n     *    rect(x, height, rectangle_width, -h )\n     *  }\n     *  let nyquist = 22050;\n     *\n     *  // get the centroid\n     *  spectralCentroid = fft.getCentroid();\n     *\n     *  // the mean_freq_index calculation is for the display.\n     *  let mean_freq_index = spectralCentroid/(nyquist/spectrum.length);\n     *\n     *  centroidplot = map(log(mean_freq_index), 0, log(spectrum.length), 0, width);\n     *\n     *  stroke(255,0,0); // the line showing where the centroid is will be red\n     *\n     *  rect(centroidplot, 0, width / spectrum.length, height)\n     *  noStroke();\n     *  fill(255,255,255);  // text is white\n     *  text('centroid: ', 10, 20);\n     *  text(round(spectralCentroid)+' Hz', 10, 40);\n     *}\n     * </code></div>\n     */\n\n  }, {\n    key: \"getCentroid\",\n    value: function getCentroid() {\n      var nyquist = main.audiocontext.sampleRate / 2;\n      var cumulative_sum = 0;\n      var centroid_normalization = 0;\n\n      for (var i = 0; i < this.freqDomain.length; i++) {\n        cumulative_sum += i * this.freqDomain[i];\n        centroid_normalization += this.freqDomain[i];\n      }\n\n      var mean_freq_index = 0;\n\n      if (centroid_normalization !== 0) {\n        mean_freq_index = cumulative_sum / centroid_normalization;\n      }\n\n      var spec_centroid_freq = mean_freq_index * (nyquist / this.freqDomain.length);\n      return spec_centroid_freq;\n    }\n    /**\n     *  Smooth FFT analysis by averaging with the last analysis frame.\n     *\n     *  @method smooth\n     *  @param {Number} smoothing    0.0 < smoothing < 1.0.\n     *                               Defaults to 0.8.\n     */\n\n  }, {\n    key: \"smooth\",\n    value: function smooth(s) {\n      if (typeof s !== 'undefined') {\n        this.smoothing = s;\n      }\n\n      return this.smoothing;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n\n      if (this.analyser) {\n        this.analyser.disconnect();\n        delete this.analyser;\n      }\n    }\n    /**\n     *  Returns an array of average amplitude values for a given number\n     *  of frequency bands split equally. N defaults to 16.\n     *  <em>NOTE: analyze() must be called prior to linAverages(). Analyze()\n     *  tells the FFT to analyze frequency data, and linAverages() uses\n     *  the results to group them into a smaller set of averages.</em></p>\n     *\n     *  @method  linAverages\n     *  @for p5.FFT\n     *  @param  {Number}  N                Number of returned frequency groups\n     *  @return {Array}   linearAverages   Array of average amplitude values for each group\n     */\n\n  }, {\n    key: \"linAverages\",\n    value: function linAverages(_N) {\n      var N = _N || 16; \n\n      var spectrum = this.freqDomain;\n      var spectrumLength = spectrum.length;\n      var spectrumStep = Math.floor(spectrumLength / N);\n      var linearAverages = new Array(N); \n\n      var groupIndex = 0;\n\n      for (var specIndex = 0; specIndex < spectrumLength; specIndex++) {\n        linearAverages[groupIndex] = linearAverages[groupIndex] !== undefined ? (linearAverages[groupIndex] + spectrum[specIndex]) / 2 : spectrum[specIndex]; \n\n        if (specIndex % spectrumStep === spectrumStep - 1) {\n          groupIndex++;\n        }\n      }\n\n      return linearAverages;\n    }\n    /**\n     *  Returns an array of average amplitude values of the spectrum, for a given\n     *  set of <a href=\"https://en.wikipedia.org/wiki/Octave_band\" target=\"_blank\">\n     *  Octave Bands</a>\n     *  <em>NOTE: analyze() must be called prior to logAverages(). Analyze()\n     *  tells the FFT to analyze frequency data, and logAverages() uses\n     *  the results to group them into a smaller set of averages.</em></p>\n     *\n     *  @method  logAverages\n     *  @for p5.FFT\n     *  @param  {Array}   octaveBands    Array of Octave Bands objects for grouping\n     *  @return {Array}   logAverages    Array of average amplitude values for each group\n     */\n\n  }, {\n    key: \"logAverages\",\n    value: function logAverages(octaveBands) {\n      var nyquist = main.audiocontext.sampleRate / 2;\n      var spectrum = this.freqDomain;\n      var spectrumLength = spectrum.length;\n      var logAverages = new Array(octaveBands.length); \n\n      var octaveIndex = 0;\n\n      for (var specIndex = 0; specIndex < spectrumLength; specIndex++) {\n        var specIndexFrequency = Math.round(specIndex * nyquist / this.freqDomain.length); \n\n        if (specIndexFrequency > octaveBands[octaveIndex].hi) {\n          octaveIndex++;\n        }\n\n        logAverages[octaveIndex] = logAverages[octaveIndex] !== undefined ? (logAverages[octaveIndex] + spectrum[specIndex]) / 2 : spectrum[specIndex];\n      }\n\n      return logAverages;\n    }\n    /**\n     *  Calculates and Returns the 1/N\n     *  <a href=\"https://en.wikipedia.org/wiki/Octave_band\" target=\"_blank\">Octave Bands</a>\n     *  N defaults to 3 and minimum central frequency to 15.625Hz.\n     *  (1/3 Octave Bands ~= 31 Frequency Bands)\n     *  Setting fCtr0 to a central value of a higher octave will ignore the lower bands\n     *  and produce less frequency groups.\n     *\n     *  @method   getOctaveBands\n     *  @for p5.FFT\n     *  @param  {Number}  N             Specifies the 1/N type of generated octave bands\n     *  @param  {Number}  fCtr0         Minimum central frequency for the lowest band\n     *  @return {Array}   octaveBands   Array of octave band objects with their bounds\n     */\n\n  }, {\n    key: \"getOctaveBands\",\n    value: function getOctaveBands(_N, _fCtr0) {\n      var N = _N || 3; \n\n      var fCtr0 = _fCtr0 || 15.625; \n\n      var octaveBands = [];\n      var lastFrequencyBand = {\n        lo: fCtr0 / Math.pow(2, 1 / (2 * N)),\n        ctr: fCtr0,\n        hi: fCtr0 * Math.pow(2, 1 / (2 * N))\n      };\n      octaveBands.push(lastFrequencyBand);\n      var nyquist = main.audiocontext.sampleRate / 2;\n\n      while (lastFrequencyBand.hi < nyquist) {\n        var newFrequencyBand = {};\n        newFrequencyBand.lo = lastFrequencyBand.hi;\n        newFrequencyBand.ctr = lastFrequencyBand.ctr * Math.pow(2, 1 / N);\n        newFrequencyBand.hi = newFrequencyBand.ctr * Math.pow(2, 1 / (2 * N));\n        octaveBands.push(newFrequencyBand);\n        lastFrequencyBand = newFrequencyBand;\n      }\n\n      return octaveBands;\n    }\n  }]);\n\n  return FFT;\n}(); \n\n\nfunction freqToFloat(fft) {\n  if (fft.freqDomain instanceof Float32Array === false) {\n    fft.freqDomain = new Float32Array(fft.analyser.frequencyBinCount);\n  }\n}\n\nfunction freqToInt(fft) {\n  if (fft.freqDomain instanceof Uint8Array === false) {\n    fft.freqDomain = new Uint8Array(fft.analyser.frequencyBinCount);\n  }\n}\n\nfunction timeToFloat(fft) {\n  if (fft.timeDomain instanceof Float32Array === false) {\n    fft.timeDomain = new Float32Array(fft.analyser.frequencyBinCount);\n  }\n}\n\nfunction timeToInt(fft) {\n  if (fft.timeDomain instanceof Uint8Array === false) {\n    fft.timeDomain = new Uint8Array(fft.analyser.frequencyBinCount);\n  }\n}\n\n var fft = (fft_FFT);\nvar Add = __webpack_require__(4);\nvar Add_default = __webpack_require__.n(Add);\n\nvar Multiply = __webpack_require__(1);\nvar Multiply_default = __webpack_require__.n(Multiply);\n\nvar Scale = __webpack_require__(8);\nvar Scale_default = __webpack_require__.n(Scale);\n\nfunction oscillator_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { oscillator_typeof = function _typeof(obj) { return typeof obj; }; } else { oscillator_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return oscillator_typeof(obj); }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (oscillator_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction oscillator_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction oscillator_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction oscillator_createClass(Constructor, protoProps, staticProps) { if (protoProps) oscillator_defineProperties(Constructor.prototype, protoProps); if (staticProps) oscillator_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n\n\n\nfunction sigChain(o, mathObj, thisChain, nextChain, type) {\n  var chainSource = o.oscillator; \n\n  for (var i in o.mathOps) {\n    if (o.mathOps[i] instanceof type) {\n      chainSource.disconnect();\n      o.mathOps[i].dispose();\n      thisChain = i; \n\n      if (thisChain < o.mathOps.length - 2) {\n        nextChain = o.mathOps[i + 1];\n      }\n    }\n  }\n\n  if (thisChain === o.mathOps.length - 1) {\n    o.mathOps.push(nextChain);\n  } \n\n\n  if (i > 0) {\n    chainSource = o.mathOps[i - 1];\n  }\n\n  chainSource.disconnect();\n  chainSource.connect(mathObj);\n  mathObj.connect(nextChain);\n  o.mathOps[thisChain] = mathObj;\n  return o;\n}\n/**\n *  <p>Creates a signal that oscillates between -1.0 and 1.0.\n *  By default, the oscillation takes the form of a sinusoidal\n *  shape ('sine'). Additional types include 'triangle',\n *  'sawtooth' and 'square'. The frequency defaults to\n *  440 oscillations per second (440Hz, equal to the pitch of an\n *  'A' note).</p>\n *\n *  <p>Set the type of oscillation with setType(), or by instantiating a\n *  specific oscillator: <a href=\"/reference/#/p5.SinOsc\">p5.SinOsc</a>, <a\n *  href=\"/reference/#/p5.TriOsc\">p5.TriOsc</a>, <a\n *  href=\"/reference/#/p5.SqrOsc\">p5.SqrOsc</a>, or <a\n *  href=\"/reference/#/p5.SawOsc\">p5.SawOsc</a>.\n *  </p>\n *\n *  @class p5.Oscillator\n *  @constructor\n *  @param {Number} [freq] frequency defaults to 440Hz\n *  @param {String} [type] type of oscillator. Options:\n *                         'sine' (default), 'triangle',\n *                         'sawtooth', 'square'\n *  @example\n *  <div><code>\n *  let osc, playing, freq, amp;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playOscillator);\n *    osc = new p5.Oscillator('sine');\n *  }\n *\n *  function draw() {\n *    background(220)\n *    freq = constrain(map(mouseX, 0, width, 100, 500), 100, 500);\n *    amp = constrain(map(mouseY, height, 0, 0, 1), 0, 1);\n *\n *    text('tap to play', 20, 20);\n *    text('freq: ' + freq, 20, 40);\n *    text('amp: ' + amp, 20, 60);\n *\n *    if (playing) {\n *      // smooth the transitions by 0.1 seconds\n *      osc.freq(freq, 0.1);\n *      osc.amp(amp, 0.1);\n *    }\n *  }\n *\n *  function playOscillator() {\n *    // starting an oscillator on a user gesture will enable audio\n *    // in browsers that have a strict autoplay policy.\n *    // See also: userStartAudio();\n *    osc.start();\n *    playing = true;\n *  }\n *\n *  function mouseReleased() {\n *    // ramp amplitude to 0 over 0.5 seconds\n *    osc.amp(0, 0.5);\n *    playing = false;\n *  }\n *  </code> </div>\n */\n\n\nvar oscillator_Oscillator =\nfunction () {\n  function Oscillator(freq, type) {\n    oscillator_classCallCheck(this, Oscillator);\n\n    if (typeof freq === 'string') {\n      var f = type;\n      type = freq;\n      freq = f;\n    }\n\n    if (typeof type === 'number') {\n      var _f = type;\n      type = freq;\n      freq = _f;\n    }\n\n    this.started = false; \n\n    this.phaseAmount = undefined;\n    this.oscillator = main.audiocontext.createOscillator();\n    this.f = freq || 440.0; \n\n    this.oscillator.type = type || 'sine';\n    this.oscillator.frequency.setValueAtTime(this.f, main.audiocontext.currentTime); \n\n    this.output = main.audiocontext.createGain();\n    this._freqMods = []; \n\n    this.output.gain.value = 0.5;\n    this.output.gain.setValueAtTime(0.5, main.audiocontext.currentTime);\n    this.oscillator.connect(this.output); \n\n    this.panPosition = 0.0;\n    this.connection = main.input; \n\n    this.panner = new panner_0(this.output, this.connection, 1); \n\n    this.mathOps = [this.output]; \n\n    main.soundArray.push(this); \n\n    this.fade = this.amp;\n  }\n  /**\n   *  Start an oscillator.\n   *\n   *  Starting an oscillator on a user gesture will enable audio in browsers\n   *  that have a strict autoplay policy, including Chrome and most mobile\n   *  devices. See also: `userStartAudio()`.\n   *\n   *  @method  start\n   *  @for p5.Oscillator\n   *  @param  {Number} [time] startTime in seconds from now.\n   *  @param  {Number} [frequency] frequency in Hz.\n   */\n\n\n  oscillator_createClass(Oscillator, [{\n    key: \"start\",\n    value: function start(time, f) {\n      if (this.started) {\n        var now = main.audiocontext.currentTime;\n        this.stop(now);\n      }\n\n      if (!this.started) {\n        var freq = f || this.f;\n        var type = this.oscillator.type; \n\n        if (this.oscillator) {\n          this.oscillator.disconnect();\n          delete this.oscillator;\n        } \n\n\n        this.oscillator = main.audiocontext.createOscillator();\n        this.oscillator.frequency.value = Math.abs(freq);\n        this.oscillator.type = type; \n\n        this.oscillator.connect(this.output);\n        time = time || 0;\n        this.oscillator.start(time + main.audiocontext.currentTime);\n        this.freqNode = this.oscillator.frequency; \n\n        for (var i in this._freqMods) {\n          if (typeof this._freqMods[i].connect !== 'undefined') {\n            this._freqMods[i].connect(this.oscillator.frequency);\n          }\n        }\n\n        this.started = true;\n      }\n    }\n    /**\n     *  Stop an oscillator. Accepts an optional parameter\n     *  to determine how long (in seconds from now) until the\n     *  oscillator stops.\n     *\n     *  @method  stop\n     *  @for p5.Oscillator\n     *  @param  {Number} secondsFromNow Time, in seconds from now.\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop(time) {\n      if (this.started) {\n        var t = time || 0;\n        var now = main.audiocontext.currentTime;\n        this.oscillator.stop(t + now);\n        this.started = false;\n      }\n    }\n    /**\n     *  Set the amplitude between 0 and 1.0. Or, pass in an object\n     *  such as an oscillator to modulate amplitude with an audio signal.\n     *\n     *  @method  amp\n     *  @for p5.Oscillator\n     *  @param  {Number|Object} vol between 0 and 1.0\n     *                              or a modulating signal/oscillator\n     *  @param {Number} [rampTime] create a fade that lasts rampTime\n     *  @param {Number} [timeFromNow] schedule this event to happen\n     *                                seconds from now\n     *  @return  {AudioParam} gain  If no value is provided,\n     *                              returns the Web Audio API\n     *                              AudioParam that controls\n     *                              this oscillator's\n     *                              gain/amplitude/volume)\n     */\n\n  }, {\n    key: \"amp\",\n    value: function amp(vol) {\n      var rampTime = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n      var tFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n\n      if (typeof vol === 'number') {\n        var now = main.audiocontext.currentTime;\n        this.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);\n      } else if (vol) {\n        vol.connect(this.output.gain);\n      } else {\n        return this.output.gain;\n      }\n    }\n    /**\n     * Returns the value of output gain\n     *\n     *  @method  getAmp\n     *  @for p5.Oscillator\n     *\n     * @returns {number} Amplitude value between 0.0 and 1.0\n     */\n\n  }, {\n    key: \"getAmp\",\n    value: function getAmp() {\n      return this.output.gain.value;\n    }\n    /**\n     *  Set frequency of an oscillator to a value. Or, pass in an object\n     *  such as an oscillator to modulate the frequency with an audio signal.\n     *\n     *  @method  freq\n     *  @for p5.Oscillator\n     *  @param  {Number|Object} Frequency Frequency in Hz\n     *                                        or modulating signal/oscillator\n     *  @param  {Number} [rampTime] Ramp time (in seconds)\n     *  @param  {Number} [timeFromNow] Schedule this event to happen\n     *                                   at x seconds from now\n     *  @return  {AudioParam} Frequency If no value is provided,\n     *                                  returns the Web Audio API\n     *                                  AudioParam that controls\n     *                                  this oscillator's frequency\n     *  @example\n     *  <div><code>\n     *  let osc;\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(playOscillator);\n     *    osc = new p5.Oscillator(300);\n     *    background(220);\n     *    text('tap to play', 20, 20);\n     *  }\n     *\n     *  function playOscillator() {\n     *    osc.start();\n     *    osc.amp(0.5);\n     *    // start at 700Hz\n     *    osc.freq(700);\n     *    // ramp to 60Hz over 0.7 seconds\n     *    osc.freq(60, 0.7);\n     *    osc.amp(0, 0.1, 0.7);\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"freq\",\n    value: function freq(val) {\n      var rampTime = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n      var tFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n\n      if (typeof val === 'number' && !isNaN(val)) {\n        this.f = val;\n        var now = main.audiocontext.currentTime;\n\n        if (rampTime === 0) {\n          this.oscillator.frequency.setValueAtTime(val, tFromNow + now);\n        } else {\n          if (val > 0) {\n            this.oscillator.frequency.exponentialRampToValueAtTime(val, tFromNow + rampTime + now);\n          } else {\n            this.oscillator.frequency.linearRampToValueAtTime(val, tFromNow + rampTime + now);\n          }\n        } \n\n\n        if (this.phaseAmount) {\n          this.phase(this.phaseAmount);\n        }\n      } else if (val) {\n        if (val.output) {\n          val = val.output;\n        }\n\n        val.connect(this.oscillator.frequency); \n\n        this._freqMods.push(val);\n      } else {\n        return this.oscillator.frequency;\n      }\n    }\n    /**\n     * Returns the value of frequency of oscillator\n     *\n     *  @method  getFreq\n     *  @for p5.Oscillator\n     *  @returns {number} Frequency of oscillator in Hertz\n     */\n\n  }, {\n    key: \"getFreq\",\n    value: function getFreq() {\n      return this.oscillator.frequency.value;\n    }\n    /**\n     *  Set type to 'sine', 'triangle', 'sawtooth' or 'square'.\n     *\n     *  @method  setType\n     *  @for p5.Oscillator\n     *  @param {String} type 'sine', 'triangle', 'sawtooth' or 'square'.\n     */\n\n  }, {\n    key: \"setType\",\n    value: function setType(type) {\n      this.oscillator.type = type;\n    }\n    /**\n     *  Returns  current type of oscillator eg. 'sine', 'triangle', 'sawtooth' or 'square'.\n     *\n     *  @method  getType\n     *  @for p5.Oscillator\n     *  @returns {String} type of oscillator  eg . 'sine', 'triangle', 'sawtooth' or 'square'.\n     */\n\n  }, {\n    key: \"getType\",\n    value: function getType() {\n      return this.oscillator.type;\n    }\n    /**\n     *  Connect to a p5.sound / Web Audio object.\n     *\n     *  @method  connect\n     *  @for p5.Oscillator\n     *  @param  {Object} unit A p5.sound or Web Audio object\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      if (!unit) {\n        this.panner.connect(main.input);\n      } else if (unit.hasOwnProperty('input')) {\n        this.panner.connect(unit.input);\n        this.connection = unit.input;\n      } else {\n        this.panner.connect(unit);\n        this.connection = unit;\n      }\n    }\n    /**\n     *  Disconnect all outputs\n     *\n     *  @method  disconnect\n     *  @for p5.Oscillator\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.output) {\n        this.output.disconnect();\n      }\n\n      if (this.panner) {\n        this.panner.disconnect();\n\n        if (this.output) {\n          this.output.connect(this.panner);\n        }\n      }\n\n      this.oscMods = [];\n    }\n    /**\n     *  Pan between Left (-1) and Right (1)\n     *\n     *  @method  pan\n     *  @for p5.Oscillator\n     *  @param  {Number} panning Number between -1 and 1\n     *  @param  {Number} timeFromNow schedule this event to happen\n     *                                seconds from now\n     */\n\n  }, {\n    key: \"pan\",\n    value: function pan(pval, tFromNow) {\n      this.panPosition = pval;\n      this.panner.pan(pval, tFromNow);\n    }\n    /**\n     *  Returns the current value of panPosition , between Left (-1) and Right (1)\n     *\n     *  @method  getPan\n     *  @for p5.Oscillator\n     *\n     *  @returns {number} panPosition of oscillator , between Left (-1) and Right (1)\n     */\n\n  }, {\n    key: \"getPan\",\n    value: function getPan() {\n      return this.panPosition;\n    } \n\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n\n      if (this.oscillator) {\n        var now = main.audiocontext.currentTime;\n        this.stop(now);\n        this.disconnect();\n        this.panner = null;\n        this.oscillator = null;\n      } \n\n\n      if (this.osc2) {\n        this.osc2.dispose();\n      }\n    }\n    /**\n     *  Set the phase of an oscillator between 0.0 and 1.0.\n     *  In this implementation, phase is a delay time\n     *  based on the oscillator's current frequency.\n     *\n     *  @method  phase\n     *  @for p5.Oscillator\n     *  @param  {Number} phase float between 0.0 and 1.0\n     */\n\n  }, {\n    key: \"phase\",\n    value: function phase(p) {\n      var delayAmt = p5.prototype.map(p, 0, 1.0, 0, 1 / this.f);\n      var now = main.audiocontext.currentTime;\n      this.phaseAmount = p;\n\n      if (!this.dNode) {\n        this.dNode = main.audiocontext.createDelay(); \n\n        this.oscillator.disconnect();\n        this.oscillator.connect(this.dNode);\n        this.dNode.connect(this.output);\n      } \n\n\n      this.dNode.delayTime.setValueAtTime(delayAmt, now);\n    }\n    /**\n     *  Add a value to the p5.Oscillator's output amplitude,\n     *  and return the oscillator. Calling this method again\n     *  will override the initial add() with a new value.\n     *\n     *  @method  add\n     *  @for p5.Oscillator\n     *  @param {Number} number Constant number to add\n     *  @return {p5.Oscillator} Oscillator Returns this oscillator\n     *                                     with scaled output\n     *\n     */\n\n  }, {\n    key: \"add\",\n    value: function add(num) {\n      var add = new Add_default.a(num);\n      var thisChain = this.mathOps.length - 1;\n      var nextChain = this.output;\n      return sigChain(this, add, thisChain, nextChain, Add_default.a);\n    }\n    /**\n     *  Multiply the p5.Oscillator's output amplitude\n     *  by a fixed value (i.e. turn it up!). Calling this method\n     *  again will override the initial mult() with a new value.\n     *\n     *  @method  mult\n     *  @for p5.Oscillator\n     *  @param {Number} number Constant number to multiply\n     *  @return {p5.Oscillator} Oscillator Returns this oscillator\n     *                                     with multiplied output\n     */\n\n  }, {\n    key: \"mult\",\n    value: function mult(num) {\n      var mult = new Multiply_default.a(num);\n      var thisChain = this.mathOps.length - 1;\n      var nextChain = this.output;\n      return sigChain(this, mult, thisChain, nextChain, Multiply_default.a);\n    }\n    /**\n     *  Scale this oscillator's amplitude values to a given\n     *  range, and return the oscillator. Calling this method\n     *  again will override the initial scale() with new values.\n     *\n     *  @method  scale\n     *  @for p5.Oscillator\n     *  @param  {Number} inMin  input range minumum\n     *  @param  {Number} inMax  input range maximum\n     *  @param  {Number} outMin input range minumum\n     *  @param  {Number} outMax input range maximum\n     *  @return {p5.Oscillator} Oscillator Returns this oscillator\n     *                                     with scaled output\n     */\n\n  }, {\n    key: \"scale\",\n    value: function scale(inMin, inMax, outMin, outMax) {\n      var mapOutMin, mapOutMax;\n\n      if (arguments.length === 4) {\n        mapOutMin = p5.prototype.map(outMin, inMin, inMax, 0, 1) - 0.5; \n\n        mapOutMax = p5.prototype.map(outMax, inMin, inMax, 0, 1) - 0.5; \n      } else {\n        mapOutMin = arguments[0];\n        mapOutMax = arguments[1];\n      }\n\n      var scale = new Scale_default.a(mapOutMin, mapOutMax);\n      var thisChain = this.mathOps.length - 1;\n      var nextChain = this.output;\n      return sigChain(this, scale, thisChain, nextChain, Scale_default.a); \n    }\n  }]);\n\n  return Oscillator;\n}(); \n\n/**\n *  Constructor: <code>new p5.SinOsc()</code>.\n *  This creates a Sine Wave Oscillator and is\n *  equivalent to <code> new p5.Oscillator('sine')\n *  </code> or creating a p5.Oscillator and then calling\n *  its method <code>setType('sine')</code>.\n *  See p5.Oscillator for methods.\n *\n *  @class  p5.SinOsc\n *  @constructor\n *  @extends p5.Oscillator\n *  @param {Number} [freq] Set the frequency\n */\n\n\nvar SinOsc =\nfunction (_Oscillator) {\n  _inherits(SinOsc, _Oscillator);\n\n  function SinOsc(freq) {\n    oscillator_classCallCheck(this, SinOsc);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(SinOsc).call(this, freq, 'sine'));\n  }\n\n  return SinOsc;\n}(oscillator_Oscillator);\n/**\n *  Constructor: <code>new p5.TriOsc()</code>.\n *  This creates a Triangle Wave Oscillator and is\n *  equivalent to <code>new p5.Oscillator('triangle')\n *  </code> or creating a p5.Oscillator and then calling\n *  its method <code>setType('triangle')</code>.\n *  See p5.Oscillator for methods.\n *\n *  @class  p5.TriOsc\n *  @constructor\n *  @extends p5.Oscillator\n *  @param {Number} [freq] Set the frequency\n */\n\n\nvar TriOsc =\nfunction (_Oscillator2) {\n  _inherits(TriOsc, _Oscillator2);\n\n  function TriOsc(freq) {\n    oscillator_classCallCheck(this, TriOsc);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(TriOsc).call(this, freq, 'triangle'));\n  }\n\n  return TriOsc;\n}(oscillator_Oscillator);\n/**\n *  Constructor: <code>new p5.SawOsc()</code>.\n *  This creates a SawTooth Wave Oscillator and is\n *  equivalent to <code> new p5.Oscillator('sawtooth')\n *  </code> or creating a p5.Oscillator and then calling\n *  its method <code>setType('sawtooth')</code>.\n *  See p5.Oscillator for methods.\n *\n *  @class  p5.SawOsc\n *  @constructor\n *  @extends p5.Oscillator\n *  @param {Number} [freq] Set the frequency\n */\n\n\nvar SawOsc =\nfunction (_Oscillator3) {\n  _inherits(SawOsc, _Oscillator3);\n\n  function SawOsc(freq) {\n    oscillator_classCallCheck(this, SawOsc);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(SawOsc).call(this, freq, 'sawtooth'));\n  }\n\n  return SawOsc;\n}(oscillator_Oscillator);\n/**\n *  Constructor: <code>new p5.SqrOsc()</code>.\n *  This creates a Square Wave Oscillator and is\n *  equivalent to <code> new p5.Oscillator('square')\n *  </code> or creating a p5.Oscillator and then calling\n *  its method <code>setType('square')</code>.\n *  See p5.Oscillator for methods.\n *\n *  @class  p5.SqrOsc\n *  @constructor\n *  @extends p5.Oscillator\n *  @param {Number} [freq] Set the frequency\n */\n\n\nvar SqrOsc =\nfunction (_Oscillator4) {\n  _inherits(SqrOsc, _Oscillator4);\n\n  function SqrOsc(freq) {\n    oscillator_classCallCheck(this, SqrOsc);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(SqrOsc).call(this, freq, 'square'));\n  }\n\n  return SqrOsc;\n}(oscillator_Oscillator);\n\n var oscillator = (oscillator_Oscillator);\n\nvar TimelineSignal = __webpack_require__(7);\nvar TimelineSignal_default = __webpack_require__.n(TimelineSignal);\n\n\n\n\n\n\n/**\n *  <p>Envelopes are pre-defined amplitude distribution over time.\n *  Typically, envelopes are used to control the output volume\n *  of an object, a series of fades referred to as Attack, Decay,\n *  Sustain and Release (\n *  <a href=\"https://upload.wikimedia.org/wikipedia/commons/e/ea/ADSR_parameter.svg\">ADSR</a>\n *  ). Envelopes can also control other Web Audio Parametersfor example, a p5.Envelope can\n *  control an Oscillator's frequency like this: <code>osc.freq(env)</code>.</p>\n *  <p>Use <code><a href=\"#/p5.Envelope/setRange\">setRange</a></code> to change the attack/release level.\n *  Use <code><a href=\"#/p5.Envelope/setADSR\">setADSR</a></code> to change attackTime, decayTime, sustainPercent and releaseTime.</p>\n *  <p>Use the <code><a href=\"#/p5.Envelope/play\">play</a></code> method to play the entire envelope,\n *  the <code><a href=\"#/p5.Envelope/ramp\">ramp</a></code> method for a pingable trigger,\n *  or <code><a href=\"#/p5.Envelope/triggerAttack\">triggerAttack</a></code>/\n *  <code><a href=\"#/p5.Envelope/triggerRelease\">triggerRelease</a></code> to trigger noteOn/noteOff.</p>\n *\n *  @class p5.Envelope\n *  @constructor\n *  @example\n *  <div><code>\n *  let t1 = 0.1; // attack time in seconds\n *  let l1 = 0.7; // attack level 0.0 to 1.0\n *  let t2 = 0.3; // decay time in seconds\n *  let l2 = 0.1; // decay level  0.0 to 1.0\n *\n *  let env;\n *  let triOsc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    background(220);\n *    text('tap to play', 20, 20);\n *    cnv.mousePressed(playSound);\n *\n *    env = new p5.Envelope(t1, l1, t2, l2);\n *    triOsc = new p5.Oscillator('triangle');\n *  }\n *\n *  function playSound() {\n *    // starting the oscillator ensures that audio is enabled.\n *    triOsc.start();\n *    env.play(triOsc);\n *  }\n *  </code></div>\n */\n\np5.Envelope = function (t1, l1, t2, l2, t3, l3) {\n  /**\n   * Time until envelope reaches attackLevel\n   * @property attackTime\n   */\n  this.aTime = t1 || 0.1;\n  /**\n   * Level once attack is complete.\n   * @property attackLevel\n   */\n\n  this.aLevel = l1 || 1;\n  /**\n   * Time until envelope reaches decayLevel.\n   * @property decayTime\n   */\n\n  this.dTime = t2 || 0.5;\n  /**\n   * Level after decay. The envelope will sustain here until it is released.\n   * @property decayLevel\n   */\n\n  this.dLevel = l2 || 0;\n  /**\n   * Duration of the release portion of the envelope.\n   * @property releaseTime\n   */\n\n  this.rTime = t3 || 0;\n  /**\n   * Level at the end of the release.\n   * @property releaseLevel\n   */\n\n  this.rLevel = l3 || 0;\n  this._rampHighPercentage = 0.98;\n  this._rampLowPercentage = 0.02;\n  this.output = main.audiocontext.createGain();\n  this.control = new TimelineSignal_default.a();\n\n  this._init(); \n\n\n  this.control.connect(this.output); \n\n  this.connection = null; \n\n  this.mathOps = [this.control]; \n\n  this.isExponential = false; \n\n  this.sourceToClear = null; \n\n  this.wasTriggered = false; \n\n  main.soundArray.push(this);\n}; \n\n\np5.Envelope.prototype._init = function () {\n  var now = main.audiocontext.currentTime;\n  var t = now;\n  this.control.setTargetAtTime(0.00001, t, 0.001); \n\n  this._setRampAD(this.aTime, this.dTime);\n};\n/**\n *  Reset the envelope with a series of time/value pairs.\n *\n *  @method  set\n *  @for p5.Envelope\n *  @param {Number} attackTime     Time (in seconds) before level\n *                                 reaches attackLevel\n *  @param {Number} attackLevel    Typically an amplitude between\n *                                 0.0 and 1.0\n *  @param {Number} decayTime      Time\n *  @param {Number} decayLevel   Amplitude (In a standard ADSR envelope,\n *                                 decayLevel = sustainLevel)\n *  @param {Number} releaseTime   Release Time (in seconds)\n *  @param {Number} releaseLevel  Amplitude\n *  @example\n *  <div><code>\n *  let attackTime;\n *  let l1 = 0.7; // attack level 0.0 to 1.0\n *  let t2 = 0.3; // decay time in seconds\n *  let l2 = 0.1; // decay level  0.0 to 1.0\n *  let l3 = 0.2; // release time in seconds\n *\n *  let env, triOsc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playSound);\n *\n *    env = new p5.Envelope();\n *    triOsc = new p5.Oscillator('triangle');\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap here to play', 5, 20);\n *\n *    attackTime = map(mouseX, 0, width, 0.0, 1.0);\n *    text('attack time: ' + attackTime, 5, height - 20);\n *  }\n *\n *  // mouseClick triggers envelope if over canvas\n *  function playSound() {\n *    env.set(attackTime, l1, t2, l2, l3);\n *\n *    triOsc.start();\n *    env.play(triOsc);\n *  }\n *  </code></div>\n *\n */\n\n\np5.Envelope.prototype.set = function (t1, l1, t2, l2, t3, l3) {\n  this.aTime = t1;\n  this.aLevel = l1;\n  this.dTime = t2 || 0;\n  this.dLevel = l2 || 0;\n  this.rTime = t3 || 0;\n  this.rLevel = l3 || 0; \n\n  this._setRampAD(t1, t2);\n};\n/**\n *  Set values like a traditional\n *  <a href=\"https://en.wikipedia.org/wiki/Synthesizer#/media/File:ADSR_parameter.svg\">\n *  ADSR envelope\n *  </a>.\n *\n *  @method  setADSR\n *  @for p5.Envelope\n *  @param {Number} attackTime    Time (in seconds before envelope\n *                                reaches Attack Level\n *  @param {Number} [decayTime]    Time (in seconds) before envelope\n *                                reaches Decay/Sustain Level\n *  @param {Number} [susRatio]    Ratio between attackLevel and releaseLevel, on a scale from 0 to 1,\n *                                where 1.0 = attackLevel, 0.0 = releaseLevel.\n *                                The susRatio determines the decayLevel and the level at which the\n *                                sustain portion of the envelope will sustain.\n *                                For example, if attackLevel is 0.4, releaseLevel is 0,\n *                                and susAmt is 0.5, the decayLevel would be 0.2. If attackLevel is\n *                                increased to 1.0 (using <code>setRange</code>),\n *                                then decayLevel would increase proportionally, to become 0.5.\n *  @param {Number} [releaseTime]   Time in seconds from now (defaults to 0)\n *  @example\n *  <div><code>\n *  let attackLevel = 1.0;\n *  let releaseLevel = 0;\n *\n *  let attackTime = 0.001;\n *  let decayTime = 0.2;\n *  let susPercent = 0.2;\n *  let releaseTime = 0.5;\n *\n *  let env, triOsc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playEnv);\n *\n *    env = new p5.Envelope();\n *    triOsc = new p5.Oscillator('triangle');\n *    triOsc.amp(env);\n *    triOsc.freq(220);\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap here to play', 5, 20);\n *    attackTime = map(mouseX, 0, width, 0, 1.0);\n *    text('attack time: ' + attackTime, 5, height - 40);\n *  }\n *\n *  function playEnv() {\n *    triOsc.start();\n *    env.setADSR(attackTime, decayTime, susPercent, releaseTime);\n *    env.play();\n *  }\n *  </code></div>\n */\n\n\np5.Envelope.prototype.setADSR = function (aTime, dTime, sPercent, rTime) {\n  this.aTime = aTime;\n  this.dTime = dTime || 0; \n\n  this.sPercent = sPercent || 0;\n  this.dLevel = typeof sPercent !== 'undefined' ? sPercent * (this.aLevel - this.rLevel) + this.rLevel : 0;\n  this.rTime = rTime || 0; \n\n  this._setRampAD(aTime, dTime);\n};\n/**\n *  Set max (attackLevel) and min (releaseLevel) of envelope.\n *\n *  @method  setRange\n *  @for p5.Envelope\n *  @param {Number} aLevel attack level (defaults to 1)\n *  @param {Number} rLevel release level (defaults to 0)\n *  @example\n *  <div><code>\n *  let attackLevel = 1.0;\n *  let releaseLevel = 0;\n *\n *  let attackTime = 0.001;\n *  let decayTime = 0.2;\n *  let susPercent = 0.2;\n *  let releaseTime = 0.5;\n *\n *  let env, triOsc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playEnv);\n *\n *    env = new p5.Envelope();\n *    triOsc = new p5.Oscillator('triangle');\n *    triOsc.amp(env);\n *    triOsc.freq(220);\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap here to play', 5, 20);\n *    attackLevel = map(mouseY, height, 0, 0, 1.0);\n *    text('attack level: ' + attackLevel, 5, height - 20);\n *  }\n *\n *  function playEnv() {\n *    triOsc.start();\n *    env.setRange(attackLevel, releaseLevel);\n *    env.play();\n *  }\n *  </code></div>\n */\n\n\np5.Envelope.prototype.setRange = function (aLevel, rLevel) {\n  this.aLevel = aLevel || 1;\n  this.rLevel = rLevel || 0; \n}; \n\n\np5.Envelope.prototype._setRampAD = function (t1, t2) {\n  this._rampAttackTime = this.checkExpInput(t1);\n  this._rampDecayTime = this.checkExpInput(t2);\n  var TCDenominator = 1.0; \n\n  TCDenominator = Math.log(1.0 / this.checkExpInput(1.0 - this._rampHighPercentage));\n  this._rampAttackTC = t1 / this.checkExpInput(TCDenominator);\n  TCDenominator = Math.log(1.0 / this._rampLowPercentage);\n  this._rampDecayTC = t2 / this.checkExpInput(TCDenominator);\n}; \n\n\np5.Envelope.prototype.setRampPercentages = function (p1, p2) {\n  this._rampHighPercentage = this.checkExpInput(p1);\n  this._rampLowPercentage = this.checkExpInput(p2);\n  var TCDenominator = 1.0; \n\n  TCDenominator = Math.log(1.0 / this.checkExpInput(1.0 - this._rampHighPercentage));\n  this._rampAttackTC = this._rampAttackTime / this.checkExpInput(TCDenominator);\n  TCDenominator = Math.log(1.0 / this._rampLowPercentage);\n  this._rampDecayTC = this._rampDecayTime / this.checkExpInput(TCDenominator);\n};\n/**\n *  Assign a parameter to be controlled by this envelope.\n *  If a p5.Sound object is given, then the p5.Envelope will control its\n *  output gain. If multiple inputs are provided, the env will\n *  control all of them.\n *\n *  @method  setInput\n *  @for p5.Envelope\n *  @param  {Object} [...inputs]         A p5.sound object or\n *                                Web Audio Param.\n */\n\n\np5.Envelope.prototype.setInput = function () {\n  for (var i = 0; i < arguments.length; i++) {\n    this.connect(arguments[i]);\n  }\n};\n/**\n *  Set whether the envelope ramp is linear (default) or exponential.\n *  Exponential ramps can be useful because we perceive amplitude\n *  and frequency logarithmically.\n *\n *  @method  setExp\n *  @for p5.Envelope\n *  @param {Boolean} isExp true is exponential, false is linear\n */\n\n\np5.Envelope.prototype.setExp = function (isExp) {\n  this.isExponential = isExp;\n}; \n\n\np5.Envelope.prototype.checkExpInput = function (value) {\n  if (value <= 0) {\n    value = 0.00000001;\n  }\n\n  return value;\n};\n/**\n *  <p>Play tells the envelope to start acting on a given input.\n *  If the input is a p5.sound object (i.e. AudioIn, Oscillator,\n *  SoundFile), then Envelope will control its output volume.\n *  Envelopes can also be used to control any <a href=\"\n *  http://docs.webplatform.org/wiki/apis/webaudio/AudioParam\">\n *  Web Audio Audio Param.</a></p>\n *\n *  @method  play\n *  @for p5.Envelope\n *  @param  {Object} unit         A p5.sound object or\n *                                Web Audio Param.\n *  @param  {Number} [startTime]  time from now (in seconds) at which to play\n *  @param  {Number} [sustainTime] time to sustain before releasing the envelope\n *  @example\n *  <div><code>\n *  let attackLevel = 1.0;\n *  let releaseLevel = 0;\n *\n *  let attackTime = 0.001;\n *  let decayTime = 0.2;\n *  let susPercent = 0.2;\n *  let releaseTime = 0.5;\n *\n *  let env, triOsc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playEnv);\n *\n *    env = new p5.Envelope();\n *    triOsc = new p5.Oscillator('triangle');\n *    triOsc.amp(env);\n *    triOsc.freq(220);\n *    triOsc.start();\n *  }\n *\n *  function draw() {\n *    background(220);\n *    text('tap here to play', 5, 20);\n *    attackTime = map(mouseX, 0, width, 0, 1.0);\n *    attackLevel = map(mouseY, height, 0, 0, 1.0);\n *    text('attack time: ' + attackTime, 5, height - 40);\n *    text('attack level: ' + attackLevel, 5, height - 20);\n *  }\n *\n *  function playEnv() {\n *    // ensure that audio is enabled\n *    userStartAudio();\n *\n *    env.setADSR(attackTime, decayTime, susPercent, releaseTime);\n *    env.setRange(attackLevel, releaseLevel);\n *    env.play();\n *  }\n *  </code></div>\n */\n\n\np5.Envelope.prototype.play = function (unit, secondsFromNow, susTime) {\n  var tFromNow = secondsFromNow || 0;\n\n  if (unit) {\n    if (this.connection !== unit) {\n      this.connect(unit);\n    }\n  }\n\n  this.triggerAttack(unit, tFromNow);\n  this.triggerRelease(unit, tFromNow + this.aTime + this.dTime + ~~susTime);\n};\n/**\n *  Trigger the Attack, and Decay portion of the Envelope.\n *  Similar to holding down a key on a piano, but it will\n *  hold the sustain level until you let go. Input can be\n *  any p5.sound object, or a <a href=\"\n *  http://docs.webplatform.org/wiki/apis/webaudio/AudioParam\">\n *  Web Audio Param</a>.\n *\n *  @method  triggerAttack\n *  @for p5.Envelope\n *  @param  {Object} unit p5.sound Object or Web Audio Param\n *  @param  {Number} secondsFromNow time from now (in seconds)\n *  @example\n *  <div><code>\n *  let attackTime = 0.001;\n *  let decayTime = 0.2;\n *  let susPercent = 0.3;\n *  let releaseTime = 0.4;\n *  let env, triOsc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    background(220);\n *    textAlign(CENTER);\n *    textSize(10);\n *    text('tap to triggerAttack', width/2, height/2);\n *\n *    env = new p5.Envelope();\n *    env.setADSR(attackTime, decayTime, susPercent, releaseTime);\n *    env.setRange(1.0, 0.0);\n *    triOsc = new p5.Oscillator('triangle');\n *    triOsc.freq(220);\n *\n *    cnv.mousePressed(envAttack);\n *  }\n *\n *  function envAttack()  {\n *    background(0, 255, 255);\n *    text('release to release', width/2, height/2);\n *\n *    // ensures audio is enabled. See also: `userStartAudio`\n *    triOsc.start();\n *\n *    env.triggerAttack(triOsc);\n *  }\n *\n *  function mouseReleased() {\n *    background(220);\n *    text('tap to triggerAttack', width/2, height/2);\n *\n *    env.triggerRelease(triOsc);\n *  }\n *  </code></div>\n */\n\n\np5.Envelope.prototype.triggerAttack = function (unit, secondsFromNow) {\n  var now = main.audiocontext.currentTime;\n  var tFromNow = secondsFromNow || 0;\n  var t = now + tFromNow;\n  this.lastAttack = t;\n  this.wasTriggered = true;\n\n  if (unit) {\n    if (this.connection !== unit) {\n      this.connect(unit);\n    }\n  } \n\n\n  var valToSet = this.control.getValueAtTime(t);\n\n  if (this.isExponential === true) {\n    this.control.exponentialRampToValueAtTime(this.checkExpInput(valToSet), t);\n  } else {\n    this.control.linearRampToValueAtTime(valToSet, t);\n  } \n\n\n  t += this.aTime;\n\n  if (this.isExponential === true) {\n    this.control.exponentialRampToValueAtTime(this.checkExpInput(this.aLevel), t);\n    valToSet = this.checkExpInput(this.control.getValueAtTime(t));\n    this.control.cancelScheduledValues(t);\n    this.control.exponentialRampToValueAtTime(valToSet, t);\n  } else {\n    this.control.linearRampToValueAtTime(this.aLevel, t);\n    valToSet = this.control.getValueAtTime(t);\n    this.control.cancelScheduledValues(t);\n    this.control.linearRampToValueAtTime(valToSet, t);\n  } \n\n\n  t += this.dTime;\n\n  if (this.isExponential === true) {\n    this.control.exponentialRampToValueAtTime(this.checkExpInput(this.dLevel), t);\n    valToSet = this.checkExpInput(this.control.getValueAtTime(t));\n    this.control.cancelScheduledValues(t);\n    this.control.exponentialRampToValueAtTime(valToSet, t);\n  } else {\n    this.control.linearRampToValueAtTime(this.dLevel, t);\n    valToSet = this.control.getValueAtTime(t);\n    this.control.cancelScheduledValues(t);\n    this.control.linearRampToValueAtTime(valToSet, t);\n  }\n};\n/**\n *  Trigger the Release of the Envelope. This is similar to releasing\n *  the key on a piano and letting the sound fade according to the\n *  release level and release time.\n *\n *  @method  triggerRelease\n *  @for p5.Envelope\n *  @param  {Object} unit p5.sound Object or Web Audio Param\n *  @param  {Number} secondsFromNow time to trigger the release\n *  @example\n *  <div><code>\n *  let attackTime = 0.001;\n *  let decayTime = 0.2;\n *  let susPercent = 0.3;\n *  let releaseTime = 0.4;\n *  let env, triOsc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    background(220);\n *    textAlign(CENTER);\n *    textSize(10);\n *    text('tap to triggerAttack', width/2, height/2);\n *\n *    env = new p5.Envelope();\n *    env.setADSR(attackTime, decayTime, susPercent, releaseTime);\n *    env.setRange(1.0, 0.0);\n *    triOsc = new p5.Oscillator('triangle');\n *    triOsc.freq(220);\n *\n *    cnv.mousePressed(envAttack);\n *  }\n *\n *  function envAttack()  {\n *    background(0, 255, 255);\n *    text('release to release', width/2, height/2);\n *\n *    // ensures audio is enabled. See also: `userStartAudio`\n *    triOsc.start();\n *\n *    env.triggerAttack(triOsc);\n *  }\n *\n *  function mouseReleased() {\n *    background(220);\n *    text('tap to triggerAttack', width/2, height/2);\n *\n *    env.triggerRelease(triOsc);\n *  }\n *  </code></div>\n */\n\n\np5.Envelope.prototype.triggerRelease = function (unit, secondsFromNow) {\n  if (!this.wasTriggered) {\n    return;\n  }\n\n  var now = main.audiocontext.currentTime;\n  var tFromNow = secondsFromNow || 0;\n  var t = now + tFromNow;\n\n  if (unit) {\n    if (this.connection !== unit) {\n      this.connect(unit);\n    }\n  } \n\n\n  var valToSet = this.control.getValueAtTime(t);\n\n  if (this.isExponential === true) {\n    this.control.exponentialRampToValueAtTime(this.checkExpInput(valToSet), t);\n  } else {\n    this.control.linearRampToValueAtTime(valToSet, t);\n  } \n\n\n  t += this.rTime;\n\n  if (this.isExponential === true) {\n    this.control.exponentialRampToValueAtTime(this.checkExpInput(this.rLevel), t);\n    valToSet = this.checkExpInput(this.control.getValueAtTime(t));\n    this.control.cancelScheduledValues(t);\n    this.control.exponentialRampToValueAtTime(valToSet, t);\n  } else {\n    this.control.linearRampToValueAtTime(this.rLevel, t);\n    valToSet = this.control.getValueAtTime(t);\n    this.control.cancelScheduledValues(t);\n    this.control.linearRampToValueAtTime(valToSet, t);\n  }\n\n  this.wasTriggered = false;\n};\n/**\n *  Exponentially ramp to a value using the first two\n *  values from <code><a href=\"#/p5.Envelope/setADSR\">setADSR(attackTime, decayTime)</a></code>\n *  as <a href=\"https://en.wikipedia.org/wiki/RC_time_constant\">\n *  time constants</a> for simple exponential ramps.\n *  If the value is higher than current value, it uses attackTime,\n *  while a decrease uses decayTime.\n *\n *  @method  ramp\n *  @for p5.Envelope\n *  @param  {Object} unit           p5.sound Object or Web Audio Param\n *  @param  {Number} secondsFromNow When to trigger the ramp\n *  @param  {Number} v              Target value\n *  @param  {Number} [v2]           Second target value\n *  @example\n *  <div><code>\n *  let env, osc, amp;\n *\n *  let attackTime = 0.001;\n *  let decayTime = 0.2;\n *  let attackLevel = 1;\n *  let decayLevel = 0;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    fill(0,255,0);\n *    noStroke();\n *\n *    env = new p5.Envelope();\n *    env.setADSR(attackTime, decayTime);\n *    osc = new p5.Oscillator();\n *    osc.amp(env);\n *    amp = new p5.Amplitude();\n *\n *    cnv.mousePressed(triggerRamp);\n *  }\n *\n *  function triggerRamp() {\n *    // ensures audio is enabled. See also: `userStartAudio`\n *    osc.start();\n *\n *    env.ramp(osc, 0, attackLevel, decayLevel);\n *  }\n *\n *  function draw() {\n *    background(20);\n *    text('tap to play', 10, 20);\n *    let h = map(amp.getLevel(), 0, 0.4, 0, height);;\n *    rect(0, height, width, -h);\n *  }\n *  </code></div>\n */\n\n\np5.Envelope.prototype.ramp = function (unit, secondsFromNow, v1, v2) {\n  var now = main.audiocontext.currentTime;\n  var tFromNow = secondsFromNow || 0;\n  var t = now + tFromNow;\n  var destination1 = this.checkExpInput(v1);\n  var destination2 = typeof v2 !== 'undefined' ? this.checkExpInput(v2) : undefined; \n\n  if (unit) {\n    if (this.connection !== unit) {\n      this.connect(unit);\n    }\n  } \n\n\n  var currentVal = this.checkExpInput(this.control.getValueAtTime(t)); \n\n  if (destination1 > currentVal) {\n    this.control.setTargetAtTime(destination1, t, this._rampAttackTC);\n    t += this._rampAttackTime;\n  } \n  else if (destination1 < currentVal) {\n      this.control.setTargetAtTime(destination1, t, this._rampDecayTC);\n      t += this._rampDecayTime;\n    } \n\n\n  if (destination2 === undefined) return; \n\n  if (destination2 > destination1) {\n    this.control.setTargetAtTime(destination2, t, this._rampAttackTC);\n  } \n  else if (destination2 < destination1) {\n      this.control.setTargetAtTime(destination2, t, this._rampDecayTC);\n    }\n};\n\np5.Envelope.prototype.connect = function (unit) {\n  this.connection = unit; \n\n  if (unit instanceof p5.Oscillator || unit instanceof p5.SoundFile || unit instanceof p5.AudioIn || unit instanceof p5.Reverb || unit instanceof p5.Noise || unit instanceof p5.Filter || unit instanceof p5.Delay) {\n    unit = unit.output.gain;\n  }\n\n  if (unit instanceof AudioParam) {\n    unit.setValueAtTime(0, main.audiocontext.currentTime);\n  }\n\n  this.output.connect(unit);\n};\n\np5.Envelope.prototype.disconnect = function () {\n  if (this.output) {\n    this.output.disconnect();\n  }\n}; \n\n/**\n *  Add a value to the p5.Oscillator's output amplitude,\n *  and return the oscillator. Calling this method\n *  again will override the initial add() with new values.\n *\n *  @method  add\n *  @for p5.Envelope\n *  @param {Number} number Constant number to add\n *  @return {p5.Envelope} Envelope Returns this envelope\n *                                     with scaled output\n */\n\n\np5.Envelope.prototype.add = function (num) {\n  var add = new Add_default.a(num);\n  var thisChain = this.mathOps.length;\n  var nextChain = this.output;\n  return p5.prototype._mathChain(this, add, thisChain, nextChain, Add_default.a);\n};\n/**\n *  Multiply the p5.Envelope's output amplitude\n *  by a fixed value. Calling this method\n *  again will override the initial mult() with new values.\n *\n *  @method  mult\n *  @for p5.Envelope\n *  @param {Number} number Constant number to multiply\n *  @return {p5.Envelope} Envelope Returns this envelope\n *                                     with scaled output\n */\n\n\np5.Envelope.prototype.mult = function (num) {\n  var mult = new Multiply_default.a(num);\n  var thisChain = this.mathOps.length;\n  var nextChain = this.output;\n  return p5.prototype._mathChain(this, mult, thisChain, nextChain, Multiply_default.a);\n};\n/**\n *  Scale this envelope's amplitude values to a given\n *  range, and return the envelope. Calling this method\n *  again will override the initial scale() with new values.\n *\n *  @method  scale\n *  @for p5.Envelope\n *  @param  {Number} inMin  input range minumum\n *  @param  {Number} inMax  input range maximum\n *  @param  {Number} outMin input range minumum\n *  @param  {Number} outMax input range maximum\n *  @return {p5.Envelope} Envelope Returns this envelope\n *                                     with scaled output\n */\n\n\np5.Envelope.prototype.scale = function (inMin, inMax, outMin, outMax) {\n  var scale = new Scale_default.a(inMin, inMax, outMin, outMax);\n  var thisChain = this.mathOps.length;\n  var nextChain = this.output;\n  return p5.prototype._mathChain(this, scale, thisChain, nextChain, Scale_default.a);\n}; \n\n\np5.Envelope.prototype.dispose = function () {\n  var index = main.soundArray.indexOf(this);\n  main.soundArray.splice(index, 1);\n  this.disconnect();\n\n  if (this.control) {\n    this.control.dispose();\n    this.control = null;\n  }\n\n  for (var i = 1; i < this.mathOps.length; i++) {\n    this.mathOps[i].dispose();\n  }\n}; \n\n\np5.Env = function (t1, l1, t2, l2, t3, l3) {\n  console.warn('WARNING: p5.Env is now deprecated and may be removed in future versions. ' + 'Please use the new p5.Envelope instead.');\n  p5.Envelope.call(this, t1, l1, t2, l2, t3, l3);\n};\n\np5.Env.prototype = Object.create(p5.Envelope.prototype);\nvar Envelope = p5.Envelope;\n var envelope = (Envelope);\nfunction noise_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { noise_typeof = function _typeof(obj) { return typeof obj; }; } else { noise_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return noise_typeof(obj); }\n\nfunction noise_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction noise_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction noise_createClass(Constructor, protoProps, staticProps) { if (protoProps) noise_defineProperties(Constructor.prototype, protoProps); if (staticProps) noise_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction noise_possibleConstructorReturn(self, call) { if (call && (noise_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return noise_assertThisInitialized(self); }\n\nfunction noise_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction noise_getPrototypeOf(o) { noise_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return noise_getPrototypeOf(o); }\n\nfunction noise_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) noise_setPrototypeOf(subClass, superClass); }\n\nfunction noise_setPrototypeOf(o, p) { noise_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return noise_setPrototypeOf(o, p); }\n\n\n\nvar _whiteNoiseBuffer = function () {\n  var bufferSize = 2 * main.audiocontext.sampleRate;\n  var whiteBuffer = main.audiocontext.createBuffer(1, bufferSize, main.audiocontext.sampleRate);\n  var noiseData = whiteBuffer.getChannelData(0);\n\n  for (var i = 0; i < bufferSize; i++) {\n    noiseData[i] = Math.random() * 2 - 1;\n  }\n\n  whiteBuffer.type = 'white';\n  return whiteBuffer;\n}();\n\nvar _pinkNoiseBuffer = function () {\n  var bufferSize = 2 * main.audiocontext.sampleRate;\n  var pinkBuffer = main.audiocontext.createBuffer(1, bufferSize, main.audiocontext.sampleRate);\n  var noiseData = pinkBuffer.getChannelData(0);\n  var b0, b1, b2, b3, b4, b5, b6;\n  b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;\n\n  for (var i = 0; i < bufferSize; i++) {\n    var white = Math.random() * 2 - 1;\n    b0 = 0.99886 * b0 + white * 0.0555179;\n    b1 = 0.99332 * b1 + white * 0.0750759;\n    b2 = 0.969 * b2 + white * 0.153852;\n    b3 = 0.8665 * b3 + white * 0.3104856;\n    b4 = 0.55 * b4 + white * 0.5329522;\n    b5 = -0.7616 * b5 - white * 0.016898;\n    noiseData[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;\n    noiseData[i] *= 0.11; \n\n    b6 = white * 0.115926;\n  }\n\n  pinkBuffer.type = 'pink';\n  return pinkBuffer;\n}();\n\nvar _brownNoiseBuffer = function () {\n  var bufferSize = 2 * main.audiocontext.sampleRate;\n  var brownBuffer = main.audiocontext.createBuffer(1, bufferSize, main.audiocontext.sampleRate);\n  var noiseData = brownBuffer.getChannelData(0);\n  var lastOut = 0.0;\n\n  for (var i = 0; i < bufferSize; i++) {\n    var white = Math.random() * 2 - 1;\n    noiseData[i] = (lastOut + 0.02 * white) / 1.02;\n    lastOut = noiseData[i];\n    noiseData[i] *= 3.5;\n  }\n\n  brownBuffer.type = 'brown';\n  return brownBuffer;\n}();\n/**\n *  Noise is a type of oscillator that generates a buffer with random values.\n *\n *  @class p5.Noise\n *  @extends p5.Oscillator\n *  @constructor\n *  @param {String} type Type of noise can be 'white' (default),\n *                       'brown' or 'pink'.\n */\n\n\nvar noise_Noise =\nfunction (_Oscillator) {\n  noise_inherits(Noise, _Oscillator);\n\n  function Noise(type) {\n    var _this;\n\n    noise_classCallCheck(this, Noise);\n\n    _this = noise_possibleConstructorReturn(this, noise_getPrototypeOf(Noise).call(this));\n    var assignType;\n    delete _this.f;\n    delete _this.freq;\n    delete _this.oscillator;\n\n    if (type === 'brown') {\n      assignType = _brownNoiseBuffer;\n    } else if (type === 'pink') {\n      assignType = _pinkNoiseBuffer;\n    } else {\n      assignType = _whiteNoiseBuffer;\n    }\n\n    _this.buffer = assignType;\n    return _this;\n  }\n  /**\n   *  Set type of noise to 'white', 'pink' or 'brown'.\n   *  White is the default.\n   *\n   *  @method setType\n   *  @param {String} [type] 'white', 'pink' or 'brown'\n   */\n\n\n  noise_createClass(Noise, [{\n    key: \"setType\",\n    value: function setType(type) {\n      switch (type) {\n        case 'white':\n          this.buffer = _whiteNoiseBuffer;\n          break;\n\n        case 'pink':\n          this.buffer = _pinkNoiseBuffer;\n          break;\n\n        case 'brown':\n          this.buffer = _brownNoiseBuffer;\n          break;\n\n        default:\n          this.buffer = _whiteNoiseBuffer;\n      }\n\n      if (this.started) {\n        var now = main.audiocontext.currentTime;\n        this.stop(now);\n        this.start(now + 0.01);\n      }\n    }\n  }, {\n    key: \"getType\",\n    value: function getType() {\n      return this.buffer.type;\n    }\n  }, {\n    key: \"start\",\n    value: function start() {\n      if (this.started) {\n        this.stop();\n      }\n\n      this.noise = main.audiocontext.createBufferSource();\n      this.noise.buffer = this.buffer;\n      this.noise.loop = true;\n      this.noise.connect(this.output);\n      var now = main.audiocontext.currentTime;\n      this.noise.start(now);\n      this.started = true;\n    }\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      var now = main.audiocontext.currentTime;\n\n      if (this.noise) {\n        this.noise.stop(now);\n        this.started = false;\n      }\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var now = main.audiocontext.currentTime; \n\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n\n      if (this.noise) {\n        this.noise.disconnect();\n        this.stop(now);\n      }\n\n      if (this.output) {\n        this.output.disconnect();\n      }\n\n      if (this.panner) {\n        this.panner.disconnect();\n      }\n\n      this.output = null;\n      this.panner = null;\n      this.buffer = null;\n      this.noise = null;\n    }\n  }]);\n\n  return Noise;\n}(oscillator);\n\n var noise = (noise_Noise);\nvar Signal = __webpack_require__(2);\nvar Signal_default = __webpack_require__.n(Signal);\n\nfunction pulse_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { pulse_typeof = function _typeof(obj) { return typeof obj; }; } else { pulse_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return pulse_typeof(obj); }\n\nfunction pulse_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction pulse_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction pulse_createClass(Constructor, protoProps, staticProps) { if (protoProps) pulse_defineProperties(Constructor.prototype, protoProps); if (staticProps) pulse_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction pulse_possibleConstructorReturn(self, call) { if (call && (pulse_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return pulse_assertThisInitialized(self); }\n\nfunction pulse_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction pulse_getPrototypeOf(o) { pulse_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return pulse_getPrototypeOf(o); }\n\nfunction pulse_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) pulse_setPrototypeOf(subClass, superClass); }\n\nfunction pulse_setPrototypeOf(o, p) { pulse_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return pulse_setPrototypeOf(o, p); }\n\n\n\n\n\n/**\n *  Creates a Pulse object, an oscillator that implements\n *  Pulse Width Modulation.\n *  The pulse is created with two oscillators.\n *  Accepts a parameter for frequency, and to set the\n *  width between the pulses. See <a href=\"\n *  http://p5js.org/reference/#/p5.Oscillator\">\n *  <code>p5.Oscillator</code> for a full list of methods.\n *\n *  @class p5.Pulse\n *  @extends p5.Oscillator\n *  @constructor\n *  @param {Number} [freq] Frequency in oscillations per second (Hz)\n *  @param {Number} [w]    Width between the pulses (0 to 1.0,\n *                         defaults to 0)\n *  @example\n *  <div><code>\n *  let pulse;\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(startPulse);\n *    background(220);\n *\n *    pulse = new p5.Pulse();\n *    pulse.amp(0.5);\n *    pulse.freq(220);\n *  }\n *  function startPulse() {\n *    pulse.start();\n *    pulse.amp(0.5, 0.02);\n *  }\n *  function mouseReleased() {\n *    pulse.amp(0, 0.2);\n *  }\n *  function draw() {\n *    background(220);\n *    text('tap to play', 5, 20, width - 20);\n *    let w = map(mouseX, 0, width, 0, 1);\n *    w = constrain(w, 0, 1);\n *    pulse.width(w);\n *    text('pulse width: ' + w, 5, height - 20);\n *  }\n *  </code></div>\n */\n\nvar pulse_Pulse =\nfunction (_Oscillator) {\n  pulse_inherits(Pulse, _Oscillator);\n\n  function Pulse(freq, w) {\n    var _this;\n\n    pulse_classCallCheck(this, Pulse);\n\n    _this = pulse_possibleConstructorReturn(this, pulse_getPrototypeOf(Pulse).call(this, freq, 'sawtooth')); \n\n    _this.w = w || 0; \n\n    _this.osc2 = new SawOsc(freq); \n\n    _this.dNode = main.audiocontext.createDelay(); \n\n    _this.dcOffset = createDCOffset();\n    _this.dcGain = main.audiocontext.createGain();\n\n    _this.dcOffset.connect(_this.dcGain);\n\n    _this.dcGain.connect(_this.output); \n\n\n    _this.f = freq || 440;\n    var mW = _this.w / _this.oscillator.frequency.value;\n    _this.dNode.delayTime.value = mW;\n    _this.dcGain.gain.value = 1.7 * (0.5 - _this.w); \n\n    _this.osc2.disconnect();\n\n    _this.osc2.panner.disconnect();\n\n    _this.osc2.amp(-1); \n\n\n    _this.osc2.output.connect(_this.dNode);\n\n    _this.dNode.connect(_this.output);\n\n    _this.output.gain.value = 1;\n\n    _this.output.connect(_this.panner);\n\n    return _this;\n  }\n  /**\n   *  Set the width of a Pulse object (an oscillator that implements\n   *  Pulse Width Modulation).\n   *\n   *  @method  width\n   *  @param {Number} [width]    Width between the pulses (0 to 1.0,\n   *                         defaults to 0)\n   */\n\n\n  pulse_createClass(Pulse, [{\n    key: \"width\",\n    value: function width(w) {\n      if (typeof w === 'number') {\n        if (w <= 1.0 && w >= 0.0) {\n          this.w = w; \n\n          var mW = this.w / this.oscillator.frequency.value;\n          this.dNode.delayTime.value = mW;\n        }\n\n        this.dcGain.gain.value = 1.7 * (0.5 - this.w);\n      } else {\n        w.connect(this.dNode.delayTime);\n        var sig = new Signal_default.a(-0.5); \n\n        w.connect(sig);\n        var mult1 = new Multiply_default.a(-1);\n        var mult2 = new Multiply_default.a(1.7);\n        sig = sig.connect(mult1).connect(mult2);\n        sig.connect(this.dcGain.gain);\n      }\n    }\n  }, {\n    key: \"start\",\n    value: function start(f, time) {\n      var now = main.audiocontext.currentTime;\n      var t = time || 0;\n\n      if (!this.started) {\n        var freq = f || this.f;\n        var type = this.oscillator.type;\n        this.oscillator = main.audiocontext.createOscillator();\n        this.oscillator.frequency.setValueAtTime(freq, now);\n        this.oscillator.type = type;\n        this.oscillator.connect(this.output);\n        this.oscillator.start(t + now); \n\n        this.osc2.oscillator = main.audiocontext.createOscillator();\n        this.osc2.oscillator.frequency.setValueAtTime(freq, t + now);\n        this.osc2.oscillator.type = type;\n        this.osc2.oscillator.connect(this.osc2.output);\n        this.osc2.start(t + now);\n        this.freqNode = [this.oscillator.frequency, this.osc2.oscillator.frequency]; \n\n        this.dcOffset = createDCOffset();\n        this.dcOffset.connect(this.dcGain);\n        this.dcOffset.start(t + now); \n\n        if (this.mods !== undefined && this.mods.frequency !== undefined) {\n          this.mods.frequency.connect(this.freqNode[0]);\n          this.mods.frequency.connect(this.freqNode[1]);\n        }\n\n        this.started = true;\n        this.osc2.started = true;\n      }\n    }\n  }, {\n    key: \"stop\",\n    value: function stop(time) {\n      if (this.started) {\n        var t = time || 0;\n        var now = main.audiocontext.currentTime;\n        this.oscillator.stop(t + now);\n\n        if (this.osc2.oscillator) {\n          this.osc2.oscillator.stop(t + now);\n        }\n\n        this.dcOffset.stop(t + now);\n        this.started = false;\n        this.osc2.started = false;\n      }\n    }\n  }, {\n    key: \"freq\",\n    value: function freq(val) {\n      var rampTime = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n      var tFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n\n      if (typeof val === 'number') {\n        this.f = val;\n        var now = main.audiocontext.currentTime;\n        var currentFreq = this.oscillator.frequency.value;\n        this.oscillator.frequency.cancelScheduledValues(now);\n        this.oscillator.frequency.setValueAtTime(currentFreq, now + tFromNow);\n        this.oscillator.frequency.exponentialRampToValueAtTime(val, tFromNow + rampTime + now);\n        this.osc2.oscillator.frequency.cancelScheduledValues(now);\n        this.osc2.oscillator.frequency.setValueAtTime(currentFreq, now + tFromNow);\n        this.osc2.oscillator.frequency.exponentialRampToValueAtTime(val, tFromNow + rampTime + now);\n\n        if (this.freqMod) {\n          this.freqMod.output.disconnect();\n          this.freqMod = null;\n        }\n      } else if (val.output) {\n        val.output.disconnect();\n        val.output.connect(this.oscillator.frequency);\n        val.output.connect(this.osc2.oscillator.frequency);\n        this.freqMod = val;\n      }\n    }\n  }]);\n\n  return Pulse;\n}(oscillator); \n\n\nfunction createDCOffset() {\n  var ac = main.audiocontext;\n  var buffer = ac.createBuffer(1, 2048, ac.sampleRate);\n  var data = buffer.getChannelData(0);\n\n  for (var i = 0; i < 2048; i++) {\n    data[i] = 1.0;\n  }\n\n  var bufferSource = ac.createBufferSource();\n  bufferSource.buffer = buffer;\n  bufferSource.loop = true;\n  return bufferSource;\n}\n\n var pulse = (pulse_Pulse);\nfunction audioin_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction audioin_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction audioin_createClass(Constructor, protoProps, staticProps) { if (protoProps) audioin_defineProperties(Constructor.prototype, protoProps); if (staticProps) audioin_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\nmain.inputSources = [];\n/**\n *  <p>Get audio from an input, i.e. your computer's microphone.</p>\n *\n *  <p>Turn the mic on/off with the start() and stop() methods. When the mic\n *  is on, its volume can be measured with getLevel or by connecting an\n *  FFT object.</p>\n *\n *  <p>If you want to hear the AudioIn, use the .connect() method.\n *  AudioIn does not connect to p5.sound output by default to prevent\n *  feedback.</p>\n *\n *  <p><em>Note: This uses the <a href=\"http://caniuse.com/stream\">getUserMedia/\n *  Stream</a> API, which is not supported by certain browsers. Access in Chrome browser\n *  is limited to localhost and https, but access over http may be limited.</em></p>\n *\n *  @class p5.AudioIn\n *  @constructor\n *  @param {Function} [errorCallback] A function to call if there is an error\n *                                    accessing the AudioIn. For example,\n *                                    Safari and iOS devices do not\n *                                    currently allow microphone access.\n *  @example\n *  <div><code>\n *  let mic;\n *\n *   function setup(){\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(userStartAudio);\n *    textAlign(CENTER);\n *    mic = new p5.AudioIn();\n *    mic.start();\n *  }\n *\n *  function draw(){\n *    background(0);\n *    fill(255);\n *    text('tap to start', width/2, 20);\n *\n *    micLevel = mic.getLevel();\n *    let y = height - micLevel * height;\n *    ellipse(width/2, y, 10, 10);\n *  }\n *  </code></div>\n */\n\nvar audioin_AudioIn =\nfunction () {\n  function AudioIn(errorCallback) {\n    audioin_classCallCheck(this, AudioIn);\n\n\n    /**\n     * @property {GainNode} input\n     */\n    this.input = main.audiocontext.createGain();\n    /**\n     * @property {GainNode} output\n     */\n\n    this.output = main.audiocontext.createGain();\n    /**\n     * @property {MediaStream|null} stream\n     */\n\n    this.stream = null;\n    /**\n     * @property {MediaStreamAudioSourceNode|null} mediaStream\n     */\n\n    this.mediaStream = null;\n    /**\n     * @property {Number|null} currentSource\n     */\n\n    this.currentSource = null;\n    /**\n     *  Client must allow browser to access their microphone / audioin source.\n     *  Default: false. Will become true when the client enables access.\n     *\n     *  @property {Boolean} enabled\n     */\n\n    this.enabled = false;\n    /**\n     * Input amplitude, connect to it by default but not to master out\n     *\n     *  @property {p5.Amplitude} amplitude\n     */\n\n    this.amplitude = new amplitude();\n    this.output.connect(this.amplitude.input);\n\n    if (!window.MediaStreamTrack || !window.navigator.mediaDevices || !window.navigator.mediaDevices.getUserMedia) {\n      errorCallback ? errorCallback() : window.alert('This browser does not support MediaStreamTrack and mediaDevices');\n    } \n\n\n    main.soundArray.push(this);\n  }\n  /**\n   *  Start processing audio input. This enables the use of other\n   *  AudioIn methods like getLevel(). Note that by default, AudioIn\n   *  is not connected to p5.sound's output. So you won't hear\n   *  anything unless you use the connect() method.<br/>\n   *\n   *  Certain browsers limit access to the user's microphone. For example,\n   *  Chrome only allows access from localhost and over https. For this reason,\n   *  you may want to include an errorCallbacka function that is called in case\n   *  the browser won't provide mic access.\n   *\n   *  @method start\n   *  @for p5.AudioIn\n   *  @param {Function} [successCallback] Name of a function to call on\n   *                                    success.\n   *  @param {Function} [errorCallback] Name of a function to call if\n   *                                    there was an error. For example,\n   *                                    some browsers do not support\n   *                                    getUserMedia.\n   */\n\n\n  audioin_createClass(AudioIn, [{\n    key: \"start\",\n    value: function start(successCallback, errorCallback) {\n      var self = this;\n\n      if (this.stream) {\n        this.stop();\n      } \n\n\n      var audioSource = main.inputSources[self.currentSource];\n      var constraints = {\n        audio: {\n          sampleRate: main.audiocontext.sampleRate,\n          echoCancellation: false\n        }\n      }; \n\n      if (main.inputSources[this.currentSource]) {\n        constraints.audio.deviceId = audioSource.deviceId;\n      }\n\n      window.navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {\n        self.stream = stream;\n        self.enabled = true; \n\n        self.mediaStream = main.audiocontext.createMediaStreamSource(stream);\n        self.mediaStream.connect(self.output); \n\n        self.amplitude.setInput(self.output);\n        if (successCallback) successCallback();\n      })[\"catch\"](function (err) {\n        if (errorCallback) errorCallback(err);else console.error(err);\n      });\n    }\n    /**\n     *  Turn the AudioIn off. If the AudioIn is stopped, it cannot getLevel().\n     *  If re-starting, the user may be prompted for permission access.\n     *\n     *  @method stop\n     *  @for p5.AudioIn\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      if (this.stream) {\n        this.stream.getTracks().forEach(function (track) {\n          track.stop();\n        });\n        this.mediaStream.disconnect();\n        delete this.mediaStream;\n        delete this.stream;\n      }\n    }\n    /**\n     *  Connect to an audio unit. If no parameter is provided, will\n     *  connect to the main output (i.e. your speakers).<br/>\n     *\n     *  @method  connect\n     *  @for p5.AudioIn\n     *  @param  {Object} [unit] An object that accepts audio input,\n     *                          such as an FFT\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      if (unit) {\n        if (unit.hasOwnProperty('input')) {\n          this.output.connect(unit.input);\n        } else if (unit.hasOwnProperty('analyser')) {\n          this.output.connect(unit.analyser);\n        } else {\n          this.output.connect(unit);\n        }\n      } else {\n        this.output.connect(main.input);\n      }\n    }\n    /**\n     *  Disconnect the AudioIn from all audio units. For example, if\n     *  connect() had been called, disconnect() will stop sending\n     *  signal to your speakers.<br/>\n     *\n     *  @method  disconnect\n     *  @for p5.AudioIn\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.output) {\n        this.output.disconnect(); \n\n        this.output.connect(this.amplitude.input);\n      }\n    }\n    /**\n     *  Read the Amplitude (volume level) of an AudioIn. The AudioIn\n     *  class contains its own instance of the Amplitude class to help\n     *  make it easy to get a microphone's volume level. Accepts an\n     *  optional smoothing value (0.0 < 1.0). <em>NOTE: AudioIn must\n     *  .start() before using .getLevel().</em><br/>\n     *\n     *  @method  getLevel\n     *  @for p5.AudioIn\n     *  @param  {Number} [smoothing] Smoothing is 0.0 by default.\n     *                               Smooths values based on previous values.\n     *  @return {Number}           Volume level (between 0.0 and 1.0)\n     */\n\n  }, {\n    key: \"getLevel\",\n    value: function getLevel(smoothing) {\n      if (smoothing) {\n        this.amplitude.smoothing = smoothing;\n      }\n\n      return this.amplitude.getLevel();\n    }\n    /**\n     *  Set amplitude (volume) of a mic input between 0 and 1.0. <br/>\n     *\n     *  @method  amp\n     *  @for p5.AudioIn\n     *  @param  {Number} vol between 0 and 1.0\n     *  @param {Number} [time] ramp time (optional)\n     */\n\n  }, {\n    key: \"amp\",\n    value: function amp(vol, t) {\n      if (t) {\n        var rampTime = t || 0;\n        var currentVol = this.output.gain.value;\n        this.output.gain.cancelScheduledValues(main.audiocontext.currentTime);\n        this.output.gain.setValueAtTime(currentVol, main.audiocontext.currentTime);\n        this.output.gain.linearRampToValueAtTime(vol, rampTime + main.audiocontext.currentTime);\n      } else {\n        this.output.gain.cancelScheduledValues(main.audiocontext.currentTime);\n        this.output.gain.setValueAtTime(vol, main.audiocontext.currentTime);\n      }\n    }\n    /**\n     * Returns a list of available input sources. This is a wrapper\n     * for <a href=\"https://developer.mozilla.org/\n     * en-US/docs/Web/API/MediaDevices/enumerateDevices\" target=\"_blank\">\n     * MediaDevices.enumerateDevices() - Web APIs | MDN</a>\n     * and it returns a Promise.\n     * @method  getSources\n     * @for p5.AudioIn\n     * @param  {Function} [successCallback] This callback function handles the sources when they\n     *                                      have been enumerated. The callback function\n     *                                      receives the deviceList array as its only argument\n     * @param  {Function} [errorCallback] This optional callback receives the error\n     *                                    message as its argument.\n     * @returns {Promise} Returns a Promise that can be used in place of the callbacks, similar\n     *                            to the enumerateDevices() method\n     * @example\n     *  <div><code>\n     *  let audioIn;\n     *\n     *  function setup(){\n     *    text('getting sources...', 0, 20);\n     *    audioIn = new p5.AudioIn();\n     *    audioIn.getSources(gotSources);\n     *  }\n     *\n     *  function gotSources(deviceList) {\n     *    if (deviceList.length > 0) {\n     *      //set the source to the first item in the deviceList array\n     *      audioIn.setSource(0);\n     *      let currentSource = deviceList[audioIn.currentSource];\n     *      text('set source to: ' + currentSource.deviceId, 5, 20, width);\n     *    }\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"getSources\",\n    value: function getSources(onSuccess, onError) {\n      return new Promise(function (resolve, reject) {\n        window.navigator.mediaDevices.enumerateDevices().then(function (devices) {\n          main.inputSources = devices.filter(function (device) {\n            return device.kind === 'audioinput';\n          });\n          resolve(main.inputSources);\n\n          if (onSuccess) {\n            onSuccess(main.inputSources);\n          }\n        })[\"catch\"](function (error) {\n          reject(error);\n\n          if (onError) {\n            onError(error);\n          } else {\n            console.error('This browser does not support MediaStreamTrack.getSources()');\n          }\n        });\n      });\n    }\n    /**\n     *  Set the input source. Accepts a number representing a\n     *  position in the array returned by getSources().\n     *  This is only available in browsers that support\n     * <a href=\"https://developer.mozilla.org/\n     * en-US/docs/Web/API/MediaDevices/enumerateDevices\" target=\"_blank\">\n     * navigator.mediaDevices.enumerateDevices()</a>\n     *\n     *  @method setSource\n     *  @for p5.AudioIn\n     *  @param {number} num position of input source in the array\n     *  @example\n     *  <div><code>\n     *  let audioIn;\n     *\n     *  function setup(){\n     *    text('getting sources...', 0, 20);\n     *    audioIn = new p5.AudioIn();\n     *    audioIn.getSources(gotSources);\n     *  }\n     *\n     *  function gotSources(deviceList) {\n     *    if (deviceList.length > 0) {\n     *      //set the source to the first item in the deviceList array\n     *      audioIn.setSource(0);\n     *      let currentSource = deviceList[audioIn.currentSource];\n     *      text('set source to: ' + currentSource.deviceId, 5, 20, width);\n     *    }\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"setSource\",\n    value: function setSource(num) {\n      if (main.inputSources.length > 0 && num < main.inputSources.length) {\n        this.currentSource = num;\n        console.log('set source to ', main.inputSources[this.currentSource]);\n      } else {\n        console.log('unable to set input source');\n      } \n\n\n      if (this.stream && this.stream.active) {\n        this.start();\n      }\n    } \n\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n      this.stop();\n\n      if (this.output) {\n        this.output.disconnect();\n      }\n\n      if (this.amplitude) {\n        this.amplitude.disconnect();\n      }\n\n      delete this.amplitude;\n      delete this.output;\n    }\n  }]);\n\n  return AudioIn;\n}();\n\n var audioin = (audioin_AudioIn);\nvar CrossFade = __webpack_require__(23);\nvar CrossFade_default = __webpack_require__.n(CrossFade);\n\nfunction effect_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction effect_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction effect_createClass(Constructor, protoProps, staticProps) { if (protoProps) effect_defineProperties(Constructor.prototype, protoProps); if (staticProps) effect_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n/**\n * Effect is a base class for audio effects in p5. <br>\n * This module handles the nodes and methods that are\n * common and useful for current and future effects.\n *\n *\n * This class is extended by <a href=\"/reference/#/p5.Distortion\">p5.Distortion</a>,\n * <a href=\"/reference/#/p5.Compressor\">p5.Compressor</a>,\n * <a href=\"/reference/#/p5.Delay\">p5.Delay</a>,\n * <a href=\"/reference/#/p5.Filter\">p5.Filter</a>,\n * <a href=\"/reference/#/p5.Reverb\">p5.Reverb</a>.\n *\n * @class  p5.Effect\n * @constructor\n *\n * @param {Object} [ac]   Reference to the audio context of the p5 object\n * @param {AudioNode} [input]  Gain Node effect wrapper\n * @param {AudioNode} [output] Gain Node effect wrapper\n * @param {Object} [_drywet]   Tone.JS CrossFade node (defaults to value: 1)\n * @param {AudioNode} [wet]  Effects that extend this class should connect\n *                              to the wet signal to this gain node, so that dry and wet\n *                              signals are mixed properly.\n */\n\nvar effect_Effect =\nfunction () {\n  function Effect() {\n    effect_classCallCheck(this, Effect);\n\n    this.ac = main.audiocontext;\n    this.input = this.ac.createGain();\n    this.output = this.ac.createGain();\n    /**\n     *\tThe p5.Effect class is built\n     * \tusing Tone.js CrossFade\n     * \t@private\n     */\n\n    this._drywet = new CrossFade_default.a(1);\n    /**\n     *\tIn classes that extend\n     *\tp5.Effect, connect effect nodes\n     *\tto the wet parameter\n     */\n\n    this.wet = this.ac.createGain();\n    this.input.connect(this._drywet.a);\n    this.wet.connect(this._drywet.b);\n\n    this._drywet.connect(this.output);\n\n    this.connect(); \n\n    main.soundArray.push(this);\n  }\n  /**\n   *  Set the output volume of the filter.\n   *\n   *  @method  amp\n   *  @for p5.Effect\n   *  @param {Number} [vol] amplitude between 0 and 1.0\n   *  @param {Number} [rampTime] create a fade that lasts until rampTime\n   *  @param {Number} [tFromNow] schedule this event to happen in tFromNow seconds\n   */\n\n\n  effect_createClass(Effect, [{\n    key: \"amp\",\n    value: function amp(vol) {\n      var rampTime = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n      var tFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n      var now = main.audiocontext.currentTime;\n      var startTime = now + tFromNow;\n      var endTime = startTime + rampTime + 0.001;\n      var currentVol = this.output.gain.value;\n      this.output.gain.cancelScheduledValues(now);\n      this.output.gain.linearRampToValueAtTime(currentVol, startTime + 0.001);\n      this.output.gain.linearRampToValueAtTime(vol, endTime);\n    }\n    /**\n     *  Link effects together in a chain\n     *  Example usage: filter.chain(reverb, delay, panner);\n     *  May be used with an open-ended number of arguments\n     *\n     *  @method chain\n     *  @for p5.Effect\n     *  @param {Object} [arguments]  Chain together multiple sound objects\n     */\n\n  }, {\n    key: \"chain\",\n    value: function chain() {\n      if (arguments.length > 0) {\n        this.connect(arguments[0]);\n\n        for (var i = 1; i < arguments.length; i += 1) {\n          arguments[i - 1].connect(arguments[i]);\n        }\n      }\n\n      return this;\n    }\n    /**\n     *  Adjust the dry/wet value.\n     *\n     *  @method drywet\n     *  @for p5.Effect\n     *  @param {Number} [fade] The desired drywet value (0 - 1.0)\n     */\n\n  }, {\n    key: \"drywet\",\n    value: function drywet(fade) {\n      if (typeof fade !== 'undefined') {\n        this._drywet.fade.value = fade;\n      }\n\n      return this._drywet.fade.value;\n    }\n    /**\n     *  Send output to a p5.js-sound, Web Audio Node, or use signal to\n     *  control an AudioParam\n     *\n     *  @method connect\n     *  @for p5.Effect\n     *  @param {Object} unit\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      var u = unit || p5.soundOut.input;\n      this.output.connect(u.input ? u.input : u);\n    }\n    /**\n     * Disconnect all output.\n     * @method disconnect\n     * @for p5.Effect\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.output) {\n        this.output.disconnect();\n      }\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n\n      if (this.input) {\n        this.input.disconnect();\n        delete this.input;\n      }\n\n      if (this.output) {\n        this.output.disconnect();\n        delete this.output;\n      }\n\n      if (this._drywet) {\n        this._drywet.disconnect();\n\n        delete this._drywet;\n      }\n\n      if (this.wet) {\n        this.wet.disconnect();\n        delete this.wet;\n      }\n\n      this.ac = undefined;\n    }\n  }]);\n\n  return Effect;\n}();\n\n var effect = (effect_Effect);\nfunction filter_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { filter_typeof = function _typeof(obj) { return typeof obj; }; } else { filter_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return filter_typeof(obj); }\n\nfunction filter_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction filter_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction filter_createClass(Constructor, protoProps, staticProps) { if (protoProps) filter_defineProperties(Constructor.prototype, protoProps); if (staticProps) filter_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction filter_possibleConstructorReturn(self, call) { if (call && (filter_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return filter_assertThisInitialized(self); }\n\nfunction filter_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { _get = Reflect.get; } else { _get = function _get(target, property, receiver) { var base = _superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return _get(target, property, receiver || target); }\n\nfunction _superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = filter_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction filter_getPrototypeOf(o) { filter_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return filter_getPrototypeOf(o); }\n\nfunction filter_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) filter_setPrototypeOf(subClass, superClass); }\n\nfunction filter_setPrototypeOf(o, p) { filter_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return filter_setPrototypeOf(o, p); }\n\n\n/**\n *  <p>A p5.Filter uses a Web Audio Biquad Filter to filter\n *  the frequency response of an input source. Subclasses\n *  include:</p>\n *  <a href=\"/reference/#/p5.LowPass\"><code>p5.LowPass</code></a>:\n *  Allows frequencies below the cutoff frequency to pass through,\n *  and attenuates frequencies above the cutoff.<br/>\n *  <a href=\"/reference/#/p5.HighPass\"><code>p5.HighPass</code></a>:\n *  The opposite of a lowpass filter. <br/>\n *  <a href=\"/reference/#/p5.BandPass\"><code>p5.BandPass</code></a>:\n *  Allows a range of frequencies to pass through and attenuates\n *  the frequencies below and above this frequency range.<br/>\n *\n *  The <code>.res()</code> method controls either width of the\n *  bandpass, or resonance of the low/highpass cutoff frequency.\n *\n *  This class extends <a href = \"/reference/#/p5.Effect\">p5.Effect</a>.\n *  Methods <a href = \"/reference/#/p5.Effect/amp\">amp()</a>, <a href = \"/reference/#/p5.Effect/chain\">chain()</a>,\n *  <a href = \"/reference/#/p5.Effect/drywet\">drywet()</a>, <a href = \"/reference/#/p5.Effect/connect\">connect()</a>, and\n *  <a href = \"/reference/#/p5.Effect/disconnect\">disconnect()</a> are available.\n *\n *  @class p5.Filter\n *  @extends p5.Effect\n *  @constructor\n *  @param {String} [type] 'lowpass' (default), 'highpass', 'bandpass'\n *  @example\n *  <div><code>\n *  let fft, noise, filter;\n *\n *  function setup() {\n *    let cnv = createCanvas(100,100);\n *    cnv.mousePressed(makeNoise);\n *    fill(255, 0, 255);\n *\n *    filter = new p5.BandPass();\n *    noise = new p5.Noise();\n *    noise.disconnect();\n *    noise.connect(filter);\n *\n *    fft = new p5.FFT();\n *  }\n *\n *  function draw() {\n *    background(220);\n *\n *    // set the BandPass frequency based on mouseX\n *    let freq = map(mouseX, 0, width, 20, 10000);\n *    freq = constrain(freq, 0, 22050);\n *    filter.freq(freq);\n *    // give the filter a narrow band (lower res = wider bandpass)\n *    filter.res(50);\n *\n *    // draw filtered spectrum\n *    let spectrum = fft.analyze();\n *    noStroke();\n *    for (let i = 0; i < spectrum.length; i++) {\n *      let x = map(i, 0, spectrum.length, 0, width);\n *      let h = -height + map(spectrum[i], 0, 255, height, 0);\n *      rect(x, height, width/spectrum.length, h);\n *    }\n *    if (!noise.started) {\n *      text('tap here and drag to change frequency', 10, 20, width - 20);\n *    } else {\n *      text('Frequency: ' + round(freq)+'Hz', 20, 20, width - 20);\n *    }\n *  }\n *\n *  function makeNoise() {\n *    // see also: `userStartAudio()`\n *    noise.start();\n *    noise.amp(0.5, 0.2);\n *  }\n *\n *  function mouseReleased() {\n *    noise.amp(0, 0.2);\n *  }\n *\n *  </code></div>\n */\n\nvar Filter =\nfunction (_Effect) {\n  filter_inherits(Filter, _Effect);\n\n  function Filter(type) {\n    var _this;\n\n    filter_classCallCheck(this, Filter);\n\n    _this = filter_possibleConstructorReturn(this, filter_getPrototypeOf(Filter).call(this)); \n\n    /**\n     *  The p5.Filter is built with a\n     *  <a href=\"http://www.w3.org/TR/webaudio/#BiquadFilterNode\">\n     *  Web Audio BiquadFilter Node</a>.\n     *\n     *  @property {DelayNode} biquadFilter\n     */\n\n    _this.biquad = _this.ac.createBiquadFilter();\n\n    _this.input.connect(_this.biquad);\n\n    _this.biquad.connect(_this.wet);\n\n    if (type) {\n      _this.setType(type);\n    } \n\n\n    _this._on = true;\n    _this._untoggledType = _this.biquad.type;\n    return _this;\n  }\n  /**\n   *  Filter an audio signal according to a set\n   *  of filter parameters.\n   *\n   *  @method  process\n   *  @param  {Object} Signal  An object that outputs audio\n   *  @param {Number} [freq] Frequency in Hz, from 10 to 22050\n   *  @param {Number} [res] Resonance/Width of the filter frequency\n   *                        from 0.001 to 1000\n   */\n\n\n  filter_createClass(Filter, [{\n    key: \"process\",\n    value: function process(src, freq, res, time) {\n      src.connect(this.input);\n      this.set(freq, res, time);\n    }\n    /**\n     *  Set the frequency and the resonance of the filter.\n     *\n     *  @method  set\n     *  @param {Number} [freq] Frequency in Hz, from 10 to 22050\n     *  @param {Number} [res]  Resonance (Q) from 0.001 to 1000\n     *  @param {Number} [timeFromNow] schedule this event to happen\n     *                                seconds from now\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(freq, res, time) {\n      if (freq) {\n        this.freq(freq, time);\n      }\n\n      if (res) {\n        this.res(res, time);\n      }\n    }\n    /**\n     *  Set the filter frequency, in Hz, from 10 to 22050 (the range of\n     *  human hearing, although in reality most people hear in a narrower\n     *  range).\n     *\n     *  @method  freq\n     *  @param  {Number} freq Filter Frequency\n     *  @param {Number} [timeFromNow] schedule this event to happen\n     *                                seconds from now\n     *  @return {Number} value  Returns the current frequency value\n     */\n\n  }, {\n    key: \"freq\",\n    value: function freq(_freq, time) {\n      var t = time || 0;\n\n      if (_freq <= 0) {\n        _freq = 1;\n      }\n\n      if (typeof _freq === 'number') {\n        this.biquad.frequency.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.biquad.frequency.exponentialRampToValueAtTime(_freq, this.ac.currentTime + 0.02 + t);\n      } else if (_freq) {\n        _freq.connect(this.biquad.frequency);\n      }\n\n      return this.biquad.frequency.value;\n    }\n    /**\n     *  Controls either width of a bandpass frequency,\n     *  or the resonance of a low/highpass cutoff frequency.\n     *\n     *  @method  res\n     *  @param {Number} res  Resonance/Width of filter freq\n     *                       from 0.001 to 1000\n     *  @param {Number} [timeFromNow] schedule this event to happen\n     *                                seconds from now\n     *  @return {Number} value Returns the current res value\n     */\n\n  }, {\n    key: \"res\",\n    value: function res(_res, time) {\n      var t = time || 0;\n\n      if (typeof _res === 'number') {\n        this.biquad.Q.value = _res;\n        this.biquad.Q.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.biquad.Q.linearRampToValueAtTime(_res, this.ac.currentTime + 0.02 + t);\n      } else if (_res) {\n        _res.connect(this.biquad.Q);\n      }\n\n      return this.biquad.Q.value;\n    }\n    /**\n     * Controls the gain attribute of a Biquad Filter.\n     * This is distinctly different from .amp() which is inherited from p5.Effect\n     * .amp() controls the volume via the output gain node\n     * p5.Filter.gain() controls the gain parameter of a Biquad Filter node.\n     *\n     * @method gain\n     * @param  {Number} gain\n     * @return {Number} Returns the current or updated gain value\n     */\n\n  }, {\n    key: \"gain\",\n    value: function gain(_gain, time) {\n      var t = time || 0;\n\n      if (typeof _gain === 'number') {\n        this.biquad.gain.value = _gain;\n        this.biquad.gain.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.biquad.gain.linearRampToValueAtTime(_gain, this.ac.currentTime + 0.02 + t);\n      } else if (_gain) {\n        _gain.connect(this.biquad.gain);\n      }\n\n      return this.biquad.gain.value;\n    }\n    /**\n     * Toggle function. Switches between the specified type and allpass\n     *\n     * @method toggle\n     * @return {boolean} [Toggle value]\n     */\n\n  }, {\n    key: \"toggle\",\n    value: function toggle() {\n      this._on = !this._on;\n\n      if (this._on === true) {\n        this.biquad.type = this._untoggledType;\n      } else if (this._on === false) {\n        this.biquad.type = 'allpass';\n      }\n\n      return this._on;\n    }\n    /**\n     *  Set the type of a p5.Filter. Possible types include:\n     *  \"lowpass\" (default), \"highpass\", \"bandpass\",\n     *  \"lowshelf\", \"highshelf\", \"peaking\", \"notch\",\n     *  \"allpass\".\n     *\n     *  @method  setType\n     *  @param {String} t\n     */\n\n  }, {\n    key: \"setType\",\n    value: function setType(t) {\n      this.biquad.type = t;\n      this._untoggledType = this.biquad.type;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      _get(filter_getPrototypeOf(Filter.prototype), \"dispose\", this).call(this);\n\n      if (this.biquad) {\n        this.biquad.disconnect();\n        delete this.biquad;\n      }\n    }\n  }]);\n\n  return Filter;\n}(effect);\n/**\n *  Constructor: <code>new p5.LowPass()</code> Filter.\n *  This is the same as creating a p5.Filter and then calling\n *  its method <code>setType('lowpass')</code>.\n *  See p5.Filter for methods.\n *\n *  @class p5.LowPass\n *  @constructor\n *  @extends p5.Filter\n */\n\n\nvar LowPass =\nfunction (_Filter) {\n  filter_inherits(LowPass, _Filter);\n\n  function LowPass() {\n    filter_classCallCheck(this, LowPass);\n\n    return filter_possibleConstructorReturn(this, filter_getPrototypeOf(LowPass).call(this, 'lowpass'));\n  }\n\n  return LowPass;\n}(Filter);\n/**\n *  Constructor: <code>new p5.HighPass()</code> Filter.\n *  This is the same as creating a p5.Filter and then calling\n *  its method <code>setType('highpass')</code>.\n *  See p5.Filter for methods.\n *\n *  @class p5.HighPass\n *  @constructor\n *  @extends p5.Filter\n */\n\n\nvar HighPass =\nfunction (_Filter2) {\n  filter_inherits(HighPass, _Filter2);\n\n  function HighPass() {\n    filter_classCallCheck(this, HighPass);\n\n    return filter_possibleConstructorReturn(this, filter_getPrototypeOf(HighPass).call(this, 'highpass'));\n  }\n\n  return HighPass;\n}(Filter);\n/**\n *  Constructor: <code>new p5.BandPass()</code> Filter.\n *  This is the same as creating a p5.Filter and then calling\n *  its method <code>setType('bandpass')</code>.\n *  See p5.Filter for methods.\n *\n *  @class p5.BandPass\n *  @constructor\n *  @extends p5.Filter\n */\n\n\nvar BandPass =\nfunction (_Filter3) {\n  filter_inherits(BandPass, _Filter3);\n\n  function BandPass() {\n    filter_classCallCheck(this, BandPass);\n\n    return filter_possibleConstructorReturn(this, filter_getPrototypeOf(BandPass).call(this, 'bandpass'));\n  }\n\n  return BandPass;\n}(Filter);\n\n var filter = (Filter);\n\nfunction eqFilter_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { eqFilter_typeof = function _typeof(obj) { return typeof obj; }; } else { eqFilter_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return eqFilter_typeof(obj); }\n\nfunction eqFilter_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction eqFilter_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction eqFilter_createClass(Constructor, protoProps, staticProps) { if (protoProps) eqFilter_defineProperties(Constructor.prototype, protoProps); if (staticProps) eqFilter_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction eqFilter_possibleConstructorReturn(self, call) { if (call && (eqFilter_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return eqFilter_assertThisInitialized(self); }\n\nfunction eqFilter_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction eqFilter_getPrototypeOf(o) { eqFilter_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return eqFilter_getPrototypeOf(o); }\n\nfunction eqFilter_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) eqFilter_setPrototypeOf(subClass, superClass); }\n\nfunction eqFilter_setPrototypeOf(o, p) { eqFilter_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return eqFilter_setPrototypeOf(o, p); }\n\n\n\n/**\n *  EQFilter extends p5.Filter with constraints\n *  necessary for the p5.EQ\n *\n *  @private\n */\n\nvar eqFilter_EQFilter =\nfunction (_Filter) {\n  eqFilter_inherits(EQFilter, _Filter);\n\n  function EQFilter(freq, res) {\n    var _this;\n\n    eqFilter_classCallCheck(this, EQFilter);\n\n    _this = eqFilter_possibleConstructorReturn(this, eqFilter_getPrototypeOf(EQFilter).call(this, 'peaking'));\n\n    _this.disconnect();\n\n    _this.set(freq, res);\n\n    _this.biquad.gain.value = 0;\n    delete _this.input;\n    delete _this.output;\n    delete _this._drywet;\n    delete _this.wet;\n    return _this;\n  }\n\n  eqFilter_createClass(EQFilter, [{\n    key: \"amp\",\n    value: function amp() {\n      console.warn('`amp()` is not available for p5.EQ bands. Use `.gain()`');\n    }\n  }, {\n    key: \"drywet\",\n    value: function drywet() {\n      console.warn('`drywet()` is not available for p5.EQ bands.');\n    }\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      var u = unit || p5.soundOut.input;\n\n      if (this.biquad) {\n        this.biquad.connect(u.input ? u.input : u);\n      } else {\n        this.output.connect(u.input ? u.input : u);\n      }\n    }\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.biquad) {\n        this.biquad.disconnect();\n      }\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n      this.disconnect();\n      delete this.biquad;\n    }\n  }]);\n\n  return EQFilter;\n}(filter);\n\n var eqFilter = (eqFilter_EQFilter);\nfunction eq_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { eq_typeof = function _typeof(obj) { return typeof obj; }; } else { eq_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return eq_typeof(obj); }\n\nfunction eq_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction eq_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction eq_createClass(Constructor, protoProps, staticProps) { if (protoProps) eq_defineProperties(Constructor.prototype, protoProps); if (staticProps) eq_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction eq_possibleConstructorReturn(self, call) { if (call && (eq_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return eq_assertThisInitialized(self); }\n\nfunction eq_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction eq_get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { eq_get = Reflect.get; } else { eq_get = function _get(target, property, receiver) { var base = eq_superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return eq_get(target, property, receiver || target); }\n\nfunction eq_superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = eq_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction eq_getPrototypeOf(o) { eq_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return eq_getPrototypeOf(o); }\n\nfunction eq_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) eq_setPrototypeOf(subClass, superClass); }\n\nfunction eq_setPrototypeOf(o, p) { eq_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return eq_setPrototypeOf(o, p); }\n\n\n\n/**\n * p5.EQ is an audio effect that performs the function of a multiband\n * audio equalizer. Equalization is used to adjust the balance of\n * frequency compoenents of an audio signal. This process is commonly used\n * in sound production and recording to change the waveform before it reaches\n * a sound output device. EQ can also be used as an audio effect to create\n * interesting distortions by filtering out parts of the spectrum. p5.EQ is\n * built using a chain of Web Audio Biquad Filter Nodes and can be\n * instantiated with 3 or 8 bands. Bands can be added or removed from\n * the EQ by directly modifying p5.EQ.bands (the array that stores filters).\n *\n * This class extends <a href = \"/reference/#/p5.Effect\">p5.Effect</a>.\n * Methods <a href = \"/reference/#/p5.Effect/amp\">amp()</a>, <a href = \"/reference/#/p5.Effect/chain\">chain()</a>,\n * <a href = \"/reference/#/p5.Effect/drywet\">drywet()</a>, <a href = \"/reference/#/p5.Effect/connect\">connect()</a>, and\n * <a href = \"/reference/#/p5.Effect/disconnect\">disconnect()</a> are available.\n *\n * @class p5.EQ\n * @constructor\n * @extends p5.Effect\n * @param {Number} [_eqsize] Constructor will accept 3 or 8, defaults to 3\n * @return {Object} p5.EQ object\n *\n * @example\n * <div><code>\n * let eq, soundFile\n * let eqBandIndex = 0;\n * let eqBandNames = ['lows', 'mids', 'highs'];\n *\n * function preload() {\n *   soundFormats('mp3', 'ogg');\n *   soundFile = loadSound('assets/beat');\n * }\n *\n * function setup() {\n *   let cnv = createCanvas(100, 100);\n *   cnv.mousePressed(toggleSound);\n *\n *   eq = new p5.EQ(eqBandNames.length);\n *   soundFile.disconnect();\n *   eq.process(soundFile);\n * }\n *\n * function draw() {\n *   background(30);\n *   noStroke();\n *   fill(255);\n *   textAlign(CENTER);\n *   text('filtering ', 50, 25);\n *\n *   fill(255, 40, 255);\n *   textSize(26);\n *   text(eqBandNames[eqBandIndex], 50, 55);\n *\n *   fill(255);\n *   textSize(9);\n *\n *   if (!soundFile.isPlaying()) {\n *     text('tap to play', 50, 80);\n *   } else {\n *     text('tap to filter next band', 50, 80)\n *   }\n * }\n *\n * function toggleSound() {\n *   if (!soundFile.isPlaying()) {\n *     soundFile.play();\n *   } else {\n *     eqBandIndex = (eqBandIndex + 1) % eq.bands.length;\n *   }\n *\n *   for (let i = 0; i < eq.bands.length; i++) {\n *     eq.bands[i].gain(0);\n *   }\n *   // filter the band we want to filter\n *   eq.bands[eqBandIndex].gain(-40);\n * }\n * </code></div>\n */\n\nvar eq_EQ =\nfunction (_Effect) {\n  eq_inherits(EQ, _Effect);\n\n  function EQ(_eqsize) {\n    var _this;\n\n    eq_classCallCheck(this, EQ);\n\n    _this = eq_possibleConstructorReturn(this, eq_getPrototypeOf(EQ).call(this)); \n\n    _eqsize = _eqsize === 3 || _eqsize === 8 ? _eqsize : 3;\n    var factor;\n    _eqsize === 3 ? factor = Math.pow(2, 3) : factor = 2;\n    /**\n     *  The p5.EQ is built with abstracted p5.Filter objects.\n     *  To modify any bands, use methods of the <a\n     *  href=\"/reference/#/p5.Filter\" title=\"p5.Filter reference\">\n     *  p5.Filter</a> API, especially `gain` and `freq`.\n     *  Bands are stored in an array, with indices 0 - 3, or 0 - 7\n     *  @property {Array}  bands\n     *\n     */\n\n    _this.bands = [];\n    var freq, res;\n\n    for (var i = 0; i < _eqsize; i++) {\n      if (i === _eqsize - 1) {\n        freq = 21000;\n        res = 0.01;\n      } else if (i === 0) {\n        freq = 100;\n        res = 0.1;\n      } else if (i === 1) {\n        freq = _eqsize === 3 ? 360 * factor : 360;\n        res = 1;\n      } else {\n        freq = _this.bands[i - 1].freq() * factor;\n        res = 1;\n      }\n\n      _this.bands[i] = _this._newBand(freq, res);\n\n      if (i > 0) {\n        _this.bands[i - 1].connect(_this.bands[i].biquad);\n      } else {\n        _this.input.connect(_this.bands[i].biquad);\n      }\n    }\n\n    _this.bands[_eqsize - 1].connect(_this.output);\n\n    return _this;\n  }\n  /**\n   * Process an input by connecting it to the EQ\n   * @method  process\n   * @param  {Object} src Audio source\n   */\n\n\n  eq_createClass(EQ, [{\n    key: \"process\",\n    value: function process(src) {\n      src.connect(this.input);\n    } \n    //   * Set the frequency and gain of each band in the EQ. This method should be\n    //   * called with 3 or 8 frequency and gain pairs, depending on the size of the EQ.\n    //   * ex. eq.set(freq0, gain0, freq1, gain1, freq2, gain2);\n    //   *\n    //   * @method  set\n    //   * @for p5.EQ\n    //   * @param {Number} [freq0] Frequency value for band with index 0\n    //   * @param {Number} [gain0] Gain value for band with index 0\n    //   * @param {Number} [freq1] Frequency value for band with index 1\n    //   * @param {Number} [gain1] Gain value for band with index 1\n    //   * @param {Number} [freq2] Frequency value for band with index 2\n    //   * @param {Number} [gain2] Gain value for band with index 2\n    //   * @param {Number} [freq3] Frequency value for band with index 3\n    //   * @param {Number} [gain3] Gain value for band with index 3\n    //   * @param {Number} [freq4] Frequency value for band with index 4\n    //   * @param {Number} [gain4] Gain value for band with index 4\n    //   * @param {Number} [freq5] Frequency value for band with index 5\n    //   * @param {Number} [gain5] Gain value for band with index 5\n    //   * @param {Number} [freq6] Frequency value for band with index 6\n    //   * @param {Number} [gain6] Gain value for band with index 6\n    //   * @param {Number} [freq7] Frequency value for band with index 7\n    //   * @param {Number} [gain7] Gain value for band with index 7\n    //   */\n\n  }, {\n    key: \"set\",\n    value: function set() {\n      if (arguments.length === this.bands.length * 2) {\n        for (var i = 0; i < arguments.length; i += 2) {\n          this.bands[i / 2].freq(arguments[i]);\n          this.bands[i / 2].gain(arguments[i + 1]);\n        }\n      } else {\n        console.error('Argument mismatch. .set() should be called with ' + this.bands.length * 2 + ' arguments. (one frequency and gain value pair for each band of the eq)');\n      }\n    }\n    /**\n     * Add a new band. Creates a p5.Filter and strips away everything but\n     * the raw biquad filter. This method returns an abstracted p5.Filter,\n     * which can be added to p5.EQ.bands, in order to create new EQ bands.\n     * @private\n     * @for p5.EQ\n     * @method  _newBand\n     * @param  {Number} freq\n     * @param  {Number} res\n     * @return {Object}      Abstracted Filter\n     */\n\n  }, {\n    key: \"_newBand\",\n    value: function _newBand(freq, res) {\n      return new eqFilter(freq, res);\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      eq_get(eq_getPrototypeOf(EQ.prototype), \"dispose\", this).call(this);\n\n      if (this.bands) {\n        while (this.bands.length > 0) {\n          delete this.bands.pop().dispose();\n        }\n\n        delete this.bands;\n      }\n    }\n  }]);\n\n  return EQ;\n}(effect);\n\n var eq = (eq_EQ);\nfunction listener3d_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction listener3d_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction listener3d_createClass(Constructor, protoProps, staticProps) { if (protoProps) listener3d_defineProperties(Constructor.prototype, protoProps); if (staticProps) listener3d_defineProperties(Constructor, staticProps); return Constructor; }\n\n//   * listener is a class that can construct both a Spatial Panner\n//   * and a Spatial Listener. The panner is based on the\n//   * Web Audio Spatial Panner Node\n//   * https://www.w3.org/TR/webaudio/#the-listenernode-interface\n//   * This panner is a spatial processing node that allows audio to be positioned\n//   * and oriented in 3D space.\n//   *\n//   * The Listener modifies the properties of the Audio Context Listener.\n//   * Both objects types use the same methods. The default is a spatial panner.\n//   *\n//   * <code>p5.Panner3D</code> - Constructs a Spatial Panner<br/>\n//   * <code>p5.Listener3D</code> - Constructs a Spatial Listener<br/>\n//   *\n//   * @class listener\n//   * @constructor\n//   * @return {Object} p5.Listener3D Object\n//   *\n//   * @param {Web Audio Node} listener Web Audio Spatial Panning Node\n//   * @param {AudioParam} listener.panningModel \"equal power\" or \"HRTF\"\n//   * @param {AudioParam} listener.distanceModel \"linear\", \"inverse\", or \"exponential\"\n//   * @param {String} [type] [Specify construction of a spatial panner or listener]\n//   */\n\nvar listener3d_Listener3D =\nfunction () {\n  function Listener3D(type) {\n    listener3d_classCallCheck(this, Listener3D);\n\n    this.ac = main.audiocontext;\n    this.listener = this.ac.listener;\n  } \n  //   * Connect an audio sorce\n  //   * @param  {Object} src Input source\n  //   */\n\n\n  listener3d_createClass(Listener3D, [{\n    key: \"process\",\n    value: function process(src) {\n      src.connect(this.input);\n    } \n    //   * Set the X,Y,Z position of the Panner\n    //   * @param  {[Number]} xVal\n    //   * @param  {[Number]} yVal\n    //   * @param  {[Number]} zVal\n    //   * @param  {[Number]} time\n    //   * @return {[Array]}      [Updated x, y, z values as an array]\n    //   */\n\n  }, {\n    key: \"position\",\n    value: function position(xVal, yVal, zVal, time) {\n      this.positionX(xVal, time);\n      this.positionY(yVal, time);\n      this.positionZ(zVal, time);\n      return [this.listener.positionX.value, this.listener.positionY.value, this.listener.positionZ.value];\n    } \n    //   * Getter and setter methods for position coordinates\n    //   * @return {Number}      [updated coordinate value]\n    //   */\n\n  }, {\n    key: \"positionX\",\n    value: function positionX(xVal, time) {\n      var t = time || 0;\n\n      if (typeof xVal === 'number') {\n        this.listener.positionX.value = xVal;\n        this.listener.positionX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.positionX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);\n      } else if (xVal) {\n        xVal.connect(this.listener.positionX);\n      }\n\n      return this.listener.positionX.value;\n    }\n  }, {\n    key: \"positionY\",\n    value: function positionY(yVal, time) {\n      var t = time || 0;\n\n      if (typeof yVal === 'number') {\n        this.listener.positionY.value = yVal;\n        this.listener.positionY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.positionY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);\n      } else if (yVal) {\n        yVal.connect(this.listener.positionY);\n      }\n\n      return this.listener.positionY.value;\n    }\n  }, {\n    key: \"positionZ\",\n    value: function positionZ(zVal, time) {\n      var t = time || 0;\n\n      if (typeof zVal === 'number') {\n        this.listener.positionZ.value = zVal;\n        this.listener.positionZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.positionZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);\n      } else if (zVal) {\n        zVal.connect(this.listener.positionZ);\n      }\n\n      return this.listener.positionZ.value;\n    } \n    //   * Overrides the listener orient() method because Listener has slightly\n    //   * different params. In human terms, Forward vectors are the direction the\n    //   * nose is pointing. Up vectors are the direction of the top of the head.\n    //   *\n    //   * @method orient\n    //   * @param  {Number} xValF  Forward vector X direction\n    //   * @param  {Number} yValF  Forward vector Y direction\n    //   * @param  {Number} zValF  Forward vector Z direction\n    //   * @param  {Number} xValU  Up vector X direction\n    //   * @param  {Number} yValU  Up vector Y direction\n    //   * @param  {Number} zValU  Up vector Z direction\n    //   * @param  {Number} time\n    //   * @return {Array}       All orienation params\n    //   */\n\n  }, {\n    key: \"orient\",\n    value: function orient(xValF, yValF, zValF, xValU, yValU, zValU, time) {\n      if (arguments.length === 3 || arguments.length === 4) {\n        time = arguments[3];\n        this.orientForward(xValF, yValF, zValF, time);\n      } else if (arguments.length === 6 || arguments === 7) {\n        this.orientForward(xValF, yValF, zValF);\n        this.orientUp(xValU, yValU, zValU, time);\n      }\n\n      return [this.listener.forwardX.value, this.listener.forwardY.value, this.listener.forwardZ.value, this.listener.upX.value, this.listener.upY.value, this.listener.upZ.value];\n    }\n  }, {\n    key: \"orientForward\",\n    value: function orientForward(xValF, yValF, zValF, time) {\n      this.forwardX(xValF, time);\n      this.forwardY(yValF, time);\n      this.forwardZ(zValF, time);\n      return [this.listener.forwardX, this.listener.forwardY, this.listener.forwardZ];\n    }\n  }, {\n    key: \"orientUp\",\n    value: function orientUp(xValU, yValU, zValU, time) {\n      this.upX(xValU, time);\n      this.upY(yValU, time);\n      this.upZ(zValU, time);\n      return [this.listener.upX, this.listener.upY, this.listener.upZ];\n    } \n    //   * Getter and setter methods for orient coordinates\n    //   * @return {Number}      [updated coordinate value]\n    //   */\n\n  }, {\n    key: \"forwardX\",\n    value: function forwardX(xVal, time) {\n      var t = time || 0;\n\n      if (typeof xVal === 'number') {\n        this.listener.forwardX.value = xVal;\n        this.listener.forwardX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.forwardX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);\n      } else if (xVal) {\n        xVal.connect(this.listener.forwardX);\n      }\n\n      return this.listener.forwardX.value;\n    }\n  }, {\n    key: \"forwardY\",\n    value: function forwardY(yVal, time) {\n      var t = time || 0;\n\n      if (typeof yVal === 'number') {\n        this.listener.forwardY.value = yVal;\n        this.listener.forwardY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.forwardY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);\n      } else if (yVal) {\n        yVal.connect(this.listener.forwardY);\n      }\n\n      return this.listener.forwardY.value;\n    }\n  }, {\n    key: \"forwardZ\",\n    value: function forwardZ(zVal, time) {\n      var t = time || 0;\n\n      if (typeof zVal === 'number') {\n        this.listener.forwardZ.value = zVal;\n        this.listener.forwardZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.forwardZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);\n      } else if (zVal) {\n        zVal.connect(this.listener.forwardZ);\n      }\n\n      return this.listener.forwardZ.value;\n    }\n  }, {\n    key: \"upX\",\n    value: function upX(xVal, time) {\n      var t = time || 0;\n\n      if (typeof xVal === 'number') {\n        this.listener.upX.value = xVal;\n        this.listener.upX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.upX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);\n      } else if (xVal) {\n        xVal.connect(this.listener.upX);\n      }\n\n      return this.listener.upX.value;\n    }\n  }, {\n    key: \"upY\",\n    value: function upY(yVal, time) {\n      var t = time || 0;\n\n      if (typeof yVal === 'number') {\n        this.listener.upY.value = yVal;\n        this.listener.upY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.upY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);\n      } else if (yVal) {\n        yVal.connect(this.listener.upY);\n      }\n\n      return this.listener.upY.value;\n    }\n  }, {\n    key: \"upZ\",\n    value: function upZ(zVal, time) {\n      var t = time || 0;\n\n      if (typeof zVal === 'number') {\n        this.listener.upZ.value = zVal;\n        this.listener.upZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.listener.upZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);\n      } else if (zVal) {\n        zVal.connect(this.listener.upZ);\n      }\n\n      return this.listener.upZ.value;\n    }\n  }]);\n\n  return Listener3D;\n}();\n\n var listener3d = (listener3d_Listener3D);\nfunction panner3d_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { panner3d_typeof = function _typeof(obj) { return typeof obj; }; } else { panner3d_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return panner3d_typeof(obj); }\n\nfunction panner3d_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction panner3d_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction panner3d_createClass(Constructor, protoProps, staticProps) { if (protoProps) panner3d_defineProperties(Constructor.prototype, protoProps); if (staticProps) panner3d_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction panner3d_possibleConstructorReturn(self, call) { if (call && (panner3d_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return panner3d_assertThisInitialized(self); }\n\nfunction panner3d_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction panner3d_get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { panner3d_get = Reflect.get; } else { panner3d_get = function _get(target, property, receiver) { var base = panner3d_superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return panner3d_get(target, property, receiver || target); }\n\nfunction panner3d_superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = panner3d_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction panner3d_getPrototypeOf(o) { panner3d_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return panner3d_getPrototypeOf(o); }\n\nfunction panner3d_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) panner3d_setPrototypeOf(subClass, superClass); }\n\nfunction panner3d_setPrototypeOf(o, p) { panner3d_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return panner3d_setPrototypeOf(o, p); }\n\n\n/**\n * Panner3D is based on the <a title=\"Web Audio Panner docs\"  href=\n * \"https://developer.mozilla.org/en-US/docs/Web/API/PannerNode\">\n * Web Audio Spatial Panner Node</a>.\n * This panner is a spatial processing node that allows audio to be positioned\n * and oriented in 3D space.\n *\n * The position is relative to an <a title=\"Web Audio Listener docs\" href=\n * \"https://developer.mozilla.org/en-US/docs/Web/API/AudioListener\">\n * Audio Context Listener</a>, which can be accessed\n * by <code>p5.soundOut.audiocontext.listener</code>\n *\n *\n * @class p5.Panner3D\n * @constructor\n */\n\nvar Panner3D =\nfunction (_Effect) {\n  panner3d_inherits(Panner3D, _Effect);\n\n  function Panner3D() {\n    var _this;\n\n    panner3d_classCallCheck(this, Panner3D);\n\n    _this = panner3d_possibleConstructorReturn(this, panner3d_getPrototypeOf(Panner3D).call(this));\n    /**\n     *  <a title=\"Web Audio Panner docs\"  href=\n     *  \"https://developer.mozilla.org/en-US/docs/Web/API/PannerNode\">\n     *  Web Audio Spatial Panner Node</a>\n     *\n     *  Properties include<br>\n     * [Panning Model](https://www.w3.org/TR/webaudio/#idl-def-PanningModelType)\n     * : \"equal power\" or \"HRTF\"<br>\n     * [DistanceModel](https://www.w3.org/TR/webaudio/#idl-def-DistanceModelType)\n     *  : \"linear\", \"inverse\", or \"exponential\"\n     *\n     *  @property {AudioNode} panner\n     *\n     */\n\n    _this.panner = _this.ac.createPanner();\n    _this.panner.panningModel = 'HRTF';\n    _this.panner.distanceModel = 'linear';\n\n    _this.panner.connect(_this.output);\n\n    _this.input.connect(_this.panner);\n\n    return _this;\n  }\n  /**\n   * Connect an audio sorce\n   *\n   * @method  process\n   * @for p5.Panner3D\n   * @param  {Object} src Input source\n   */\n\n\n  panner3d_createClass(Panner3D, [{\n    key: \"process\",\n    value: function process(src) {\n      src.connect(this.input);\n    }\n    /**\n     * Set the X,Y,Z position of the Panner\n     * @method set\n     * @for p5.Panner3D\n     * @param  {Number} xVal\n     * @param  {Number} yVal\n     * @param  {Number} zVal\n     * @param  {Number} time\n     * @return {Array}      Updated x, y, z values as an array\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(xVal, yVal, zVal, time) {\n      this.positionX(xVal, time);\n      this.positionY(yVal, time);\n      this.positionZ(zVal, time);\n      return [this.panner.positionX.value, this.panner.positionY.value, this.panner.positionZ.value];\n    }\n    /**\n     * Getter and setter methods for position coordinates\n     * @method positionX\n     * @for p5.Panner3D\n     * @return {Number}      updated coordinate value\n     */\n\n    /**\n     * Getter and setter methods for position coordinates\n     * @method positionY\n     * @for p5.Panner3D\n     * @return {Number}      updated coordinate value\n     */\n\n    /**\n     * Getter and setter methods for position coordinates\n     * @method positionZ\n     * @for p5.Panner3D\n     * @return {Number}      updated coordinate value\n     */\n\n  }, {\n    key: \"positionX\",\n    value: function positionX(xVal, time) {\n      var t = time || 0;\n\n      if (typeof xVal === 'number') {\n        this.panner.positionX.value = xVal;\n        this.panner.positionX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.panner.positionX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);\n      } else if (xVal) {\n        xVal.connect(this.panner.positionX);\n      }\n\n      return this.panner.positionX.value;\n    }\n  }, {\n    key: \"positionY\",\n    value: function positionY(yVal, time) {\n      var t = time || 0;\n\n      if (typeof yVal === 'number') {\n        this.panner.positionY.value = yVal;\n        this.panner.positionY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.panner.positionY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);\n      } else if (yVal) {\n        yVal.connect(this.panner.positionY);\n      }\n\n      return this.panner.positionY.value;\n    }\n  }, {\n    key: \"positionZ\",\n    value: function positionZ(zVal, time) {\n      var t = time || 0;\n\n      if (typeof zVal === 'number') {\n        this.panner.positionZ.value = zVal;\n        this.panner.positionZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.panner.positionZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);\n      } else if (zVal) {\n        zVal.connect(this.panner.positionZ);\n      }\n\n      return this.panner.positionZ.value;\n    }\n    /**\n     * Set the X,Y,Z position of the Panner\n     * @method  orient\n     * @for p5.Panner3D\n     * @param  {Number} xVal\n     * @param  {Number} yVal\n     * @param  {Number} zVal\n     * @param  {Number} time\n     * @return {Array}      Updated x, y, z values as an array\n     */\n\n  }, {\n    key: \"orient\",\n    value: function orient(xVal, yVal, zVal, time) {\n      this.orientX(xVal, time);\n      this.orientY(yVal, time);\n      this.orientZ(zVal, time);\n      return [this.panner.orientationX.value, this.panner.orientationY.value, this.panner.orientationZ.value];\n    }\n    /**\n     * Getter and setter methods for orient coordinates\n     * @method orientX\n     * @for p5.Panner3D\n     * @return {Number}      updated coordinate value\n     */\n\n    /**\n     * Getter and setter methods for orient coordinates\n     * @method orientY\n     * @for p5.Panner3D\n     * @return {Number}      updated coordinate value\n     */\n\n    /**\n     * Getter and setter methods for orient coordinates\n     * @method orientZ\n     * @for p5.Panner3D\n     * @return {Number}      updated coordinate value\n     */\n\n  }, {\n    key: \"orientX\",\n    value: function orientX(xVal, time) {\n      var t = time || 0;\n\n      if (typeof xVal === 'number') {\n        this.panner.orientationX.value = xVal;\n        this.panner.orientationX.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.panner.orientationX.linearRampToValueAtTime(xVal, this.ac.currentTime + 0.02 + t);\n      } else if (xVal) {\n        xVal.connect(this.panner.orientationX);\n      }\n\n      return this.panner.orientationX.value;\n    }\n  }, {\n    key: \"orientY\",\n    value: function orientY(yVal, time) {\n      var t = time || 0;\n\n      if (typeof yVal === 'number') {\n        this.panner.orientationY.value = yVal;\n        this.panner.orientationY.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.panner.orientationY.linearRampToValueAtTime(yVal, this.ac.currentTime + 0.02 + t);\n      } else if (yVal) {\n        yVal.connect(this.panner.orientationY);\n      }\n\n      return this.panner.orientationY.value;\n    }\n  }, {\n    key: \"orientZ\",\n    value: function orientZ(zVal, time) {\n      var t = time || 0;\n\n      if (typeof zVal === 'number') {\n        this.panner.orientationZ.value = zVal;\n        this.panner.orientationZ.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.panner.orientationZ.linearRampToValueAtTime(zVal, this.ac.currentTime + 0.02 + t);\n      } else if (zVal) {\n        zVal.connect(this.panner.orientationZ);\n      }\n\n      return this.panner.orientationZ.value;\n    }\n    /**\n     * Set the rolloff factor and max distance\n     * @method  setFalloff\n     * @for p5.Panner3D\n     * @param {Number} [maxDistance]\n     * @param {Number} [rolloffFactor]\n     */\n\n  }, {\n    key: \"setFalloff\",\n    value: function setFalloff(maxDistance, rolloffFactor) {\n      this.maxDist(maxDistance);\n      this.rolloff(rolloffFactor);\n    }\n    /**\n     * Maxium distance between the source and the listener\n     * @method  maxDist\n     * @for p5.Panner3D\n     * @param  {Number} maxDistance\n     * @return {Number} updated value\n     */\n\n  }, {\n    key: \"maxDist\",\n    value: function maxDist(maxDistance) {\n      if (typeof maxDistance === 'number') {\n        this.panner.maxDistance = maxDistance;\n      }\n\n      return this.panner.maxDistance;\n    }\n    /**\n     * How quickly the volume is reduced as the source moves away from the listener\n     * @method  rollof\n     * @for p5.Panner3D\n     * @param  {Number} rolloffFactor\n     * @return {Number} updated value\n     */\n\n  }, {\n    key: \"rolloff\",\n    value: function rolloff(rolloffFactor) {\n      if (typeof rolloffFactor === 'number') {\n        this.panner.rolloffFactor = rolloffFactor;\n      }\n\n      return this.panner.rolloffFactor;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      panner3d_get(panner3d_getPrototypeOf(Panner3D.prototype), \"dispose\", this).call(this);\n\n      if (this.panner) {\n        this.panner.disconnect();\n        delete this.panner;\n      }\n    }\n  }]);\n\n  return Panner3D;\n}(effect);\n\n var panner3d = (Panner3D);\nfunction delay_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { delay_typeof = function _typeof(obj) { return typeof obj; }; } else { delay_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return delay_typeof(obj); }\n\nfunction delay_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction delay_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction delay_createClass(Constructor, protoProps, staticProps) { if (protoProps) delay_defineProperties(Constructor.prototype, protoProps); if (staticProps) delay_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction delay_possibleConstructorReturn(self, call) { if (call && (delay_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return delay_assertThisInitialized(self); }\n\nfunction delay_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction delay_get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { delay_get = Reflect.get; } else { delay_get = function _get(target, property, receiver) { var base = delay_superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return delay_get(target, property, receiver || target); }\n\nfunction delay_superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = delay_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction delay_getPrototypeOf(o) { delay_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return delay_getPrototypeOf(o); }\n\nfunction delay_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) delay_setPrototypeOf(subClass, superClass); }\n\nfunction delay_setPrototypeOf(o, p) { delay_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return delay_setPrototypeOf(o, p); }\n\n\n\n/**\n *  Delay is an echo effect. It processes an existing sound source,\n *  and outputs a delayed version of that sound. The p5.Delay can\n *  produce different effects depending on the delayTime, feedback,\n *  filter, and type. In the example below, a feedback of 0.5 (the\n *  default value) will produce a looping delay that decreases in\n *  volume by 50% each repeat. A filter will cut out the high\n *  frequencies so that the delay does not sound as piercing as the\n *  original source.\n *\n *\n *  This class extends <a href = \"/reference/#/p5.Effect\">p5.Effect</a>.\n *  Methods <a href = \"/reference/#/p5.Effect/amp\">amp()</a>, <a href = \"/reference/#/p5.Effect/chain\">chain()</a>,\n *  <a href = \"/reference/#/p5.Effect/drywet\">drywet()</a>, <a href = \"/reference/#/p5.Effect/connect\">connect()</a>, and\n *  <a href = \"/reference/#/p5.Effect/disconnect\">disconnect()</a> are available.\n *  @class p5.Delay\n *  @extends p5.Effect\n *  @constructor\n *  @example\n *  <div><code>\n *  let osc;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    background(220);\n *    textAlign(CENTER);\n *    text('tap to play', width/2, height/2);\n *\n *    osc = new p5.Oscillator('square');\n *    osc.amp(0.5);\n *    delay = new p5.Delay();\n *\n *    // delay.process() accepts 4 parameters:\n *    // source, delayTime (in seconds), feedback, filter frequency\n *    delay.process(osc, 0.12, .7, 2300);\n *\n *    cnv.mousePressed(oscStart);\n *  }\n *\n *  function oscStart() {\n *    osc.start();\n *  }\n *\n *  function mouseReleased() {\n *    osc.stop();\n *  }\n *  </code></div>\n */\n\nvar delay_Delay =\nfunction (_Effect) {\n  delay_inherits(Delay, _Effect);\n\n  function Delay() {\n    var _this;\n\n    delay_classCallCheck(this, Delay);\n\n    _this = delay_possibleConstructorReturn(this, delay_getPrototypeOf(Delay).call(this));\n    _this._split = _this.ac.createChannelSplitter(2);\n    _this._merge = _this.ac.createChannelMerger(2);\n    _this._leftGain = _this.ac.createGain();\n    _this._rightGain = _this.ac.createGain();\n    /**\n     *  The p5.Delay is built with two\n     *  <a href=\"http://www.w3.org/TR/webaudio/#DelayNode\">\n     *  Web Audio Delay Nodes</a>, one for each stereo channel.\n     *\n     *  @for p5.Delay\n     *  @property {DelayNode} leftDelay\n     */\n\n    _this.leftDelay = _this.ac.createDelay();\n    /**\n     *  The p5.Delay is built with two\n     *  <a href=\"http://www.w3.org/TR/webaudio/#DelayNode\">\n     *  Web Audio Delay Nodes</a>, one for each stereo channel.\n     *  @for p5.Delay\n     *  @property {DelayNode} rightDelay\n     */\n\n    _this.rightDelay = _this.ac.createDelay();\n    _this._leftFilter = new filter();\n    _this._rightFilter = new filter();\n\n    _this._leftFilter.disconnect();\n\n    _this._rightFilter.disconnect();\n\n    _this._leftFilter.biquad.frequency.setValueAtTime(1200, _this.ac.currentTime);\n\n    _this._rightFilter.biquad.frequency.setValueAtTime(1200, _this.ac.currentTime);\n\n    _this._leftFilter.biquad.Q.setValueAtTime(0.3, _this.ac.currentTime);\n\n    _this._rightFilter.biquad.Q.setValueAtTime(0.3, _this.ac.currentTime); \n\n\n    _this.input.connect(_this._split);\n\n    _this.leftDelay.connect(_this._leftGain);\n\n    _this.rightDelay.connect(_this._rightGain);\n\n    _this._leftGain.connect(_this._leftFilter.input);\n\n    _this._rightGain.connect(_this._rightFilter.input);\n\n    _this._merge.connect(_this.wet);\n\n    _this._leftFilter.biquad.gain.setValueAtTime(1, _this.ac.currentTime);\n\n    _this._rightFilter.biquad.gain.setValueAtTime(1, _this.ac.currentTime); \n\n\n    _this.setType(0);\n\n    _this._maxDelay = _this.leftDelay.delayTime.maxValue; \n\n    _this.feedback(0.5);\n\n    return _this;\n  }\n  /**\n   *  Add delay to an audio signal according to a set\n   *  of delay parameters.\n   *\n   *  @method  process\n   *  @for p5.Delay\n   *  @param  {Object} Signal  An object that outputs audio\n   *  @param  {Number} [delayTime] Time (in seconds) of the delay/echo.\n   *                               Some browsers limit delayTime to\n   *                               1 second.\n   *  @param  {Number} [feedback]  sends the delay back through itself\n   *                               in a loop that decreases in volume\n   *                               each time.\n   *  @param  {Number} [lowPass]   Cutoff frequency. Only frequencies\n   *                               below the lowPass will be part of the\n   *                               delay.\n   */\n\n\n  delay_createClass(Delay, [{\n    key: \"process\",\n    value: function process(src, _delayTime, _feedback, _filter) {\n      var feedback = _feedback || 0;\n      var delayTime = _delayTime || 0;\n\n      if (feedback >= 1.0) {\n        throw new Error('Feedback value will force a positive feedback loop.');\n      }\n\n      if (delayTime >= this._maxDelay) {\n        throw new Error('Delay Time exceeds maximum delay time of ' + this._maxDelay + ' second.');\n      }\n\n      src.connect(this.input);\n      this.leftDelay.delayTime.setValueAtTime(delayTime, this.ac.currentTime);\n      this.rightDelay.delayTime.setValueAtTime(delayTime, this.ac.currentTime);\n      this._leftGain.gain.value = feedback;\n      this._rightGain.gain.value = feedback;\n\n      if (_filter) {\n        this._leftFilter.freq(_filter);\n\n        this._rightFilter.freq(_filter);\n      }\n    }\n    /**\n     *  Set the delay (echo) time, in seconds. Usually this value will be\n     *  a floating point number between 0.0 and 1.0.\n     *\n     *  @method  delayTime\n     *  @for p5.Delay\n     *  @param {Number} delayTime Time (in seconds) of the delay\n     */\n\n  }, {\n    key: \"delayTime\",\n    value: function delayTime(t) {\n      if (typeof t !== 'number') {\n        t.connect(this.leftDelay.delayTime);\n        t.connect(this.rightDelay.delayTime);\n      } else {\n        this.leftDelay.delayTime.cancelScheduledValues(this.ac.currentTime);\n        this.rightDelay.delayTime.cancelScheduledValues(this.ac.currentTime);\n        this.leftDelay.delayTime.linearRampToValueAtTime(t, this.ac.currentTime);\n        this.rightDelay.delayTime.linearRampToValueAtTime(t, this.ac.currentTime);\n      }\n    }\n    /**\n     *  Feedback occurs when Delay sends its signal back through its input\n     *  in a loop. The feedback amount determines how much signal to send each\n     *  time through the loop. A feedback greater than 1.0 is not desirable because\n     *  it will increase the overall output each time through the loop,\n     *  creating an infinite feedback loop. The default value is 0.5\n     *\n     *  @method  feedback\n     *  @for p5.Delay\n     *  @param {Number|Object} feedback 0.0 to 1.0, or an object such as an\n     *                                  Oscillator that can be used to\n     *                                  modulate this param\n     *  @returns {Number} Feedback value\n     *\n     */\n\n  }, {\n    key: \"feedback\",\n    value: function feedback(f) {\n      if (f && typeof f !== 'number') {\n        f.connect(this._leftGain.gain);\n        f.connect(this._rightGain.gain);\n      } else if (f >= 1.0) {\n        throw new Error('Feedback value will force a positive feedback loop.');\n      } else if (typeof f === 'number') {\n        this._leftGain.gain.value = f;\n        this._rightGain.gain.value = f;\n      } \n\n\n      return this._leftGain.gain.value;\n    }\n    /**\n     *  Set a lowpass filter frequency for the delay. A lowpass filter\n     *  will cut off any frequencies higher than the filter frequency.\n     *\n     *  @method  filter\n     *  @for p5.Delay\n     *  @param {Number|Object} cutoffFreq  A lowpass filter will cut off any\n     *                              frequencies higher than the filter frequency.\n     *  @param {Number|Object} res  Resonance of the filter frequency\n     *                              cutoff, or an object (i.e. a p5.Oscillator)\n     *                              that can be used to modulate this parameter.\n     *                              High numbers (i.e. 15) will produce a resonance,\n     *                              low numbers (i.e. .2) will produce a slope.\n     */\n\n  }, {\n    key: \"filter\",\n    value: function filter(freq, q) {\n      this._leftFilter.set(freq, q);\n\n      this._rightFilter.set(freq, q);\n    }\n    /**\n     *  Choose a preset type of delay. 'pingPong' bounces the signal\n     *  from the left to the right channel to produce a stereo effect.\n     *  Any other parameter will revert to the default delay setting.\n     *\n     *  @method  setType\n     *  @for p5.Delay\n     *  @param {String|Number} type 'pingPong' (1) or 'default' (0)\n     */\n\n  }, {\n    key: \"setType\",\n    value: function setType(t) {\n      if (t === 1) {\n        t = 'pingPong';\n      }\n\n      this._split.disconnect();\n\n      this._leftFilter.disconnect();\n\n      this._rightFilter.disconnect();\n\n      this._split.connect(this.leftDelay, 0);\n\n      this._split.connect(this.rightDelay, 1);\n\n      switch (t) {\n        case 'pingPong':\n          this._rightFilter.setType(this._leftFilter.biquad.type);\n\n          this._leftFilter.output.connect(this._merge, 0, 0);\n\n          this._rightFilter.output.connect(this._merge, 0, 1);\n\n          this._leftFilter.output.connect(this.rightDelay);\n\n          this._rightFilter.output.connect(this.leftDelay);\n\n          break;\n\n        default:\n          this._leftFilter.output.connect(this._merge, 0, 0);\n\n          this._rightFilter.output.connect(this._merge, 0, 1);\n\n          this._leftFilter.output.connect(this.leftDelay);\n\n          this._rightFilter.output.connect(this.rightDelay);\n\n      }\n    } \n\n    /**\n     *  Set the output level of the delay effect.\n     *\n     *  @method  amp\n     *  @for p5.Delay\n     *  @param  {Number} volume amplitude between 0 and 1.0\n     *  @param {Number} [rampTime] create a fade that lasts rampTime\n     *  @param {Number} [timeFromNow] schedule this event to happen\n     *                                seconds from now\n     */\n\n    /**\n     *  Send output to a p5.sound or web audio object\n     *\n     *  @method  connect\n     *  @for p5.Delay\n     *  @param  {Object} unit\n     */\n\n    /**\n     *  Disconnect all output.\n     *\n     *  @method disconnect\n     *  @for p5.Delay\n     */\n\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      delay_get(delay_getPrototypeOf(Delay.prototype), \"dispose\", this).call(this);\n\n      this._split.disconnect();\n\n      this._leftFilter.dispose();\n\n      this._rightFilter.dispose();\n\n      this._merge.disconnect();\n\n      this._leftGain.disconnect();\n\n      this._rightGain.disconnect();\n\n      this.leftDelay.disconnect();\n      this.rightDelay.disconnect();\n      this._split = undefined;\n      this._leftFilter = undefined;\n      this._rightFilter = undefined;\n      this._merge = undefined;\n      this._leftGain = undefined;\n      this._rightGain = undefined;\n      this.leftDelay = undefined;\n      this.rightDelay = undefined;\n    }\n  }]);\n\n  return Delay;\n}(effect);\n\n var delay = (delay_Delay);\nfunction reverb_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { reverb_typeof = function _typeof(obj) { return typeof obj; }; } else { reverb_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return reverb_typeof(obj); }\n\nfunction reverb_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction reverb_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction reverb_createClass(Constructor, protoProps, staticProps) { if (protoProps) reverb_defineProperties(Constructor.prototype, protoProps); if (staticProps) reverb_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction reverb_possibleConstructorReturn(self, call) { if (call && (reverb_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return reverb_assertThisInitialized(self); }\n\nfunction reverb_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction reverb_get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { reverb_get = Reflect.get; } else { reverb_get = function _get(target, property, receiver) { var base = reverb_superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return reverb_get(target, property, receiver || target); }\n\nfunction reverb_superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = reverb_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction reverb_getPrototypeOf(o) { reverb_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return reverb_getPrototypeOf(o); }\n\nfunction reverb_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) reverb_setPrototypeOf(subClass, superClass); }\n\nfunction reverb_setPrototypeOf(o, p) { reverb_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return reverb_setPrototypeOf(o, p); }\n\n\n\n\n/**\n *  Reverb adds depth to a sound through a large number of decaying\n *  echoes. It creates the perception that sound is occurring in a\n *  physical space. The p5.Reverb has paramters for Time (how long does the\n *  reverb last) and decayRate (how much the sound decays with each echo)\n *  that can be set with the .set() or .process() methods. The p5.Convolver\n *  extends p5.Reverb allowing you to recreate the sound of actual physical\n *  spaces through convolution.\n *\n *  This class extends <a href = \"/reference/#/p5.Effect\">p5.Effect</a>.\n *  Methods <a href = \"/reference/#/p5.Effect/amp\">amp()</a>, <a href = \"/reference/#/p5.Effect/chain\">chain()</a>,\n *  <a href = \"/reference/#/p5.Effect/drywet\">drywet()</a>, <a href = \"/reference/#/p5.Effect/connect\">connect()</a>, and\n *  <a href = \"/reference/#/p5.Effect/disconnect\">disconnect()</a> are available.\n *\n *  @class p5.Reverb\n *  @extends p5.Effect\n *  @constructor\n *  @example\n *  <div><code>\n *  let soundFile, reverb;\n *  function preload() {\n *    soundFile = loadSound('assets/Damscray_DancingTiger.mp3');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playSound);\n *\n *    reverb = new p5.Reverb();\n *    soundFile.disconnect(); // so we'll only hear reverb...\n *\n *    // connect soundFile to reverb, process w/\n *    // 3 second reverbTime, decayRate of 2%\n *    reverb.process(soundFile, 3, 2);\n *  }\n *\n *  function draw() {\n *    let dryWet = constrain(map(mouseX, 0, width, 0, 1), 0, 1);\n *    // 1 = all reverb, 0 = no reverb\n *    reverb.drywet(dryWet);\n *\n *    background(220);\n *    text('tap to play', 10, 20);\n *    text('dry/wet: ' + round(dryWet * 100) + '%', 10, height - 20);\n *  }\n *\n *  function playSound() {\n *    soundFile.play();\n *  }\n *  </code></div>\n */\n\nvar Reverb =\nfunction (_Effect) {\n  reverb_inherits(Reverb, _Effect);\n\n  function Reverb() {\n    var _this;\n\n    reverb_classCallCheck(this, Reverb);\n\n    _this = reverb_possibleConstructorReturn(this, reverb_getPrototypeOf(Reverb).call(this));\n\n    _this._initConvolverNode(); \n\n\n    _this.input.gain.value = 0.5; \n\n    _this._seconds = 3;\n    _this._decay = 2;\n    _this._reverse = false;\n\n    _this._buildImpulse();\n\n    return _this;\n  }\n\n  reverb_createClass(Reverb, [{\n    key: \"_initConvolverNode\",\n    value: function _initConvolverNode() {\n      this.convolverNode = this.ac.createConvolver();\n      this.input.connect(this.convolverNode);\n      this.convolverNode.connect(this.wet);\n    }\n  }, {\n    key: \"_teardownConvolverNode\",\n    value: function _teardownConvolverNode() {\n      if (this.convolverNode) {\n        this.convolverNode.disconnect();\n        delete this.convolverNode;\n      }\n    }\n  }, {\n    key: \"_setBuffer\",\n    value: function _setBuffer(audioBuffer) {\n      this._teardownConvolverNode();\n\n      this._initConvolverNode();\n\n      this.convolverNode.buffer = audioBuffer;\n    }\n    /**\n     *  Connect a source to the reverb, and assign reverb parameters.\n     *\n     *  @method  process\n     *  @for p5.Reverb\n     *  @param  {Object} src     p5.sound / Web Audio object with a sound\n     *                           output.\n     *  @param  {Number} [seconds] Duration of the reverb, in seconds.\n     *                           Min: 0, Max: 10. Defaults to 3.\n     *  @param  {Number} [decayRate] Percentage of decay with each echo.\n     *                            Min: 0, Max: 100. Defaults to 2.\n     *  @param  {Boolean} [reverse] Play the reverb backwards or forwards.\n     */\n\n  }, {\n    key: \"process\",\n    value: function process(src, seconds, decayRate, reverse) {\n      src.connect(this.input);\n      var rebuild = false;\n\n      if (seconds) {\n        this._seconds = seconds;\n        rebuild = true;\n      }\n\n      if (decayRate) {\n        this._decay = decayRate;\n      }\n\n      if (reverse) {\n        this._reverse = reverse;\n      }\n\n      if (rebuild) {\n        this._buildImpulse();\n      }\n    }\n    /**\n     *  Set the reverb settings. Similar to .process(), but without\n     *  assigning a new input.\n     *\n     *  @method  set\n     *  @for p5.Reverb\n     *  @param  {Number} [seconds] Duration of the reverb, in seconds.\n     *                           Min: 0, Max: 10. Defaults to 3.\n     *  @param  {Number} [decayRate] Percentage of decay with each echo.\n     *                            Min: 0, Max: 100. Defaults to 2.\n     *  @param  {Boolean} [reverse] Play the reverb backwards or forwards.\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(seconds, decayRate, reverse) {\n      var rebuild = false;\n\n      if (seconds) {\n        this._seconds = seconds;\n        rebuild = true;\n      }\n\n      if (decayRate) {\n        this._decay = decayRate;\n      }\n\n      if (reverse) {\n        this._reverse = reverse;\n      }\n\n      if (rebuild) {\n        this._buildImpulse();\n      }\n    } \n\n    /**\n     *  Set the output level of the reverb effect.\n     *\n     *  @method  amp\n     *  @for p5.Reverb\n     *  @param  {Number} volume amplitude between 0 and 1.0\n     *  @param  {Number} [rampTime] create a fade that lasts rampTime\n     *  @param  {Number} [timeFromNow] schedule this event to happen\n     *                                seconds from now\n     */\n\n    /**\n     *  Send output to a p5.sound or web audio object\n     *\n     *  @method  connect\n     *  @for p5.Reverb\n     *  @param  {Object} unit\n     */\n\n    /**\n     *  Disconnect all output.\n     *\n     *  @method disconnect\n     *  @for p5.Reverb\n     */\n\n    /**\n     *  Inspired by Simple Reverb by Jordan Santell\n     *  https://github.com/web-audio-components/simple-reverb/blob/master/index.js\n     *\n     *  Utility function for building an impulse response\n     *  based on the module parameters.\n     *\n     *  @private\n     */\n\n  }, {\n    key: \"_buildImpulse\",\n    value: function _buildImpulse() {\n      var rate = this.ac.sampleRate;\n      var length = rate * this._seconds;\n      var decay = this._decay;\n      var impulse = this.ac.createBuffer(2, length, rate);\n      var impulseL = impulse.getChannelData(0);\n      var impulseR = impulse.getChannelData(1);\n      var n, i;\n\n      for (i = 0; i < length; i++) {\n        n = this._reverse ? length - i : i;\n        impulseL[i] = (Math.random() * 2 - 1) * Math.pow(1 - n / length, decay);\n        impulseR[i] = (Math.random() * 2 - 1) * Math.pow(1 - n / length, decay);\n      }\n\n      this._setBuffer(impulse);\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      reverb_get(reverb_getPrototypeOf(Reverb.prototype), \"dispose\", this).call(this);\n\n      this._teardownConvolverNode();\n    }\n  }]);\n\n  return Reverb;\n}(effect); \n\n/**\n *  <p>p5.Convolver extends p5.Reverb. It can emulate the sound of real\n *  physical spaces through a process called <a href=\"\n *  https://en.wikipedia.org/wiki/Convolution_reverb#Real_space_simulation\">\n *  convolution</a>.</p>\n *\n *  <p>Convolution multiplies any audio input by an \"impulse response\"\n *  to simulate the dispersion of sound over time. The impulse response is\n *  generated from an audio file that you provide. One way to\n *  generate an impulse response is to pop a balloon in a reverberant space\n *  and record the echo. Convolution can also be used to experiment with\n *  sound.</p>\n *\n *  <p>Use the method <code>createConvolution(path)</code> to instantiate a\n *  p5.Convolver with a path to your impulse response audio file.</p>\n *\n *  @class p5.Convolver\n *  @extends p5.Effect\n *  @constructor\n *  @param  {String}   path     path to a sound file\n *  @param  {Function} [callback] function to call when loading succeeds\n *  @param  {Function} [errorCallback] function to call if loading fails.\n *                                     This function will receive an error or\n *                                     XMLHttpRequest object with information\n *                                     about what went wrong.\n *  @example\n *  <div><code>\n *  let cVerb, sound;\n *  function preload() {\n *    // We have both MP3 and OGG versions of all sound assets\n *    soundFormats('ogg', 'mp3');\n *\n *    // Try replacing 'bx-spring' with other soundfiles like\n *    // 'concrete-tunnel' 'small-plate' 'drum' 'beatbox'\n *    cVerb = createConvolver('assets/bx-spring.mp3');\n *\n *    // Try replacing 'Damscray_DancingTiger' with\n *    // 'beat', 'doorbell', lucky_dragons_-_power_melody'\n *    sound = loadSound('assets/Damscray_DancingTiger.mp3');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playSound);\n *    background(220);\n *    text('tap to play', 20, 20);\n *\n *    // disconnect from main output...\n *    sound.disconnect();\n *\n *    // ...and process with cVerb\n *    // so that we only hear the convolution\n *    cVerb.process(sound);\n *  }\n *\n *  function playSound() {\n *    sound.play();\n *  }\n *  </code></div>\n */\n\n\nvar reverb_Convolver =\nfunction (_Reverb) {\n  reverb_inherits(Convolver, _Reverb);\n\n  function Convolver(path, callback, errorCallback) {\n    var _this2;\n\n    reverb_classCallCheck(this, Convolver);\n\n    _this2 = reverb_possibleConstructorReturn(this, reverb_getPrototypeOf(Convolver).call(this));\n    /**\n     *  Internally, the p5.Convolver uses the a\n     *  <a href=\"http://www.w3.org/TR/webaudio/#ConvolverNode\">\n     *  Web Audio Convolver Node</a>.\n     *\n     *  @property {ConvolverNode} convolverNode\n     */\n\n    _this2._initConvolverNode(); \n\n\n    _this2.input.gain.value = 0.5;\n\n    if (path) {\n      _this2.impulses = [];\n\n      _this2._loadBuffer(path, callback, errorCallback);\n    } else {\n      _this2._seconds = 3;\n      _this2._decay = 2;\n      _this2._reverse = false;\n\n      _this2._buildImpulse();\n    }\n    /**\n     *  If you load multiple impulse files using the .addImpulse method,\n     *  they will be stored as Objects in this Array. Toggle between them\n     *  with the <code>toggleImpulse(id)</code> method.\n     *\n     *  @property {Array} impulses\n     *  @for p5.Convolver\n     */\n\n\n    _this2.impulses = [];\n    _this2.set = null;\n    return _this2;\n  }\n  /**\n   *  Private method to load a buffer as an Impulse Response,\n   *  assign it to the convolverNode, and add to the Array of .impulses.\n   *\n   *  @param   {String}   path\n   *  @param   {Function} callback\n   *  @param   {Function} errorCallback\n   *  @private\n   */\n\n\n  reverb_createClass(Convolver, [{\n    key: \"_loadBuffer\",\n    value: function _loadBuffer(_path, callback, errorCallback) {\n      var path = p5.prototype._checkFileFormats(_path);\n\n      var self = this;\n      var errorTrace = new Error().stack;\n      var ac = Object(audiocontext[\"b\" ])();\n      var request = new XMLHttpRequest();\n      request.open('GET', path, true);\n      request.responseType = 'arraybuffer';\n\n      request.onload = function () {\n        if (request.status === 200) {\n          ac.decodeAudioData(request.response, function (buff) {\n            var buffer = {};\n            var chunks = path.split('/');\n            buffer.name = chunks[chunks.length - 1];\n            buffer.audioBuffer = buff;\n            self.impulses.push(buffer);\n\n            self._setBuffer(buffer.audioBuffer);\n\n            if (callback) {\n              callback(buffer);\n            }\n          }, \n          function () {\n            var err = new errorHandler('decodeAudioData', errorTrace, self.url);\n            var msg = 'AudioContext error at decodeAudioData for ' + self.url;\n\n            if (errorCallback) {\n              err.msg = msg;\n              errorCallback(err);\n            } else {\n              console.error(msg + '\\n The error stack trace includes: \\n' + err.stack);\n            }\n          });\n        } \n        else {\n            var err = new errorHandler('loadConvolver', errorTrace, self.url);\n            var msg = 'Unable to load ' + self.url + '. The request status was: ' + request.status + ' (' + request.statusText + ')';\n\n            if (errorCallback) {\n              err.message = msg;\n              errorCallback(err);\n            } else {\n              console.error(msg + '\\n The error stack trace includes: \\n' + err.stack);\n            }\n          }\n      }; \n\n\n      request.onerror = function () {\n        var err = new errorHandler('loadConvolver', errorTrace, self.url);\n        var msg = 'There was no response from the server at ' + self.url + '. Check the url and internet connectivity.';\n\n        if (errorCallback) {\n          err.message = msg;\n          errorCallback(err);\n        } else {\n          console.error(msg + '\\n The error stack trace includes: \\n' + err.stack);\n        }\n      };\n\n      request.send();\n    }\n    /**\n     *  Connect a source to the convolver.\n     *\n     *  @method  process\n     *  @for p5.Convolver\n     *  @param  {Object} src     p5.sound / Web Audio object with a sound\n     *                           output.\n     *  @example\n     *  <div><code>\n     *  let cVerb, sound;\n     *  function preload() {\n     *    // We have both MP3 and OGG versions of all sound assets\n     *    soundFormats('ogg', 'mp3');\n     *\n     *    // Try replacing 'bx-spring' with other soundfiles like\n     *    // 'concrete-tunnel' 'small-plate' 'drum' 'beatbox'\n     *    cVerb = createConvolver('assets/bx-spring.mp3');\n     *\n     *    // Try replacing 'Damscray_DancingTiger' with\n     *    // 'beat', 'doorbell', lucky_dragons_-_power_melody'\n     *    sound = loadSound('assets/Damscray_DancingTiger.mp3');\n     *  }\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(playSound);\n     *    background(220);\n     *    text('tap to play', 20, 20);\n     *\n     *    // disconnect from main output...\n     *    sound.disconnect();\n     *\n     *    // ...and process with cVerb\n     *    // so that we only hear the convolution\n     *    cVerb.process(sound);\n     *  }\n     *\n     *  function playSound() {\n     *    sound.play();\n     *  }\n     *\n     *  </code></div>\n     */\n\n  }, {\n    key: \"process\",\n    value: function process(src) {\n      src.connect(this.input);\n    }\n    /**\n     *  Load and assign a new Impulse Response to the p5.Convolver.\n     *  The impulse is added to the <code>.impulses</code> array. Previous\n     *  impulses can be accessed with the <code>.toggleImpulse(id)</code>\n     *  method.\n     *\n     *  @method  addImpulse\n     *  @for p5.Convolver\n     *  @param  {String}   path     path to a sound file\n     *  @param  {Function} callback function (optional)\n     *  @param  {Function} errorCallback function (optional)\n     */\n\n  }, {\n    key: \"addImpulse\",\n    value: function addImpulse(path, callback, errorCallback) {\n      if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {\n        alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');\n      }\n\n      this._loadBuffer(path, callback, errorCallback);\n    }\n    /**\n     *  Similar to .addImpulse, except that the <code>.impulses</code>\n     *  Array is reset to save memory. A new <code>.impulses</code>\n     *  array is created with this impulse as the only item.\n     *\n     *  @method  resetImpulse\n     *  @for p5.Convolver\n     *  @param  {String}   path     path to a sound file\n     *  @param  {Function} callback function (optional)\n     *  @param  {Function} errorCallback function (optional)\n     */\n\n  }, {\n    key: \"resetImpulse\",\n    value: function resetImpulse(path, callback, errorCallback) {\n      if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {\n        alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');\n      }\n\n      this.impulses = [];\n\n      this._loadBuffer(path, callback, errorCallback);\n    }\n    /**\n     *  If you have used <code>.addImpulse()</code> to add multiple impulses\n     *  to a p5.Convolver, then you can use this method to toggle between\n     *  the items in the <code>.impulses</code> Array. Accepts a parameter\n     *  to identify which impulse you wish to use, identified either by its\n     *  original filename (String) or by its position in the <code>.impulses\n     *  </code> Array (Number).<br/>\n     *  You can access the objects in the .impulses Array directly. Each\n     *  Object has two attributes: an <code>.audioBuffer</code> (type:\n     *  Web Audio <a href=\"\n     *  http://webaudio.github.io/web-audio-api/#the-audiobuffer-interface\">\n     *  AudioBuffer)</a> and a <code>.name</code>, a String that corresponds\n     *  with the original filename.\n     *\n     *  @method toggleImpulse\n     *  @for p5.Convolver\n     *  @param {String|Number} id Identify the impulse by its original filename\n     *                            (String), or by its position in the\n     *                            <code>.impulses</code> Array (Number).\n     */\n\n  }, {\n    key: \"toggleImpulse\",\n    value: function toggleImpulse(id) {\n      if (typeof id === 'number' && id < this.impulses.length) {\n        this._setBuffer(this.impulses[id].audioBuffer);\n      }\n\n      if (typeof id === 'string') {\n        for (var i = 0; i < this.impulses.length; i++) {\n          if (this.impulses[i].name === id) {\n            this._setBuffer(this.impulses[i].audioBuffer);\n\n            break;\n          }\n        }\n      }\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      reverb_get(reverb_getPrototypeOf(Convolver.prototype), \"dispose\", this).call(this); \n\n\n      for (var i in this.impulses) {\n        if (this.impulses[i]) {\n          this.impulses[i] = null;\n        }\n      }\n    }\n  }]);\n\n  return Convolver;\n}(Reverb);\n/**\n *  Create a p5.Convolver. Accepts a path to a soundfile\n *  that will be used to generate an impulse response.\n *\n *  @method  createConvolver\n *  @for p5\n *  @param  {String}   path     path to a sound file\n *  @param  {Function} [callback] function to call if loading is successful.\n *                                The object will be passed in as the argument\n *                                to the callback function.\n *  @param  {Function} [errorCallback] function to call if loading is not successful.\n *                                A custom error will be passed in as the argument\n *                                to the callback function.\n *  @return {p5.Convolver}\n *  @example\n *  <div><code>\n *  let cVerb, sound;\n *  function preload() {\n *    // We have both MP3 and OGG versions of all sound assets\n *    soundFormats('ogg', 'mp3');\n *\n *    // Try replacing 'bx-spring' with other soundfiles like\n *    // 'concrete-tunnel' 'small-plate' 'drum' 'beatbox'\n *    cVerb = createConvolver('assets/bx-spring.mp3');\n *\n *    // Try replacing 'Damscray_DancingTiger' with\n *    // 'beat', 'doorbell', lucky_dragons_-_power_melody'\n *    sound = loadSound('assets/Damscray_DancingTiger.mp3');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playSound);\n *    background(220);\n *    text('tap to play', 20, 20);\n *\n *    // disconnect from main output...\n *    sound.disconnect();\n *\n *    // ...and process with cVerb\n *    // so that we only hear the convolution\n *    cVerb.process(sound);\n *  }\n *\n *  function playSound() {\n *    sound.play();\n *  }\n *  </code></div>\n */\n\n\nfunction createConvolver(path, callback, errorCallback) {\n  if (window.location.origin.indexOf('file://') > -1 && window.cordova === 'undefined') {\n    alert('This sketch may require a server to load external files. Please see http://bit.ly/1qcInwS');\n  }\n\n  var self = this;\n  var cReverb = new reverb_Convolver(path, function (buffer) {\n    if (typeof callback === 'function') {\n      callback(buffer);\n    }\n\n    if (typeof self._decrementPreload === 'function') {\n      self._decrementPreload();\n    }\n  }, errorCallback);\n  cReverb.impulses = [];\n  return cReverb;\n}\n\n\nvar Clock = __webpack_require__(11);\nvar Clock_default = __webpack_require__.n(Clock);\n\nfunction metro_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction metro_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction metro_createClass(Constructor, protoProps, staticProps) { if (protoProps) metro_defineProperties(Constructor.prototype, protoProps); if (staticProps) metro_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n\nvar metro_Metro =\nfunction () {\n  function Metro() {\n    metro_classCallCheck(this, Metro);\n\n    this.clock = new Clock_default.a({\n      callback: this.ontick.bind(this)\n    });\n    this.syncedParts = [];\n    this.bpm = 120; \n\n    this._init();\n\n    this.prevTick = 0;\n    this.tatumTime = 0;\n\n    this.tickCallback = function () {};\n  }\n\n  metro_createClass(Metro, [{\n    key: \"ontick\",\n    value: function ontick(tickTime) {\n      var elapsedTime = tickTime - this.prevTick;\n      var secondsFromNow = tickTime - main.audiocontext.currentTime;\n\n      if (elapsedTime - this.tatumTime <= -0.02) {\n        return;\n      } else {\n        this.prevTick = tickTime; \n\n        var self = this;\n        this.syncedParts.forEach(function (thisPart) {\n          if (!thisPart.isPlaying) return;\n          thisPart.incrementStep(secondsFromNow); \n\n          thisPart.phrases.forEach(function (thisPhrase) {\n            var phraseArray = thisPhrase.sequence;\n            var bNum = self.metroTicks % phraseArray.length;\n\n            if (phraseArray[bNum] !== 0 && (self.metroTicks < phraseArray.length || !thisPhrase.looping)) {\n              thisPhrase.callback(secondsFromNow, phraseArray[bNum]);\n            }\n          });\n        });\n        this.metroTicks += 1;\n        this.tickCallback(secondsFromNow);\n      }\n    }\n  }, {\n    key: \"setBPM\",\n    value: function setBPM(bpm) {\n      var rampTime = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n      var beatTime = 60 / (bpm * this.tatums);\n      var now = main.audiocontext.currentTime;\n      this.tatumTime = beatTime;\n      this.clock.frequency.setValueAtTime(this.clock.frequency.value, now);\n      this.clock.frequency.linearRampToValueAtTime(bpm, now + rampTime);\n      this.bpm = bpm;\n    }\n  }, {\n    key: \"getBPM\",\n    value: function getBPM() {\n      return this.clock.getRate() / this.tatums * 60;\n    }\n  }, {\n    key: \"_init\",\n    value: function _init() {\n      this.metroTicks = 0; \n    } \n\n  }, {\n    key: \"resetSync\",\n    value: function resetSync(part) {\n      this.syncedParts = [part];\n    } \n\n  }, {\n    key: \"pushSync\",\n    value: function pushSync(part) {\n      this.syncedParts.push(part);\n    }\n  }, {\n    key: \"start\",\n    value: function start(timeFromNow) {\n      var t = timeFromNow || 0;\n      var now = main.audiocontext.currentTime;\n      this.clock.start(now + t);\n      this.setBPM(this.bpm);\n    }\n  }, {\n    key: \"stop\",\n    value: function stop(timeFromNow) {\n      var t = timeFromNow || 0;\n      var now = main.audiocontext.currentTime;\n      this.clock.stop(now + t);\n    }\n  }, {\n    key: \"beatLength\",\n    value: function beatLength(tatums) {\n      this.tatums = 1 / tatums / 4; \n    }\n  }]);\n\n  return Metro;\n}();\n\n var metro = (metro_Metro);\nfunction looper_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction looper_createClass(Constructor, protoProps, staticProps) { if (protoProps) looper_defineProperties(Constructor.prototype, protoProps); if (staticProps) looper_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction looper_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n\n\nvar BPM = 120;\n/**\n *  Set the global tempo, in beats per minute, for all\n *  p5.Parts. This method will impact all active p5.Parts.\n *\n *  @method setBPM\n *  @for p5\n *  @param {Number} BPM      Beats Per Minute\n *  @param {Number} rampTime Seconds from now\n */\n\np5.prototype.setBPM = function (bpm, rampTime) {\n  BPM = bpm;\n\n  for (var i in main.parts) {\n    if (main.parts[i]) {\n      main.parts[i].setBPM(bpm, rampTime);\n    }\n  }\n};\n/**\n *  <p>A phrase is a pattern of musical events over time, i.e.\n *  a series of notes and rests.</p>\n *\n *  <p>Phrases must be added to a p5.Part for playback, and\n *  each part can play multiple phrases at the same time.\n *  For example, one Phrase might be a kick drum, another\n *  could be a snare, and another could be the bassline.</p>\n *\n *  <p>The first parameter is a name so that the phrase can be\n *  modified or deleted later. The callback is a a function that\n *  this phrase will call at every stepfor example it might be\n *  called <code>playNote(value){}</code>. The array determines\n *  which value is passed into the callback at each step of the\n *  phrase. It can be numbers, an object with multiple numbers,\n *  or a zero (0) indicates a rest so the callback won't be called).</p>\n *\n *  @class p5.Phrase\n *  @constructor\n *  @param {String}   name     Name so that you can access the Phrase.\n *  @param {Function} callback The name of a function that this phrase\n *                             will call. Typically it will play a sound,\n *                             and accept two parameters: a time at which\n *                             to play the sound (in seconds from now),\n *                             and a value from the sequence array. The\n *                             time should be passed into the play() or\n *                             start() method to ensure precision.\n *  @param {Array}   sequence    Array of values to pass into the callback\n *                            at each step of the phrase.\n *  @example\n *  <div><code>\n *  let mySound, myPhrase, myPart;\n *  let pattern = [1,0,0,2,0,2,0,0];\n *\n *  function preload() {\n *    mySound = loadSound('assets/beatbox.mp3');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playMyPart);\n *    background(220);\n *    text('tap to play', width/2, height/2);\n *    textAlign(CENTER, CENTER);\n *\n *    myPhrase = new p5.Phrase('bbox', onEachStep, pattern);\n *    myPart = new p5.Part();\n *    myPart.addPhrase(myPhrase);\n *    myPart.setBPM(60);\n *  }\n *\n *  function onEachStep(time, playbackRate) {\n *    mySound.rate(playbackRate);\n *    mySound.play(time);\n *  }\n *\n *  function playMyPart() {\n *    userStartAudio();\n *    myPart.start();\n *  }\n *  </code></div>\n */\n\n\nvar Phrase = function Phrase(name, callback, sequence) {\n  looper_classCallCheck(this, Phrase);\n\n  this.phraseStep = 0;\n  this.name = name;\n  this.callback = callback;\n  /**\n   * Array of values to pass into the callback\n   * at each step of the phrase. Depending on the callback\n   * function's requirements, these values may be numbers,\n   * strings, or an object with multiple parameters.\n   * Zero (0) indicates a rest.\n   *\n   * @property {Array} sequence\n   */\n\n  this.sequence = sequence;\n};\n/**\n *  <p>A p5.Part plays back one or more p5.Phrases. Instantiate a part\n *  with steps and tatums. By default, each step represents a 1/16th note.</p>\n *\n *  <p>See p5.Phrase for more about musical timing.</p>\n *\n *  @class p5.Part\n *  @constructor\n *  @param {Number} [steps]   Steps in the part\n *  @param {Number} [tatums] Divisions of a beat, e.g. use 1/4, or 0.25 for a quater note (default is 1/16, a sixteenth note)\n *  @example\n *  <div><code>\n *  let box, drum, myPart;\n *  let boxPat = [1,0,0,2,0,2,0,0];\n *  let drumPat = [0,1,1,0,2,0,1,0];\n *\n *  function preload() {\n *    box = loadSound('assets/beatbox.mp3');\n *    drum = loadSound('assets/drum.mp3');\n *  }\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playMyPart);\n *    background(220);\n *    textAlign(CENTER, CENTER);\n *    text('tap to play', width/2, height/2);\n *\n *    let boxPhrase = new p5.Phrase('box', playBox, boxPat);\n *    let drumPhrase = new p5.Phrase('drum', playDrum, drumPat);\n *    myPart = new p5.Part();\n *    myPart.addPhrase(boxPhrase);\n *    myPart.addPhrase(drumPhrase);\n *    myPart.setBPM(60);\n *  }\n *\n *  function playBox(time, playbackRate) {\n *    box.rate(playbackRate);\n *    box.play(time);\n *  }\n *\n *  function playDrum(time, playbackRate) {\n *    drum.rate(playbackRate);\n *    drum.play(time);\n *  }\n *\n *  function playMyPart() {\n *    userStartAudio();\n *\n *    myPart.start();\n *  }\n *  </code></div>\n */\n\n\nvar looper_Part =\nfunction () {\n  function Part(steps, bLength) {\n    looper_classCallCheck(this, Part);\n\n    this.length = steps || 0; \n\n    this.partStep = 0;\n    this.phrases = [];\n    this.isPlaying = false;\n    this.noLoop();\n    this.tatums = bLength || 0.0625; \n\n    this.metro = new metro();\n\n    this.metro._init();\n\n    this.metro.beatLength(this.tatums);\n    this.metro.setBPM(BPM);\n    main.parts.push(this);\n\n    this.callback = function () {};\n  }\n  /**\n   *  Set the tempo of this part, in Beats Per Minute.\n   *\n   *  @method  setBPM\n   *  @for p5.Part\n   *  @param {Number} BPM      Beats Per Minute\n   *  @param {Number} [rampTime] Seconds from now\n   */\n\n\n  looper_createClass(Part, [{\n    key: \"setBPM\",\n    value: function setBPM(tempo, rampTime) {\n      this.metro.setBPM(tempo, rampTime);\n    }\n    /**\n     *  Returns the tempo, in Beats Per Minute, of this part.\n     *\n     *  @method getBPM\n     *  @for p5.Part\n     *  @return {Number}\n     */\n\n  }, {\n    key: \"getBPM\",\n    value: function getBPM() {\n      return this.metro.getBPM();\n    }\n    /**\n     *  Start playback of this part. It will play\n     *  through all of its phrases at a speed\n     *  determined by setBPM.\n     *\n     *  @method  start\n     *  @for p5.Part\n     *  @param  {Number} [time] seconds from now\n     */\n\n  }, {\n    key: \"start\",\n    value: function start(time) {\n      if (!this.isPlaying) {\n        this.isPlaying = true;\n        this.metro.resetSync(this);\n        var t = time || 0;\n        this.metro.start(t);\n      }\n    }\n    /**\n     *  Loop playback of this part. It will begin\n     *  looping through all of its phrases at a speed\n     *  determined by setBPM.\n     *\n     *  @method  loop\n     *  @for p5.Part\n     *  @param  {Number} [time] seconds from now\n     */\n\n  }, {\n    key: \"loop\",\n    value: function loop(time) {\n      this.looping = true; \n\n      this.onended = function () {\n        this.partStep = 0;\n      };\n\n      var t = time || 0;\n      this.start(t);\n    }\n    /**\n     *  Tell the part to stop looping.\n     *\n     *  @method  noLoop\n     *  @for p5.Part\n     */\n\n  }, {\n    key: \"noLoop\",\n    value: function noLoop() {\n      this.looping = false; \n\n      this.onended = function () {\n        this.stop();\n      };\n    }\n    /**\n     *  Stop the part and cue it to step 0. Playback will resume from the begining of the Part when it is played again.\n     *\n     *  @method  stop\n     *  @for p5.Part\n     *  @param  {Number} [time] seconds from now\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop(time) {\n      this.partStep = 0;\n      this.pause(time);\n    }\n    /**\n     *  Pause the part. Playback will resume\n     *  from the current step.\n     *\n     *  @method  pause\n     *  @for p5.Part\n     *  @param  {Number} time seconds from now\n     */\n\n  }, {\n    key: \"pause\",\n    value: function pause(time) {\n      this.isPlaying = false;\n      var t = time || 0;\n      this.metro.stop(t);\n    }\n    /**\n     *  Add a p5.Phrase to this Part.\n     *\n     *  @method  addPhrase\n     *  @for p5.Part\n     *  @param {p5.Phrase}   phrase   reference to a p5.Phrase\n     */\n\n  }, {\n    key: \"addPhrase\",\n    value: function addPhrase(name, callback, array) {\n      var p;\n\n      if (arguments.length === 3) {\n        p = new Phrase(name, callback, array);\n      } else if (arguments[0] instanceof Phrase) {\n        p = arguments[0];\n      } else {\n        throw 'invalid input. addPhrase accepts name, callback, array or a p5.Phrase';\n      }\n\n      this.phrases.push(p); \n\n      if (p.sequence.length > this.length) {\n        this.length = p.sequence.length;\n      }\n    }\n    /**\n     *  Remove a phrase from this part, based on the name it was\n     *  given when it was created.\n     *\n     *  @method  removePhrase\n     *  @for p5.Part\n     *  @param  {String} phraseName\n     */\n\n  }, {\n    key: \"removePhrase\",\n    value: function removePhrase(name) {\n      for (var i in this.phrases) {\n        if (this.phrases[i].name === name) {\n          this.phrases.splice(i, 1);\n        }\n      }\n    }\n    /**\n     *  Get a phrase from this part, based on the name it was\n     *  given when it was created. Now you can modify its array.\n     *\n     *  @method  getPhrase\n     *  @for p5.Part\n     *  @param  {String} phraseName\n     */\n\n  }, {\n    key: \"getPhrase\",\n    value: function getPhrase(name) {\n      for (var i in this.phrases) {\n        if (this.phrases[i].name === name) {\n          return this.phrases[i];\n        }\n      }\n    }\n    /**\n     *  Find all sequences with the specified name, and replace their patterns with the specified array.\n     *\n     *  @method  replaceSequence\n     *  @for p5.Part\n     *  @param  {String} phraseName\n     *  @param  {Array} sequence  Array of values to pass into the callback\n     *                            at each step of the phrase.\n     */\n\n  }, {\n    key: \"replaceSequence\",\n    value: function replaceSequence(name, array) {\n      for (var i in this.phrases) {\n        if (this.phrases[i].name === name) {\n          this.phrases[i].sequence = array;\n        }\n      }\n    }\n  }, {\n    key: \"incrementStep\",\n    value: function incrementStep(time) {\n      if (this.partStep < this.length - 1) {\n        this.callback(time);\n        this.partStep += 1;\n      } else {\n        if (!this.looping && this.partStep === this.length - 1) {\n          this.onended();\n        }\n      }\n    }\n    /**\n     *  Set the function that will be called at every step. This will clear the previous function.\n     *\n     *  @method onStep\n     *  @for p5.Part\n     *  @param  {Function} callback The name of the callback\n     *                              you want to fire\n     *                              on every beat/tatum.\n     */\n\n  }, {\n    key: \"onStep\",\n    value: function onStep(callback) {\n      this.callback = callback;\n    }\n  }]);\n\n  return Part;\n}(); \n\n/**\n *  A Score consists of a series of Parts. The parts will\n *  be played back in order. For example, you could have an\n *  A part, a B part, and a C part, and play them back in this order\n *  <code>new p5.Score(a, a, b, a, c)</code>\n *\n *  @class p5.Score\n *  @constructor\n *  @param {p5.Part} [...parts] One or multiple parts, to be played in sequence.\n */\n\n\nvar Score =\nfunction () {\n  function Score() {\n    looper_classCallCheck(this, Score);\n\n    this.parts = [];\n    this.currentPart = new Array(arguments.length);\n    ;\n    var thisScore = this;\n\n    for (var i in arguments) {\n      this.parts[i] = arguments[i];\n      this.parts[i].nextPart = this.parts[i + 1];\n\n      this.parts[i].onended = function () {\n        thisScore.resetPart(i);\n        playNextPart(thisScore);\n      };\n    }\n\n    this.looping = false;\n  }\n\n  looper_createClass(Score, [{\n    key: \"onended\",\n    value: function onended() {\n      if (this.looping) {\n        this.parts[0].start();\n      } else {\n        this.parts[this.parts.length - 1].onended = function () {\n          this.stop();\n          this.resetParts();\n        };\n      }\n\n      this.currentPart = 0;\n    }\n    /**\n     *  Start playback of the score.\n     *\n     *  @method  start\n     *  @for p5.Score\n     */\n\n  }, {\n    key: \"start\",\n    value: function start() {\n      this.parts[this.currentPart].start();\n      this.scoreStep = 0;\n    }\n    /**\n     *  Stop playback of the score.\n     *\n     *  @method  stop\n     *  @for p5.Score\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      this.parts[this.currentPart].stop();\n      this.currentPart = 0;\n      this.scoreStep = 0;\n    }\n    /**\n     *  Pause playback of the score.\n     *\n     *  @method  pause\n     *  @for p5.Score\n     */\n\n  }, {\n    key: \"pause\",\n    value: function pause() {\n      this.parts[this.currentPart].stop();\n    }\n    /**\n     *  Loop playback of the score.\n     *\n     *  @method  loop\n     *  @for p5.Score\n     */\n\n  }, {\n    key: \"loop\",\n    value: function loop() {\n      this.looping = true;\n      this.start();\n    }\n    /**\n     *  Stop looping playback of the score. If it\n     *  is currently playing, this will go into effect\n     *  after the current round of playback completes.\n     *\n     *  @method  noLoop\n     *  @for p5.Score\n     */\n\n  }, {\n    key: \"noLoop\",\n    value: function noLoop() {\n      this.looping = false;\n    }\n  }, {\n    key: \"resetParts\",\n    value: function resetParts() {\n      var self = this;\n      this.parts.forEach(function (part) {\n        self.resetParts[part];\n      });\n    }\n  }, {\n    key: \"resetPart\",\n    value: function resetPart(i) {\n      this.parts[i].stop();\n      this.parts[i].partStep = 0;\n\n      for (var p in this.parts[i].phrases) {\n        if (this.parts[i]) {\n          this.parts[i].phrases[p].phraseStep = 0;\n        }\n      }\n    }\n    /**\n     *  Set the tempo for all parts in the score\n     *\n     *  @method setBPM\n     *  @for p5.Score\n     *  @param {Number} BPM      Beats Per Minute\n     *  @param {Number} rampTime Seconds from now\n     */\n\n  }, {\n    key: \"setBPM\",\n    value: function setBPM(bpm, rampTime) {\n      for (var i in this.parts) {\n        if (this.parts[i]) {\n          this.parts[i].setBPM(bpm, rampTime);\n        }\n      }\n    }\n  }]);\n\n  return Score;\n}();\n\nfunction playNextPart(aScore) {\n  aScore.currentPart++;\n\n  if (aScore.currentPart >= aScore.parts.length) {\n    aScore.scoreStep = 0;\n    aScore.onended();\n  } else {\n    aScore.scoreStep = 0;\n    aScore.parts[aScore.currentPart - 1].stop();\n    aScore.parts[aScore.currentPart].start();\n  }\n}\n\n\nfunction soundLoop_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction soundLoop_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction soundLoop_createClass(Constructor, protoProps, staticProps) { if (protoProps) soundLoop_defineProperties(Constructor.prototype, protoProps); if (staticProps) soundLoop_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n/**\n * SoundLoop\n *\n * @class p5.SoundLoop\n * @constructor\n *\n * @param {Function} callback this function will be called on each iteration of theloop\n * @param {Number|String} [interval] amount of time (if a number) or beats (if a string, following <a href = \"https://github.com/Tonejs/Tone.js/wiki/Time\">Tone.Time</a> convention) for each iteration of the loop. Defaults to 1 second.\n *\n * @example\n * <div><code>\n *  let synth, soundLoop;\n *  let notePattern = [60, 62, 64, 67, 69, 72];\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(canvasPressed);\n *    colorMode(HSB);\n *    background(0, 0, 86);\n *    text('tap to start/stop', 10, 20);\n *\n *    //the looper's callback is passed the timeFromNow\n *    //this value should be used as a reference point from\n *    //which to schedule sounds\n *    let intervalInSeconds = 0.2;\n *    soundLoop = new p5.SoundLoop(onSoundLoop, intervalInSeconds);\n *\n *    synth = new p5.MonoSynth();\n * }\n *\n * function canvasPressed() {\n *   // ensure audio is enabled\n *   userStartAudio();\n *\n *   if (soundLoop.isPlaying) {\n *     soundLoop.stop();\n *   } else {\n *     // start the loop\n *     soundLoop.start();\n *   }\n * }\n *\n * function onSoundLoop(timeFromNow) {\n *   let noteIndex = (soundLoop.iterations - 1) % notePattern.length;\n *   let note = midiToFreq(notePattern[noteIndex]);\n *   synth.play(note, 0.5, timeFromNow);\n *   background(noteIndex * 360 / notePattern.length, 50, 100);\n * }\n * </code></div>\n */\n\nvar soundLoop_SoundLoop =\nfunction () {\n  function SoundLoop(callback, interval) {\n    soundLoop_classCallCheck(this, SoundLoop);\n\n    /**\n     * Getters and Setters, setting any paramter will result in a change in the clock's\n     * frequency, that will be reflected after the next callback\n     * beats per minute (defaults to 60)\n     * @property {Number} bpm\n     * @for p5.SoundLoop\n     */\n    Object.defineProperty(this, 'bpm', {\n      get: function get() {\n        return this._bpm;\n      },\n      set: function set(bpm) {\n        if (!this.musicalTimeMode) {\n          console.warn('Changing the BPM in \"seconds\" mode has no effect. ' + 'BPM is only relevant in musicalTimeMode ' + 'when the interval is specified as a string ' + '(\"2n\", \"4n\", \"1m\"...etc)');\n        }\n\n        this._bpm = bpm;\n\n        this._update();\n      }\n    });\n    /**\n     * number of quarter notes in a measure (defaults to 4)\n     * @property {Number} timeSignature\n     * @for p5.SoundLoop\n     */\n\n    Object.defineProperty(this, 'timeSignature', {\n      get: function get() {\n        return this._timeSignature;\n      },\n      set: function set(timeSig) {\n        if (!this.musicalTimeMode) {\n          console.warn('Changing the timeSignature in \"seconds\" mode has no effect. ' + 'BPM is only relevant in musicalTimeMode ' + 'when the interval is specified as a string ' + '(\"2n\", \"4n\", \"1m\"...etc)');\n        }\n\n        this._timeSignature = timeSig;\n\n        this._update();\n      }\n    });\n    /**\n     * length of the loops interval\n     * @property {Number|String} interval\n     * @for p5.SoundLoop\n     */\n\n    Object.defineProperty(this, 'interval', {\n      get: function get() {\n        return this._interval;\n      },\n      set: function set(interval) {\n        this.musicalTimeMode = typeof interval === 'number' ? false : true;\n        this._interval = interval;\n\n        this._update();\n      }\n    });\n    /**\n     * how many times the callback has been called so far\n     * @property {Number} iterations\n     * @for p5.SoundLoop\n     * @readonly\n     */\n\n    Object.defineProperty(this, 'iterations', {\n      get: function get() {\n        return this.clock.ticks;\n      }\n    });\n    this.callback = callback;\n    /**\n     * musicalTimeMode uses <a href = \"https://github.com/Tonejs/Tone.js/wiki/Time\">Tone.Time</a> convention\n     * true if string, false if number\n     * @property {Boolean} musicalTimeMode\n     */\n\n    this.musicalTimeMode = typeof this._interval === 'number' ? false : true;\n    this._interval = interval || 1;\n    /**\n     * musicalTimeMode variables\n     * modify these only when the interval is specified in musicalTime format as a string\n     */\n\n    this._timeSignature = 4;\n    this._bpm = 60;\n    this.isPlaying = false;\n    /**\n     * Set a limit to the number of loops to play. defaults to Infinity\n     * @property {Number} maxIterations\n     */\n\n    this.maxIterations = Infinity;\n    var self = this;\n    this.clock = new Clock_default.a({\n      callback: function callback(time) {\n        var timeFromNow = time - main.audiocontext.currentTime;\n        /**\n         * Do not initiate the callback if timeFromNow is < 0\n         * This ususually occurs for a few milliseconds when the page\n         * is not fully loaded\n         *\n         * The callback should only be called until maxIterations is reached\n         */\n\n        if (timeFromNow > 0 && self.iterations <= self.maxIterations) {\n          self.callback(timeFromNow);\n        }\n      },\n      frequency: this._calcFreq()\n    });\n  }\n  /**\n   * Start the loop\n   * @method  start\n   * @for p5.SoundLoop\n   * @param  {Number} [timeFromNow] schedule a starting time\n   */\n\n\n  soundLoop_createClass(SoundLoop, [{\n    key: \"start\",\n    value: function start(timeFromNow) {\n      var t = timeFromNow || 0;\n      var now = main.audiocontext.currentTime;\n\n      if (!this.isPlaying) {\n        this.clock.start(now + t);\n        this.isPlaying = true;\n      }\n    }\n    /**\n     * Stop the loop\n     * @method  stop\n     * @for p5.SoundLoop\n     * @param  {Number} [timeFromNow] schedule a stopping time\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop(timeFromNow) {\n      var t = timeFromNow || 0;\n      var now = main.audiocontext.currentTime;\n\n      if (this.isPlaying) {\n        this.clock.stop(now + t);\n        this.isPlaying = false;\n      }\n    }\n    /**\n     * Pause the loop\n     * @method pause\n     * @for p5.SoundLoop\n     * @param  {Number} [timeFromNow] schedule a pausing time\n     */\n\n  }, {\n    key: \"pause\",\n    value: function pause(timeFromNow) {\n      var t = timeFromNow || 0;\n      var now = main.audiocontext.currentTime;\n\n      if (this.isPlaying) {\n        this.clock.pause(now + t);\n        this.isPlaying = false;\n      }\n    }\n    /**\n     * Synchronize loops. Use this method to start two or more loops in synchronization\n     * or to start a loop in synchronization with a loop that is already playing\n     * This method will schedule the implicit loop in sync with the explicit master loop\n     * i.e. loopToStart.syncedStart(loopToSyncWith)\n     *\n     * @method  syncedStart\n     * @for p5.SoundLoop\n     * @param  {Object} otherLoop   a p5.SoundLoop to sync with\n     * @param  {Number} [timeFromNow] Start the loops in sync after timeFromNow seconds\n     */\n\n  }, {\n    key: \"syncedStart\",\n    value: function syncedStart(otherLoop, timeFromNow) {\n      var t = timeFromNow || 0;\n      var now = main.audiocontext.currentTime;\n\n      if (!otherLoop.isPlaying) {\n        otherLoop.clock.start(now + t);\n        otherLoop.isPlaying = true;\n        this.clock.start(now + t);\n        this.isPlaying = true;\n      } else if (otherLoop.isPlaying) {\n        var time = otherLoop.clock._nextTick - main.audiocontext.currentTime;\n        this.clock.start(now + time);\n        this.isPlaying = true;\n      }\n    }\n    /**\n     * Updates frequency value, reflected in next callback\n     * @private\n     * @for p5.SoundLoop\n     * @method  _update\n     */\n\n  }, {\n    key: \"_update\",\n    value: function _update() {\n      this.clock.frequency.value = this._calcFreq();\n    }\n    /**\n     * Calculate the frequency of the clock's callback based on bpm, interval, and timesignature\n     * @private\n     * @for p5.SoundLoop\n     * @method  _calcFreq\n     * @return {Number} new clock frequency value\n     */\n\n  }, {\n    key: \"_calcFreq\",\n    value: function _calcFreq() {\n      if (typeof this._interval === 'number') {\n        this.musicalTimeMode = false;\n        return 1 / this._interval;\n      } \n      else if (typeof this._interval === 'string') {\n          this.musicalTimeMode = true;\n          return this._bpm / 60 / this._convertNotation(this._interval) * (this._timeSignature / 4);\n        }\n    }\n    /**\n     * Convert notation from musical time format to seconds\n     * Uses <a href = \"https://github.com/Tonejs/Tone.js/wiki/Time\">Tone.Time</a> convention\n     * @private\n     * @for p5.SoundLoop\n     * @method _convertNotation\n     * @param  {String} value value to be converted\n     * @return {Number}       converted value in seconds\n     */\n\n  }, {\n    key: \"_convertNotation\",\n    value: function _convertNotation(value) {\n      var type = value.slice(-1);\n      value = Number(value.slice(0, -1));\n\n      switch (type) {\n        case 'm':\n          return this._measure(value);\n\n        case 'n':\n          return this._note(value);\n\n        default:\n          console.warn('Specified interval is not formatted correctly. See Tone.js ' + 'timing reference for more info: https://github.com/Tonejs/Tone.js/wiki/Time');\n      }\n    }\n    /**\n     * Helper conversion methods of measure and note\n     * @private\n     * @for p5.SoundLoop\n     * @method  _measure\n     */\n\n  }, {\n    key: \"_measure\",\n    value: function _measure(value) {\n      return value * this._timeSignature;\n    }\n    /**\n     * @private\n     * @method  _note\n     * @for p5.SoundLoop\n     */\n\n  }, {\n    key: \"_note\",\n    value: function _note(value) {\n      return this._timeSignature / value;\n    }\n  }]);\n\n  return SoundLoop;\n}();\n\n var soundLoop = (soundLoop_SoundLoop);\nfunction compressor_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { compressor_typeof = function _typeof(obj) { return typeof obj; }; } else { compressor_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return compressor_typeof(obj); }\n\nfunction compressor_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction compressor_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction compressor_createClass(Constructor, protoProps, staticProps) { if (protoProps) compressor_defineProperties(Constructor.prototype, protoProps); if (staticProps) compressor_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction compressor_possibleConstructorReturn(self, call) { if (call && (compressor_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return compressor_assertThisInitialized(self); }\n\nfunction compressor_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction compressor_get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { compressor_get = Reflect.get; } else { compressor_get = function _get(target, property, receiver) { var base = compressor_superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return compressor_get(target, property, receiver || target); }\n\nfunction compressor_superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = compressor_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction compressor_getPrototypeOf(o) { compressor_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return compressor_getPrototypeOf(o); }\n\nfunction compressor_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) compressor_setPrototypeOf(subClass, superClass); }\n\nfunction compressor_setPrototypeOf(o, p) { compressor_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return compressor_setPrototypeOf(o, p); }\n\n\n/**\n * Compressor is an audio effect class that performs dynamics compression\n * on an audio input source. This is a very commonly used technique in music\n * and sound production. Compression creates an overall louder, richer,\n * and fuller sound by lowering the volume of louds and raising that of softs.\n * Compression can be used to avoid clipping (sound distortion due to\n * peaks in volume) and is especially useful when many sounds are played\n * at once. Compression can be used on indivudal sound sources in addition\n * to the main output.\n *\n * This class extends <a href = \"/reference/#/p5.Effect\">p5.Effect</a>.\n * Methods <a href = \"/reference/#/p5.Effect/amp\">amp()</a>, <a href = \"/reference/#/p5.Effect/chain\">chain()</a>,\n * <a href = \"/reference/#/p5.Effect/drywet\">drywet()</a>, <a href = \"/reference/#/p5.Effect/connect\">connect()</a>, and\n * <a href = \"/reference/#/p5.Effect/disconnect\">disconnect()</a> are available.\n *\n * @class p5.Compressor\n * @constructor\n * @extends p5.Effect\n *\n *\n */\n\nvar Compressor =\nfunction (_Effect) {\n  compressor_inherits(Compressor, _Effect);\n\n  function Compressor() {\n    var _this;\n\n    compressor_classCallCheck(this, Compressor);\n\n    _this = compressor_possibleConstructorReturn(this, compressor_getPrototypeOf(Compressor).call(this));\n    /**\n     *\n     * The p5.Compressor is built with a <a href=\"https://www.w3.org/TR/webaudio/#the-dynamicscompressornode-interface\"\n     *   target=\"_blank\" title=\"W3 spec for Dynamics Compressor Node\">Web Audio Dynamics Compressor Node\n     *   </a>\n     * @property {AudioNode} compressor\n     */\n\n    _this.compressor = _this.ac.createDynamicsCompressor();\n\n    _this.input.connect(_this.compressor);\n\n    _this.compressor.connect(_this.wet);\n\n    return _this;\n  }\n  /**\n   * Performs the same function as .connect, but also accepts\n   * optional parameters to set compressor's audioParams\n   * @method process\n   * @for p5.Compressor\n   *\n   * @param {Object} src         Sound source to be connected\n   *\n   * @param {Number} [attack]     The amount of time (in seconds) to reduce the gain by 10dB,\n   *                            default = .003, range 0 - 1\n   * @param {Number} [knee]       A decibel value representing the range above the\n   *                            threshold where the curve smoothly transitions to the \"ratio\" portion.\n   *                            default = 30, range 0 - 40\n   * @param {Number} [ratio]      The amount of dB change in input for a 1 dB change in output\n   *                            default = 12, range 1 - 20\n   * @param {Number} [threshold]  The decibel value above which the compression will start taking effect\n   *                            default = -24, range -100 - 0\n   * @param {Number} [release]    The amount of time (in seconds) to increase the gain by 10dB\n   *                            default = .25, range 0 - 1\n   */\n\n\n  compressor_createClass(Compressor, [{\n    key: \"process\",\n    value: function process(src, attack, knee, ratio, threshold, release) {\n      src.connect(this.input);\n      this.set(attack, knee, ratio, threshold, release);\n    }\n    /**\n     * Set the paramters of a compressor.\n     * @method  set\n     * @for p5.Compressor\n     * @param {Number} attack     The amount of time (in seconds) to reduce the gain by 10dB,\n     *                            default = .003, range 0 - 1\n     * @param {Number} knee       A decibel value representing the range above the\n     *                            threshold where the curve smoothly transitions to the \"ratio\" portion.\n     *                            default = 30, range 0 - 40\n     * @param {Number} ratio      The amount of dB change in input for a 1 dB change in output\n     *                            default = 12, range 1 - 20\n     * @param {Number} threshold  The decibel value above which the compression will start taking effect\n     *                            default = -24, range -100 - 0\n     * @param {Number} release    The amount of time (in seconds) to increase the gain by 10dB\n     *                            default = .25, range 0 - 1\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(attack, knee, ratio, threshold, release) {\n      if (typeof attack !== 'undefined') {\n        this.attack(attack);\n      }\n\n      if (typeof knee !== 'undefined') {\n        this.knee(knee);\n      }\n\n      if (typeof ratio !== 'undefined') {\n        this.ratio(ratio);\n      }\n\n      if (typeof threshold !== 'undefined') {\n        this.threshold(threshold);\n      }\n\n      if (typeof release !== 'undefined') {\n        this.release(release);\n      }\n    }\n    /**\n     * Get current attack or set value w/ time ramp\n     *\n     *\n     * @method attack\n     * @for p5.Compressor\n     * @param {Number} [attack] Attack is the amount of time (in seconds) to reduce the gain by 10dB,\n     *                          default = .003, range 0 - 1\n     * @param {Number} [time]  Assign time value to schedule the change in value\n     */\n\n  }, {\n    key: \"attack\",\n    value: function attack(_attack, time) {\n      var t = time || 0;\n\n      if (typeof _attack === 'number') {\n        this.compressor.attack.value = _attack;\n        this.compressor.attack.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.compressor.attack.linearRampToValueAtTime(_attack, this.ac.currentTime + 0.02 + t);\n      } else if (typeof _attack !== 'undefined') {\n        _attack.connect(this.compressor.attack);\n      }\n\n      return this.compressor.attack.value;\n    }\n    /**\n     * Get current knee or set value w/ time ramp\n     *\n     * @method knee\n     * @for p5.Compressor\n     * @param {Number} [knee] A decibel value representing the range above the\n     *                        threshold where the curve smoothly transitions to the \"ratio\" portion.\n     *                        default = 30, range 0 - 40\n     * @param {Number} [time]  Assign time value to schedule the change in value\n     */\n\n  }, {\n    key: \"knee\",\n    value: function knee(_knee, time) {\n      var t = time || 0;\n\n      if (typeof _knee === 'number') {\n        this.compressor.knee.value = _knee;\n        this.compressor.knee.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.compressor.knee.linearRampToValueAtTime(_knee, this.ac.currentTime + 0.02 + t);\n      } else if (typeof _knee !== 'undefined') {\n        _knee.connect(this.compressor.knee);\n      }\n\n      return this.compressor.knee.value;\n    }\n    /**\n     * Get current ratio or set value w/ time ramp\n     * @method ratio\n     * @for p5.Compressor\n     * @param {Number} [ratio]      The amount of dB change in input for a 1 dB change in output\n     *                            default = 12, range 1 - 20\n     * @param {Number} [time]  Assign time value to schedule the change in value\n     */\n\n  }, {\n    key: \"ratio\",\n    value: function ratio(_ratio, time) {\n      var t = time || 0;\n\n      if (typeof _ratio === 'number') {\n        this.compressor.ratio.value = _ratio;\n        this.compressor.ratio.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.compressor.ratio.linearRampToValueAtTime(_ratio, this.ac.currentTime + 0.02 + t);\n      } else if (typeof _ratio !== 'undefined') {\n        _ratio.connect(this.compressor.ratio);\n      }\n\n      return this.compressor.ratio.value;\n    }\n    /**\n     * Get current threshold or set value w/ time ramp\n     * @method threshold\n     * @for p5.Compressor\n     * @param {Number} threshold  The decibel value above which the compression will start taking effect\n     *                            default = -24, range -100 - 0\n     * @param {Number} [time]  Assign time value to schedule the change in value\n     */\n\n  }, {\n    key: \"threshold\",\n    value: function threshold(_threshold, time) {\n      var t = time || 0;\n\n      if (typeof _threshold === 'number') {\n        this.compressor.threshold.value = _threshold;\n        this.compressor.threshold.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.compressor.threshold.linearRampToValueAtTime(_threshold, this.ac.currentTime + 0.02 + t);\n      } else if (typeof _threshold !== 'undefined') {\n        _threshold.connect(this.compressor.threshold);\n      }\n\n      return this.compressor.threshold.value;\n    }\n    /**\n     * Get current release or set value w/ time ramp\n     * @method release\n     * @for p5.Compressor\n     * @param {Number} release    The amount of time (in seconds) to increase the gain by 10dB\n     *                            default = .25, range 0 - 1\n     *\n     * @param {Number} [time]  Assign time value to schedule the change in value\n     */\n\n  }, {\n    key: \"release\",\n    value: function release(_release, time) {\n      var t = time || 0;\n\n      if (typeof _release === 'number') {\n        this.compressor.release.value = _release;\n        this.compressor.release.cancelScheduledValues(this.ac.currentTime + 0.01 + t);\n        this.compressor.release.linearRampToValueAtTime(_release, this.ac.currentTime + 0.02 + t);\n      } else if (typeof number !== 'undefined') {\n        _release.connect(this.compressor.release);\n      }\n\n      return this.compressor.release.value;\n    }\n    /**\n     * Return the current reduction value\n     *\n     * @method reduction\n     * @for p5.Compressor\n     * @return {Number} Value of the amount of gain reduction that is applied to the signal\n     */\n\n  }, {\n    key: \"reduction\",\n    value: function reduction() {\n      return this.compressor.reduction.value;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      compressor_get(compressor_getPrototypeOf(Compressor.prototype), \"dispose\", this).call(this);\n\n      if (this.compressor) {\n        this.compressor.disconnect();\n        delete this.compressor;\n      }\n    }\n  }]);\n\n  return Compressor;\n}(effect);\n\n var compressor = (Compressor);\nfunction peakDetect_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction peakDetect_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction peakDetect_createClass(Constructor, protoProps, staticProps) { if (protoProps) peakDetect_defineProperties(Constructor.prototype, protoProps); if (staticProps) peakDetect_defineProperties(Constructor, staticProps); return Constructor; }\n\n/**\n *  <p>PeakDetect works in conjunction with p5.FFT to\n *  look for onsets in some or all of the frequency spectrum.\n *  </p>\n *  <p>\n *  To use p5.PeakDetect, call <code>update</code> in the draw loop\n *  and pass in a p5.FFT object.\n *  </p>\n *  <p>\n *  You can listen for a specific part of the frequency spectrum by\n *  setting the range between <code>freq1</code> and <code>freq2</code>.\n *  </p>\n *\n *  <p><code>threshold</code> is the threshold for detecting a peak,\n *  scaled between 0 and 1. It is logarithmic, so 0.1 is half as loud\n *  as 1.0.</p>\n *\n *  <p>\n *  The update method is meant to be run in the draw loop, and\n *  <b>frames</b> determines how many loops must pass before\n *  another peak can be detected.\n *  For example, if the frameRate() = 60, you could detect the beat of a\n *  120 beat-per-minute song with this equation:\n *  <code> framesPerPeak = 60 / (estimatedBPM / 60 );</code>\n *  </p>\n *\n *  <p>\n *  Based on example contribtued by @b2renger, and a simple beat detection\n *  explanation by <a\n *  href=\"http://www.airtightinteractive.com/2013/10/making-audio-reactive-visuals/\"\n *  target=\"_blank\">Felix Turner</a>.\n *  </p>\n *\n *  @class  p5.PeakDetect\n *  @constructor\n *  @param {Number} [freq1]     lowFrequency - defaults to 20Hz\n *  @param {Number} [freq2]     highFrequency - defaults to 20000 Hz\n *  @param {Number} [threshold] Threshold for detecting a beat between 0 and 1\n *                            scaled logarithmically where 0.1 is 1/2 the loudness\n *                            of 1.0. Defaults to 0.35.\n *  @param {Number} [framesPerPeak]     Defaults to 20.\n *  @example\n *  <div><code>\n *\n *  var cnv, soundFile, fft, peakDetect;\n *  var ellipseWidth = 10;\n *\n *  function preload() {\n *    soundFile = loadSound('assets/beat.mp3');\n *  }\n *\n *  function setup() {\n *    background(0);\n *    noStroke();\n *    fill(255);\n *    textAlign(CENTER);\n *\n *    // p5.PeakDetect requires a p5.FFT\n *    fft = new p5.FFT();\n *    peakDetect = new p5.PeakDetect();\n *  }\n *\n *  function draw() {\n *    background(0);\n *    text('click to play/pause', width/2, height/2);\n *\n *    // peakDetect accepts an fft post-analysis\n *    fft.analyze();\n *    peakDetect.update(fft);\n *\n *    if ( peakDetect.isDetected ) {\n *      ellipseWidth = 50;\n *    } else {\n *      ellipseWidth *= 0.95;\n *    }\n *\n *    ellipse(width/2, height/2, ellipseWidth, ellipseWidth);\n *  }\n *\n *  // toggle play/stop when canvas is clicked\n *  function mouseClicked() {\n *    if (mouseX > 0 && mouseX < width && mouseY > 0 && mouseY < height) {\n *      if (soundFile.isPlaying() ) {\n *        soundFile.stop();\n *      } else {\n *        soundFile.play();\n *      }\n *    }\n *  }\n *  </code></div>\n */\nvar PeakDetect =\nfunction () {\n  function PeakDetect(freq1, freq2, threshold, _framesPerPeak) {\n    peakDetect_classCallCheck(this, PeakDetect);\n\n    this.framesPerPeak = _framesPerPeak || 20;\n    this.framesSinceLastPeak = 0;\n    this.decayRate = 0.95;\n    this.threshold = threshold || 0.35;\n    this.cutoff = 0; \n\n    this.cutoffMult = 1.5;\n    this.energy = 0;\n    this.penergy = 0; \n\n    this.currentValue = 0;\n    /**\n     *  isDetected is set to true when a peak is detected.\n     *\n     *  @attribute isDetected {Boolean}\n     *  @default  false\n     */\n\n    this.isDetected = false;\n    this.f1 = freq1 || 40;\n    this.f2 = freq2 || 20000; \n\n    this._onPeak = function () {};\n  }\n  /**\n   *  The update method is run in the draw loop.\n   *\n   *  Accepts an FFT object. You must call .analyze()\n   *  on the FFT object prior to updating the peakDetect\n   *  because it relies on a completed FFT analysis.\n   *\n   *  @method  update\n   *  @param  {p5.FFT} fftObject A p5.FFT object\n   */\n\n\n  peakDetect_createClass(PeakDetect, [{\n    key: \"update\",\n    value: function update(fftObject) {\n      var nrg = this.energy = fftObject.getEnergy(this.f1, this.f2) / 255;\n\n      if (nrg > this.cutoff && nrg > this.threshold && nrg - this.penergy > 0) {\n        this._onPeak();\n\n        this.isDetected = true; \n\n        this.cutoff = nrg * this.cutoffMult;\n        this.framesSinceLastPeak = 0;\n      } else {\n        this.isDetected = false;\n\n        if (this.framesSinceLastPeak <= this.framesPerPeak) {\n          this.framesSinceLastPeak++;\n        } else {\n          this.cutoff *= this.decayRate;\n          this.cutoff = Math.max(this.cutoff, this.threshold);\n        }\n      }\n\n      this.currentValue = nrg;\n      this.penergy = nrg;\n    }\n    /**\n     *  onPeak accepts two arguments: a function to call when\n     *  a peak is detected. The value of the peak,\n     *  between 0.0 and 1.0, is passed to the callback.\n     *\n     *  @method  onPeak\n     *  @param  {Function} callback Name of a function that will\n     *                              be called when a peak is\n     *                              detected.\n     *  @param  {Object}   [val]    Optional value to pass\n     *                              into the function when\n     *                              a peak is detected.\n     *  @example\n     *  <div><code>\n     *  var cnv, soundFile, fft, peakDetect;\n     *  var ellipseWidth = 0;\n     *\n     *  function preload() {\n     *    soundFile = loadSound('assets/beat.mp3');\n     *  }\n     *\n     *  function setup() {\n     *    cnv = createCanvas(100,100);\n     *    textAlign(CENTER);\n     *\n     *    fft = new p5.FFT();\n     *    peakDetect = new p5.PeakDetect();\n     *\n     *    setupSound();\n     *\n     *    // when a beat is detected, call triggerBeat()\n     *    peakDetect.onPeak(triggerBeat);\n     *  }\n     *\n     *  function draw() {\n     *    background(0);\n     *    fill(255);\n     *    text('click to play', width/2, height/2);\n     *\n     *    fft.analyze();\n     *    peakDetect.update(fft);\n     *\n     *    ellipseWidth *= 0.95;\n     *    ellipse(width/2, height/2, ellipseWidth, ellipseWidth);\n     *  }\n     *\n     *  // this function is called by peakDetect.onPeak\n     *  function triggerBeat() {\n     *    ellipseWidth = 50;\n     *  }\n     *\n     *  // mouseclick starts/stops sound\n     *  function setupSound() {\n     *    cnv.mouseClicked( function() {\n     *      if (soundFile.isPlaying() ) {\n     *        soundFile.stop();\n     *      } else {\n     *        soundFile.play();\n     *      }\n     *    });\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"onPeak\",\n    value: function onPeak(callback, val) {\n      var self = this;\n\n      self._onPeak = function () {\n        callback(self.energy, val);\n      };\n    }\n  }]);\n\n  return PeakDetect;\n}();\n\n var peakDetect = (PeakDetect);\nfunction soundRecorder_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction soundRecorder_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction soundRecorder_createClass(Constructor, protoProps, staticProps) { if (protoProps) soundRecorder_defineProperties(Constructor.prototype, protoProps); if (staticProps) soundRecorder_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n\nvar soundRecorder_ac = main.audiocontext;\n/**\n *  <p>Record sounds for playback and/or to save as a .wav file.\n *  The p5.SoundRecorder records all sound output from your sketch,\n *  or can be assigned a specific source with setInput().</p>\n *  <p>The record() method accepts a p5.SoundFile as a parameter.\n *  When playback is stopped (either after the given amount of time,\n *  or with the stop() method), the p5.SoundRecorder will send its\n *  recording to that p5.SoundFile for playback.</p>\n *\n *  @class p5.SoundRecorder\n *  @constructor\n *  @example\n *  <div><code>\n *  let mic, recorder, soundFile;\n *  let state = 0;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(canvasPressed);\n *    background(220);\n *    textAlign(CENTER, CENTER);\n *\n *    // create an audio in\n *    mic = new p5.AudioIn();\n *\n *    // prompts user to enable their browser mic\n *    mic.start();\n *\n *    // create a sound recorder\n *    recorder = new p5.SoundRecorder();\n *\n *    // connect the mic to the recorder\n *    recorder.setInput(mic);\n *\n *    // this sound file will be used to\n *    // playback & save the recording\n *    soundFile = new p5.SoundFile();\n *\n *    text('tap to record', width/2, height/2);\n *  }\n *\n *  function canvasPressed() {\n *    // ensure audio is enabled\n *    userStartAudio();\n *\n *    // make sure user enabled the mic\n *    if (state === 0 && mic.enabled) {\n *\n *      // record to our p5.SoundFile\n *      recorder.record(soundFile);\n *\n *      background(255,0,0);\n *      text('Recording!', width/2, height/2);\n *      state++;\n *    }\n *    else if (state === 1) {\n *      background(0,255,0);\n *\n *      // stop recorder and\n *      // send result to soundFile\n *      recorder.stop();\n *\n *      text('Done! Tap to play and download', width/2, height/2, width - 20);\n *      state++;\n *    }\n *\n *    else if (state === 2) {\n *      soundFile.play(); // play the result!\n *      save(soundFile, 'mySound.wav');\n *      state++;\n *    }\n *  }\n *  </div></code>\n */\n\nvar soundRecorder_SoundRecorder =\nfunction () {\n  function SoundRecorder() {\n    soundRecorder_classCallCheck(this, SoundRecorder);\n\n    this.input = soundRecorder_ac.createGain();\n    this.output = soundRecorder_ac.createGain();\n    this._inputChannels = 2;\n    this._outputChannels = 2; \n\n    var workletBufferSize = safeBufferSize(1024);\n    this._workletNode = new AudioWorkletNode(soundRecorder_ac, processorNames_default.a.recorderProcessor, {\n      outputChannelCount: [this._outputChannels],\n      processorOptions: {\n        numInputChannels: this._inputChannels,\n        bufferSize: workletBufferSize\n      }\n    });\n\n    this._workletNode.port.onmessage = function (event) {\n      if (event.data.name === 'buffers') {\n        var buffers = [new Float32Array(event.data.leftBuffer), new Float32Array(event.data.rightBuffer)];\n\n        this._callback(buffers);\n      }\n    }.bind(this);\n    /**\n     *  callback invoked when the recording is over\n     *  @private\n     *  @type Function(Float32Array)\n     */\n\n\n    this._callback = function () {}; \n\n\n    this._workletNode.connect(p5.soundOut._silentNode);\n\n    this.setInput(); \n\n    main.soundArray.push(this);\n  }\n  /**\n   *  Connect a specific device to the p5.SoundRecorder.\n   *  If no parameter is given, p5.SoundRecorer will record\n   *  all audible p5.sound from your sketch.\n   *\n   *  @method  setInput\n   *  @for p5.SoundRecorder\n   *  @param {Object} [unit] p5.sound object or a web audio unit\n   *                         that outputs sound\n   */\n\n\n  soundRecorder_createClass(SoundRecorder, [{\n    key: \"setInput\",\n    value: function setInput(unit) {\n      this.input.disconnect();\n      this.input = null;\n      this.input = soundRecorder_ac.createGain();\n      this.input.connect(this._workletNode);\n      this.input.connect(this.output);\n\n      if (unit) {\n        unit.connect(this.input);\n      } else {\n        p5.soundOut.output.connect(this.input);\n      }\n    }\n    /**\n     *  Start recording. To access the recording, provide\n     *  a p5.SoundFile as the first parameter. The p5.SoundRecorder\n     *  will send its recording to that p5.SoundFile for playback once\n     *  recording is complete. Optional parameters include duration\n     *  (in seconds) of the recording, and a callback function that\n     *  will be called once the complete recording has been\n     *  transfered to the p5.SoundFile.\n     *\n     *  @method  record\n     *  @for p5.SoundRecorder\n     *  @param  {p5.SoundFile}   soundFile    p5.SoundFile\n     *  @param  {Number}   [duration] Time (in seconds)\n     *  @param  {Function} [callback] The name of a function that will be\n     *                                called once the recording completes\n     */\n\n  }, {\n    key: \"record\",\n    value: function record(sFile, duration, callback) {\n      this._workletNode.port.postMessage({\n        name: 'start',\n        duration: duration\n      });\n\n      if (sFile && callback) {\n        this._callback = function (buffer) {\n          sFile.setBuffer(buffer);\n          callback();\n        };\n      } else if (sFile) {\n        this._callback = function (buffer) {\n          sFile.setBuffer(buffer);\n        };\n      }\n    }\n    /**\n     *  Stop the recording. Once the recording is stopped,\n     *  the results will be sent to the p5.SoundFile that\n     *  was given on .record(), and if a callback function\n     *  was provided on record, that function will be called.\n     *\n     *  @method  stop\n     *  @for p5.SoundRecorder\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      this._workletNode.port.postMessage({\n        name: 'stop'\n      });\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n\n      this._callback = function () {};\n\n      if (this.input) {\n        this.input.disconnect();\n      }\n\n      this.input = null;\n      this._workletNode = null;\n    }\n  }]);\n\n  return SoundRecorder;\n}();\n\n var soundRecorder = (soundRecorder_SoundRecorder);\nfunction distortion_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { distortion_typeof = function _typeof(obj) { return typeof obj; }; } else { distortion_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return distortion_typeof(obj); }\n\nfunction distortion_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction distortion_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction distortion_createClass(Constructor, protoProps, staticProps) { if (protoProps) distortion_defineProperties(Constructor.prototype, protoProps); if (staticProps) distortion_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction distortion_possibleConstructorReturn(self, call) { if (call && (distortion_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return distortion_assertThisInitialized(self); }\n\nfunction distortion_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction distortion_get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { distortion_get = Reflect.get; } else { distortion_get = function _get(target, property, receiver) { var base = distortion_superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return distortion_get(target, property, receiver || target); }\n\nfunction distortion_superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = distortion_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction distortion_getPrototypeOf(o) { distortion_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return distortion_getPrototypeOf(o); }\n\nfunction distortion_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) distortion_setPrototypeOf(subClass, superClass); }\n\nfunction distortion_setPrototypeOf(o, p) { distortion_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return distortion_setPrototypeOf(o, p); }\n\n\n\nfunction makeDistortionCurve(amount) {\n  var k = typeof amount === 'number' ? amount : 50;\n  var numSamples = 44100;\n  var curve = new Float32Array(numSamples);\n  var deg = Math.PI / 180;\n  var i = 0;\n  var x;\n\n  for (; i < numSamples; ++i) {\n    x = i * 2 / numSamples - 1;\n    curve[i] = (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));\n  }\n\n  return curve;\n}\n/**\n * A Distortion effect created with a Waveshaper Node,\n * with an approach adapted from\n * [Kevin Ennis](http://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion)\n *\n * This class extends <a href = \"/reference/#/p5.Effect\">p5.Effect</a>.\n * Methods <a href = \"/reference/#/p5.Effect/amp\">amp()</a>, <a href = \"/reference/#/p5.Effect/chain\">chain()</a>,\n * <a href = \"/reference/#/p5.Effect/drywet\">drywet()</a>, <a href = \"/reference/#/p5.Effect/connect\">connect()</a>, and\n * <a href = \"/reference/#/p5.Effect/disconnect\">disconnect()</a> are available.\n *\n * @class p5.Distortion\n * @extends p5.Effect\n * @constructor\n * @param {Number} [amount=0.25] Unbounded distortion amount.\n *                                Normal values range from 0-1.\n * @param {String} [oversample='none'] 'none', '2x', or '4x'.\n *\n */\n\n\nvar Distortion =\nfunction (_Effect) {\n  distortion_inherits(Distortion, _Effect);\n\n  function Distortion(amount, oversample) {\n    var _this;\n\n    distortion_classCallCheck(this, Distortion);\n\n    _this = distortion_possibleConstructorReturn(this, distortion_getPrototypeOf(Distortion).call(this));\n\n    if (typeof amount === 'undefined') {\n      amount = 0.25;\n    }\n\n    if (typeof amount !== 'number') {\n      throw new Error('amount must be a number');\n    }\n\n    if (typeof oversample === 'undefined') {\n      oversample = '2x';\n    }\n\n    if (typeof oversample !== 'string') {\n      throw new Error('oversample must be a String');\n    }\n\n    var curveAmount = p5.prototype.map(amount, 0.0, 1.0, 0, 2000);\n    /**\n     *  The p5.Distortion is built with a\n     *  <a href=\"http://www.w3.org/TR/webaudio/#WaveShaperNode\">\n     *  Web Audio WaveShaper Node</a>.\n     *\n     *  @property {AudioNode} WaveShaperNode\n     */\n\n    _this.waveShaperNode = _this.ac.createWaveShaper();\n    _this.amount = curveAmount;\n    _this.waveShaperNode.curve = makeDistortionCurve(curveAmount);\n    _this.waveShaperNode.oversample = oversample;\n\n    _this.input.connect(_this.waveShaperNode);\n\n    _this.waveShaperNode.connect(_this.wet);\n\n    return _this;\n  }\n  /**\n   * Process a sound source, optionally specify amount and oversample values.\n   *\n   * @method process\n   * @for p5.Distortion\n   * @param {Number} [amount=0.25] Unbounded distortion amount.\n   *                                Normal values range from 0-1.\n   * @param {String} [oversample='none'] 'none', '2x', or '4x'.\n   */\n\n\n  distortion_createClass(Distortion, [{\n    key: \"process\",\n    value: function process(src, amount, oversample) {\n      src.connect(this.input);\n      this.set(amount, oversample);\n    }\n    /**\n     * Set the amount and oversample of the waveshaper distortion.\n     *\n     * @method set\n     * @for p5.Distortion\n     * @param {Number} [amount=0.25] Unbounded distortion amount.\n     *                                Normal values range from 0-1.\n     * @param {String} [oversample='none'] 'none', '2x', or '4x'.\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(amount, oversample) {\n      if (amount) {\n        var curveAmount = p5.prototype.map(amount, 0.0, 1.0, 0, 2000);\n        this.amount = curveAmount;\n        this.waveShaperNode.curve = makeDistortionCurve(curveAmount);\n      }\n\n      if (oversample) {\n        this.waveShaperNode.oversample = oversample;\n      }\n    }\n    /**\n     *  Return the distortion amount, typically between 0-1.\n     *\n     *  @method  getAmount\n     *  @for p5.Distortion\n     *  @return {Number} Unbounded distortion amount.\n     *                   Normal values range from 0-1.\n     */\n\n  }, {\n    key: \"getAmount\",\n    value: function getAmount() {\n      return this.amount;\n    }\n    /**\n     *  Return the oversampling.\n     *\n     *  @method getOversample\n     *  @for p5.Distortion\n     *  @return {String} Oversample can either be 'none', '2x', or '4x'.\n     */\n\n  }, {\n    key: \"getOversample\",\n    value: function getOversample() {\n      return this.waveShaperNode.oversample;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      distortion_get(distortion_getPrototypeOf(Distortion.prototype), \"dispose\", this).call(this);\n\n      if (this.waveShaperNode) {\n        this.waveShaperNode.disconnect();\n        this.waveShaperNode = null;\n      }\n    }\n  }]);\n\n  return Distortion;\n}(effect);\n\n var distortion = (Distortion);\nfunction gain_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction gain_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction gain_createClass(Constructor, protoProps, staticProps) { if (protoProps) gain_defineProperties(Constructor.prototype, protoProps); if (staticProps) gain_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n/**\n *  A gain node is usefull to set the relative volume of sound.\n *  It's typically used to build mixers.\n *\n *  @class p5.Gain\n *  @constructor\n *  @example\n *  <div><code>\n *\n *  // load two soundfile and crossfade beetween them\n *  let sound1,sound2;\n *  let sound1Gain, sound2Gain, mixGain;\n *  function preload(){\n *    soundFormats('ogg', 'mp3');\n *    sound1 = loadSound('assets/Damscray_-_Dancing_Tiger_01');\n *    sound2 = loadSound('assets/beat');\n *  }\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(startSound);\n *    // create a 'mix' gain bus to which we will connect both soundfiles\n *    mixGain = new p5.Gain();\n *    mixGain.connect();\n *    sound1.disconnect(); // diconnect from p5 output\n *    sound1Gain = new p5.Gain(); // setup a gain node\n *    sound1Gain.setInput(sound1); // connect the first sound to its input\n *    sound1Gain.connect(mixGain); // connect its output to the final mix bus\n *    sound2.disconnect();\n *    sound2Gain = new p5.Gain();\n *    sound2Gain.setInput(sound2);\n *    sound2Gain.connect(mixGain);\n *  }\n *  function startSound() {\n *    sound1.loop();\n *    sound2.loop();\n *    loop();\n *  }\n *  function mouseReleased() {\n *    sound1.stop();\n *    sound2.stop();\n *  }\n *  function draw(){\n *    background(220);\n *    textAlign(CENTER);\n *    textSize(11);\n *    fill(0);\n *    if (!sound1.isPlaying()) {\n *      text('tap and drag to play', width/2, height/2);\n *      return;\n *    }\n *    // map the horizontal position of the mouse to values useable for volume    *  control of sound1\n *    var sound1Volume = constrain(map(mouseX,width,0,0,1), 0, 1);\n *    var sound2Volume = 1-sound1Volume;\n *    sound1Gain.amp(sound1Volume);\n *    sound2Gain.amp(sound2Volume);\n *    // map the vertical position of the mouse to values useable for 'output    *  volume control'\n *    var outputVolume = constrain(map(mouseY,height,0,0,1), 0, 1);\n *    mixGain.amp(outputVolume);\n *    text('output', width/2, height - outputVolume * height * 0.9)\n *    fill(255, 0, 255);\n *    textAlign(LEFT);\n *    text('sound1', 5, height - sound1Volume * height * 0.9);\n *    textAlign(RIGHT);\n *    text('sound2', width - 5, height - sound2Volume * height * 0.9);\n *  }\n *</code></div>\n */\n\nvar gain_Gain =\nfunction () {\n  function Gain() {\n    gain_classCallCheck(this, Gain);\n\n    this.ac = main.audiocontext;\n    this.input = this.ac.createGain();\n    this.output = this.ac.createGain(); \n\n    this.input.gain.value = 0.5;\n    this.input.connect(this.output); \n\n    main.soundArray.push(this);\n  }\n  /**\n   *  Connect a source to the gain node.\n   *\n   *  @method  setInput\n   *  @for p5.Gain\n   *  @param  {Object} src     p5.sound / Web Audio object with a sound\n   *                           output.\n   */\n\n\n  gain_createClass(Gain, [{\n    key: \"setInput\",\n    value: function setInput(src) {\n      src.connect(this.input);\n    }\n    /**\n     *  Send output to a p5.sound or web audio object\n     *\n     *  @method  connect\n     *  @for p5.Gain\n     *  @param  {Object} unit\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      var u = unit || p5.soundOut.input;\n      this.output.connect(u.input ? u.input : u);\n    }\n    /**\n     *  Disconnect all output.\n     *\n     *  @method disconnect\n     *  @for p5.Gain\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.output) {\n        this.output.disconnect();\n      }\n    }\n    /**\n     *  Set the output level of the gain node.\n     *\n     *  @method  amp\n     *  @for p5.Gain\n     *  @param  {Number} volume amplitude between 0 and 1.0\n     *  @param  {Number} [rampTime] create a fade that lasts rampTime\n     *  @param  {Number} [timeFromNow] schedule this event to happen\n     *                                seconds from now\n     */\n\n  }, {\n    key: \"amp\",\n    value: function amp(vol) {\n      var rampTime = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n      var tFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n      var now = main.audiocontext.currentTime;\n      var currentVol = this.output.gain.value;\n      this.output.gain.cancelScheduledValues(now);\n      this.output.gain.linearRampToValueAtTime(currentVol, now + tFromNow);\n      this.output.gain.linearRampToValueAtTime(vol, now + tFromNow + rampTime);\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var index = main.soundArray.indexOf(this);\n      main.soundArray.splice(index, 1);\n\n      if (this.output) {\n        this.output.disconnect();\n        delete this.output;\n      }\n\n      if (this.input) {\n        this.input.disconnect();\n        delete this.input;\n      }\n    }\n  }]);\n\n  return Gain;\n}();\n\n var gain = (gain_Gain);\nfunction audioVoice_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction audioVoice_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction audioVoice_createClass(Constructor, protoProps, staticProps) { if (protoProps) audioVoice_defineProperties(Constructor.prototype, protoProps); if (staticProps) audioVoice_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n/**\n * Base class for monophonic synthesizers. Any extensions of this class\n * should follow the API and implement the methods below in order to\n * remain compatible with p5.PolySynth();\n *\n * @class p5.AudioVoice\n * @constructor\n */\n\nvar audioVoice_AudioVoice =\nfunction () {\n  function AudioVoice() {\n    audioVoice_classCallCheck(this, AudioVoice);\n\n    this.ac = main.audiocontext;\n    this.output = this.ac.createGain();\n    this.connect();\n    main.soundArray.push(this);\n  }\n\n  audioVoice_createClass(AudioVoice, [{\n    key: \"play\",\n    value: function play(note, velocity, secondsFromNow, sustime) {}\n  }, {\n    key: \"triggerAttack\",\n    value: function triggerAttack(note, velocity, secondsFromNow) {}\n  }, {\n    key: \"triggerRelease\",\n    value: function triggerRelease(secondsFromNow) {}\n  }, {\n    key: \"amp\",\n    value: function amp(vol, rampTime) {}\n    /**\n     * Connect to p5 objects or Web Audio Nodes\n     * @method  connect\n     * @for p5.AudioVoice\n     * @param {Object} unit\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      var u = unit || main.input;\n      this.output.connect(u.input ? u.input : u);\n    }\n    /**\n     * Disconnect from soundOut\n     * @method  disconnect\n     * @for p5.AudioVoice\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      this.output.disconnect();\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      if (this.output) {\n        this.output.disconnect();\n        delete this.output;\n      }\n    }\n  }]);\n\n  return AudioVoice;\n}();\n\n var audioVoice_0 = (audioVoice_AudioVoice);\nfunction monosynth_typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { monosynth_typeof = function _typeof(obj) { return typeof obj; }; } else { monosynth_typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return monosynth_typeof(obj); }\n\nfunction monosynth_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction monosynth_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction monosynth_createClass(Constructor, protoProps, staticProps) { if (protoProps) monosynth_defineProperties(Constructor.prototype, protoProps); if (staticProps) monosynth_defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction monosynth_possibleConstructorReturn(self, call) { if (call && (monosynth_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return monosynth_assertThisInitialized(self); }\n\nfunction monosynth_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction monosynth_get(target, property, receiver) { if (typeof Reflect !== \"undefined\" && Reflect.get) { monosynth_get = Reflect.get; } else { monosynth_get = function _get(target, property, receiver) { var base = monosynth_superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(receiver); } return desc.value; }; } return monosynth_get(target, property, receiver || target); }\n\nfunction monosynth_superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = monosynth_getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction monosynth_getPrototypeOf(o) { monosynth_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return monosynth_getPrototypeOf(o); }\n\nfunction monosynth_inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) monosynth_setPrototypeOf(subClass, superClass); }\n\nfunction monosynth_setPrototypeOf(o, p) { monosynth_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return monosynth_setPrototypeOf(o, p); }\n\n\n\n\n\n\nvar DEFAULT_SUSTAIN = 0.15;\n/**\n *  A MonoSynth is used as a single voice for sound synthesis.\n *  This is a class to be used in conjunction with the PolySynth\n *  class. Custom synthetisers should be built inheriting from\n *  this class.\n *\n *  @class p5.MonoSynth\n *  @constructor\n *  @example\n *  <div><code>\n *  let monoSynth;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playSynth);\n *    background(220);\n *    textAlign(CENTER);\n *    text('tap to play', width/2, height/2);\n *\n *    monoSynth = new p5.MonoSynth();\n *  }\n *\n *  function playSynth() {\n *    userStartAudio();\n *\n *    let note = random(['Fb4', 'G4']);\n *    // note velocity (volume, from 0 to 1)\n *    let velocity = random();\n *    // time from now (in seconds)\n *    let time = 0;\n *    // note duration (in seconds)\n *    let dur = 1/6;\n *\n *    monoSynth.play(note, velocity, time, dur);\n *  }\n *  </code></div>\n **/\n\nvar monosynth_MonoSynth =\nfunction (_AudioVoice) {\n  monosynth_inherits(MonoSynth, _AudioVoice);\n\n  function MonoSynth() {\n    var _this;\n\n    monosynth_classCallCheck(this, MonoSynth);\n\n    _this = monosynth_possibleConstructorReturn(this, monosynth_getPrototypeOf(MonoSynth).call(this));\n    _this.oscillator = new oscillator();\n    _this.env = new envelope(); \n\n    _this.env.setRange(1, 0);\n\n    _this.env.setExp(true); \n\n\n    _this.setADSR(0.02, 0.25, 0.05, 0.35); \n\n\n    _this.oscillator.disconnect();\n\n    _this.oscillator.connect(_this.output);\n\n    _this.env.disconnect();\n\n    _this.env.setInput(_this.output.gain); \n\n\n    _this.oscillator.output.gain.value = 1.0;\n\n    _this.oscillator.start();\n\n    _this.connect();\n\n    main.soundArray.push(monosynth_assertThisInitialized(_this));\n    /**\n     * Getters and Setters\n     * @property {Number} attack\n     * @for p5.MonoSynth\n     */\n\n    /**\n     * @property {Number} decay\n     * @for p5.MonoSynth\n     */\n\n    /**\n     * @property {Number} sustain\n     * @for p5.MonoSynth\n     */\n\n    /**\n     * @property {Number} release\n     * @for p5.MonoSynth\n     */\n\n    Object.defineProperties(monosynth_assertThisInitialized(_this), {\n      attack: {\n        get: function get() {\n          return this.env.aTime;\n        },\n        set: function set(attack) {\n          this.env.setADSR(attack, this.env.dTime, this.env.sPercent, this.env.rTime);\n        }\n      },\n      decay: {\n        get: function get() {\n          return this.env.dTime;\n        },\n        set: function set(decay) {\n          this.env.setADSR(this.env.aTime, decay, this.env.sPercent, this.env.rTime);\n        }\n      },\n      sustain: {\n        get: function get() {\n          return this.env.sPercent;\n        },\n        set: function set(sustain) {\n          this.env.setADSR(this.env.aTime, this.env.dTime, sustain, this.env.rTime);\n        }\n      },\n      release: {\n        get: function get() {\n          return this.env.rTime;\n        },\n        set: function set(release) {\n          this.env.setADSR(this.env.aTime, this.env.dTime, this.env.sPercent, release);\n        }\n      }\n    });\n    return _this;\n  }\n  /**\n   *  Play tells the MonoSynth to start playing a note. This method schedules\n   *  the calling of .triggerAttack and .triggerRelease.\n   *\n   *  @method play\n   *  @for p5.MonoSynth\n   *  @param {String | Number} note the note you want to play, specified as a\n   *                                 frequency in Hertz (Number) or as a midi\n   *                                 value in Note/Octave format (\"C4\", \"Eb3\"...etc\")\n   *                                 See <a href = \"https://github.com/Tonejs/Tone.js/wiki/Instruments\">\n   *                                 Tone</a>. Defaults to 440 hz.\n   *  @param  {Number} [velocity] velocity of the note to play (ranging from 0 to 1)\n   *  @param  {Number} [secondsFromNow]  time from now (in seconds) at which to play\n   *  @param  {Number} [sustainTime] time to sustain before releasing the envelope. Defaults to 0.15 seconds.\n   *  @example\n   *  <div><code>\n   *  let monoSynth;\n   *\n   *  function setup() {\n   *    let cnv = createCanvas(100, 100);\n   *    cnv.mousePressed(playSynth);\n   *    background(220);\n   *    textAlign(CENTER);\n   *    text('tap to play', width/2, height/2);\n   *\n   *    monoSynth = new p5.MonoSynth();\n   *  }\n   *\n   *  function playSynth() {\n   *    userStartAudio();\n   *\n   *    let note = random(['Fb4', 'G4']);\n   *    // note velocity (volume, from 0 to 1)\n   *    let velocity = random();\n   *    // time from now (in seconds)\n   *    let time = 0;\n   *    // note duration (in seconds)\n   *    let dur = 1/6;\n   *\n   *    monoSynth.play(note, velocity, time, dur);\n   *  }\n   *  </code></div>\n   *\n   */\n\n\n  monosynth_createClass(MonoSynth, [{\n    key: \"play\",\n    value: function play(note, velocity, secondsFromNow, susTime) {\n      this.triggerAttack(note, velocity, ~~secondsFromNow);\n      this.triggerRelease(~~secondsFromNow + (susTime || DEFAULT_SUSTAIN));\n    }\n    /**\n     *  Trigger the Attack, and Decay portion of the Envelope.\n     *  Similar to holding down a key on a piano, but it will\n     *  hold the sustain level until you let go.\n     *\n     *  @param {String | Number} note the note you want to play, specified as a\n     *                                 frequency in Hertz (Number) or as a midi\n     *                                 value in Note/Octave format (\"C4\", \"Eb3\"...etc\")\n     *                                 See <a href = \"https://github.com/Tonejs/Tone.js/wiki/Instruments\">\n     *                                 Tone</a>. Defaults to 440 hz\n     *  @param  {Number} [velocity] velocity of the note to play (ranging from 0 to 1)\n     *  @param  {Number} [secondsFromNow]  time from now (in seconds) at which to play\n     *  @method  triggerAttack\n     *  @for p5.MonoSynth\n     *  @example\n     *  <div><code>\n     *  let monoSynth;\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(triggerAttack);\n     *    background(220);\n     *    text('tap here for attack, let go to release', 5, 20, width - 20);\n     *    monoSynth = new p5.MonoSynth();\n     *  }\n     *\n     *  function triggerAttack() {\n     *    userStartAudio();\n     *\n     *    monoSynth.triggerAttack(\"E3\");\n     *  }\n     *\n     *  function mouseReleased() {\n     *    monoSynth.triggerRelease();\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"triggerAttack\",\n    value: function triggerAttack(note, velocity) {\n      var secondsFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n      var freq = noteToFreq(note);\n      var vel = velocity || 0.1;\n      this.oscillator.freq(freq, 0, secondsFromNow);\n      this.env.ramp(this.output.gain, secondsFromNow, vel);\n    }\n    /**\n     *  Trigger the release of the Envelope. This is similar to releasing\n     *  the key on a piano and letting the sound fade according to the\n     *  release level and release time.\n     *\n     *  @param  {Number} secondsFromNow time to trigger the release\n     *  @method  triggerRelease\n     *  @for p5.MonoSynth\n     *  @example\n     *  <div><code>\n     *  let monoSynth;\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(triggerAttack);\n     *    background(220);\n     *    text('tap here for attack, let go to release', 5, 20, width - 20);\n     *    monoSynth = new p5.MonoSynth();\n     *  }\n     *\n     *  function triggerAttack() {\n     *    userStartAudio();\n     *\n     *    monoSynth.triggerAttack(\"E3\");\n     *  }\n     *\n     *  function mouseReleased() {\n     *    monoSynth.triggerRelease();\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"triggerRelease\",\n    value: function triggerRelease() {\n      var secondsFromNow = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;\n      this.env.ramp(this.output.gain, secondsFromNow, 0);\n    }\n    /**\n     *  Set values like a traditional\n     *  <a href=\"https://en.wikipedia.org/wiki/Synthesizer#/media/File:ADSR_parameter.svg\">\n     *  ADSR envelope\n     *  </a>.\n     *\n     *  @method  setADSR\n     *  @for p5.MonoSynth\n     *  @param {Number} attackTime    Time (in seconds before envelope\n     *                                reaches Attack Level\n     *  @param {Number} [decayTime]    Time (in seconds) before envelope\n     *                                reaches Decay/Sustain Level\n     *  @param {Number} [susRatio]    Ratio between attackLevel and releaseLevel, on a scale from 0 to 1,\n     *                                where 1.0 = attackLevel, 0.0 = releaseLevel.\n     *                                The susRatio determines the decayLevel and the level at which the\n     *                                sustain portion of the envelope will sustain.\n     *                                For example, if attackLevel is 0.4, releaseLevel is 0,\n     *                                and susAmt is 0.5, the decayLevel would be 0.2. If attackLevel is\n     *                                increased to 1.0 (using <code>setRange</code>),\n     *                                then decayLevel would increase proportionally, to become 0.5.\n     *  @param {Number} [releaseTime]   Time in seconds from now (defaults to 0)\n     */\n\n  }, {\n    key: \"setADSR\",\n    value: function setADSR(attack, decay, sustain, release) {\n      this.env.setADSR(attack, decay, sustain, release);\n    }\n    /**\n     * MonoSynth amp\n     * @method  amp\n     * @for p5.MonoSynth\n     * @param  {Number} vol      desired volume\n     * @param  {Number} [rampTime] Time to reach new volume\n     * @return {Number}          new volume value\n     */\n\n  }, {\n    key: \"amp\",\n    value: function amp(vol, rampTime) {\n      var t = rampTime || 0;\n\n      if (typeof vol !== 'undefined') {\n        this.oscillator.amp(vol, t);\n      }\n\n      return this.oscillator.amp().value;\n    }\n    /**\n     *  Connect to a p5.sound / Web Audio object.\n     *\n     *  @method  connect\n     *  @for p5.MonoSynth\n     *  @param  {Object} unit A p5.sound or Web Audio object\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      var u = unit || main.input;\n      this.output.connect(u.input ? u.input : u);\n    }\n    /**\n     *  Disconnect all outputs\n     *\n     *  @method  disconnect\n     *  @for p5.MonoSynth\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.output) {\n        this.output.disconnect();\n      }\n    }\n    /**\n     *  Get rid of the MonoSynth and free up its resources / memory.\n     *\n     *  @method  dispose\n     *  @for p5.MonoSynth\n     */\n\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      monosynth_get(monosynth_getPrototypeOf(MonoSynth.prototype), \"dispose\", this).call(this);\n\n      if (this.env) {\n        this.env.dispose();\n      }\n\n      if (this.oscillator) {\n        this.oscillator.dispose();\n      }\n    }\n  }]);\n\n  return MonoSynth;\n}(audioVoice_0);\n\n var monosynth = (monosynth_MonoSynth);\nfunction onsetDetect_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction onsetDetect_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction onsetDetect_createClass(Constructor, protoProps, staticProps) { if (protoProps) onsetDetect_defineProperties(Constructor.prototype, protoProps); if (staticProps) onsetDetect_defineProperties(Constructor, staticProps); return Constructor; }\n\n/**\n *  Listen for onsets (a sharp increase in volume) within a given\n *  frequency range.\n *\n *  @class p5.OnsetDetect\n *  @constructor\n *  @param {Number} freqLow     Low frequency\n *  @param {Number} freqHigh     High frequency\n *  @param {Number} threshold   Amplitude threshold between 0 (no energy) and 1 (maximum)\n *  @param {Function} callback  Function to call when an onset is detected\n */\nvar OnsetDetect =\nfunction () {\n  function OnsetDetect(freqLow, freqHigh, threshold, callback) {\n    onsetDetect_classCallCheck(this, OnsetDetect);\n\n    this.isDetected = false;\n    this.freqLow = freqLow;\n    this.freqHigh = freqHigh;\n    this.treshold = threshold;\n    this.energy = 0;\n    this.penergy = 0; \n\n    this.sensitivity = 500;\n    this.callback = callback;\n  } \n\n\n  onsetDetect_createClass(OnsetDetect, [{\n    key: \"update\",\n    value: function update(fftObject, callback) {\n      this.energy = fftObject.getEnergy(this.freqLow, this.freqHigh) / 255;\n\n      if (this.isDetected === false) {\n        if (this.energy - this.penergy > this.treshold) {\n          this.isDetected = true;\n\n          if (this.callback) {\n            this.callback(this.energy);\n          } else if (callback) {\n            callback(this.energy);\n          }\n\n          var self = this;\n          setTimeout(function () {\n            self.isDetected = false;\n          }, this.sensitivity);\n        }\n      }\n\n      this.penergy = this.energy;\n    }\n  }]);\n\n  return OnsetDetect;\n}();\n\n var onsetDetect = (OnsetDetect);\nfunction polysynth_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction polysynth_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction polysynth_createClass(Constructor, protoProps, staticProps) { if (protoProps) polysynth_defineProperties(Constructor.prototype, protoProps); if (staticProps) polysynth_defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n\n/**\n *  An AudioVoice is used as a single voice for sound synthesis.\n *  The PolySynth class holds an array of AudioVoice, and deals\n *  with voices allocations, with setting notes to be played, and\n *  parameters to be set.\n *\n *  @class p5.PolySynth\n *  @constructor\n *\n *  @param {Number} [synthVoice]   A monophonic synth voice inheriting\n *                                 the AudioVoice class. Defaults to p5.MonoSynth\n *  @param {Number} [maxVoices] Number of voices, defaults to 8;\n *  @example\n *  <div><code>\n *  let polySynth;\n *\n *  function setup() {\n *    let cnv = createCanvas(100, 100);\n *    cnv.mousePressed(playSynth);\n *    background(220);\n *    text('click to play', 20, 20);\n *\n *    polySynth = new p5.PolySynth();\n *  }\n *\n *  function playSynth() {\n *    userStartAudio();\n *\n *    // note duration (in seconds)\n *    let dur = 1.5;\n *\n *    // time from now (in seconds)\n *    let time = 0;\n *\n *    // velocity (volume, from 0 to 1)\n *    let vel = 0.1;\n *\n *    // notes can overlap with each other\n *    polySynth.play('G2', vel, 0, dur);\n *    polySynth.play('C3', vel, time += 1/3, dur);\n *    polySynth.play('G3', vel, time += 1/3, dur);\n *  }\n *  </code></div>\n **/\n\nvar polysynth_PolySynth =\nfunction () {\n  function PolySynth(audioVoice, maxVoices) {\n    polysynth_classCallCheck(this, PolySynth);\n\n    this.audiovoices = [];\n    /**\n     * An object that holds information about which notes have been played and\n     * which notes are currently being played. New notes are added as keys\n     * on the fly. While a note has been attacked, but not released, the value of the\n     * key is the audiovoice which is generating that note. When notes are released,\n     * the value of the key becomes undefined.\n     * @property notes\n     */\n\n    this.notes = {}; \n\n    this._newest = 0;\n    this._oldest = 0;\n    /**\n     * A PolySynth must have at least 1 voice, defaults to 8\n     * @property polyvalue\n     */\n\n    this.maxVoices = maxVoices || 8;\n    /**\n     * Monosynth that generates the sound for each note that is triggered. The\n     * p5.PolySynth defaults to using the p5.MonoSynth as its voice.\n     * @property AudioVoice\n     */\n\n    this.AudioVoice = audioVoice === undefined ? p5.MonoSynth : audioVoice;\n    /**\n     * This value must only change as a note is attacked or released. Due to delay\n     * and sustain times, Tone.TimelineSignal is required to schedule the change in value.\n     * @private\n     * @property {Tone.TimelineSignal} _voicesInUse\n     */\n\n    this._voicesInUse = new TimelineSignal_default.a(0);\n    this.output = main.audiocontext.createGain();\n    this.connect(); \n\n    this._allocateVoices();\n\n    main.soundArray.push(this);\n  }\n  /**\n   * Construct the appropriate number of audiovoices\n   * @private\n   * @for p5.PolySynth\n   * @method  _allocateVoices\n   */\n\n\n  polysynth_createClass(PolySynth, [{\n    key: \"_allocateVoices\",\n    value: function _allocateVoices() {\n      for (var i = 0; i < this.maxVoices; i++) {\n        this.audiovoices.push(new this.AudioVoice());\n        this.audiovoices[i].disconnect();\n        this.audiovoices[i].connect(this.output);\n      }\n    }\n    /**\n     *  Play a note by triggering noteAttack and noteRelease with sustain time\n     *\n     *  @method  play\n     *  @for p5.PolySynth\n     *  @param  {Number} [note] midi note to play (ranging from 0 to 127 - 60 being a middle C)\n     *  @param  {Number} [velocity] velocity of the note to play (ranging from 0 to 1)\n     *  @param  {Number} [secondsFromNow]  time from now (in seconds) at which to play\n     *  @param  {Number} [sustainTime] time to sustain before releasing the envelope\n     *  @example\n     *  <div><code>\n     *  let polySynth;\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(playSynth);\n     *    background(220);\n     *    text('click to play', 20, 20);\n     *\n     *    polySynth = new p5.PolySynth();\n     *  }\n     *\n     *  function playSynth() {\n     *    userStartAudio();\n     *\n     *    // note duration (in seconds)\n     *    let dur = 1.5;\n     *\n     *    // time from now (in seconds)\n     *    let time = 0;\n     *\n     *    // velocity (volume, from 0 to 1)\n     *    let vel = 0.1;\n     *\n     *    // notes can overlap with each other\n     *    polySynth.play('G2', vel, 0, dur);\n     *    polySynth.play('C3', vel, time += 1/3, dur);\n     *    polySynth.play('G3', vel, time += 1/3, dur);\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"play\",\n    value: function play(note, velocity, secondsFromNow) {\n      var susTime = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n      this.noteAttack(note, velocity, secondsFromNow);\n      this.noteRelease(note, secondsFromNow + susTime);\n    }\n    /**\n     *  noteADSR sets the envelope for a specific note that has just been triggered.\n     *  Using this method modifies the envelope of whichever audiovoice is being used\n     *  to play the desired note. The envelope should be reset before noteRelease is called\n     *  in order to prevent the modified envelope from being used on other notes.\n     *\n     *  @method  noteADSR\n     *  @for p5.PolySynth\n     *  @param {Number} [note]        Midi note on which ADSR should be set.\n     *  @param {Number} [attackTime]  Time (in seconds before envelope\n     *                                reaches Attack Level\n     *  @param {Number} [decayTime]   Time (in seconds) before envelope\n     *                                reaches Decay/Sustain Level\n     *  @param {Number} [susRatio]    Ratio between attackLevel and releaseLevel, on a scale from 0 to 1,\n     *                                where 1.0 = attackLevel, 0.0 = releaseLevel.\n     *                                The susRatio determines the decayLevel and the level at which the\n     *                                sustain portion of the envelope will sustain.\n     *                                For example, if attackLevel is 0.4, releaseLevel is 0,\n     *                                and susAmt is 0.5, the decayLevel would be 0.2. If attackLevel is\n     *                                increased to 1.0 (using <code>setRange</code>),\n     *                                then decayLevel would increase proportionally, to become 0.5.\n     *  @param {Number} [releaseTime]   Time in seconds from now (defaults to 0)\n     **/\n\n  }, {\n    key: \"noteADSR\",\n    value: function noteADSR(note, a, d, s, r) {\n      var timeFromNow = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;\n      var now = main.audiocontext.currentTime;\n      var t = now + timeFromNow;\n      this.audiovoices[this.notes[note].getValueAtTime(t)].setADSR(a, d, s, r);\n    }\n    /**\n     * Set the PolySynths global envelope. This method modifies the envelopes of each\n     * monosynth so that all notes are played with this envelope.\n     *\n     *  @method  setADSR\n     *  @for p5.PolySynth\n     *  @param {Number} [attackTime]  Time (in seconds before envelope\n     *                                reaches Attack Level\n     *  @param {Number} [decayTime]   Time (in seconds) before envelope\n     *                                reaches Decay/Sustain Level\n     *  @param {Number} [susRatio]    Ratio between attackLevel and releaseLevel, on a scale from 0 to 1,\n     *                                where 1.0 = attackLevel, 0.0 = releaseLevel.\n     *                                The susRatio determines the decayLevel and the level at which the\n     *                                sustain portion of the envelope will sustain.\n     *                                For example, if attackLevel is 0.4, releaseLevel is 0,\n     *                                and susAmt is 0.5, the decayLevel would be 0.2. If attackLevel is\n     *                                increased to 1.0 (using <code>setRange</code>),\n     *                                then decayLevel would increase proportionally, to become 0.5.\n     *  @param {Number} [releaseTime]   Time in seconds from now (defaults to 0)\n     **/\n\n  }, {\n    key: \"setADSR\",\n    value: function setADSR(a, d, s, r) {\n      this.audiovoices.forEach(function (voice) {\n        voice.setADSR(a, d, s, r);\n      });\n    }\n    /**\n     *  Trigger the Attack, and Decay portion of a MonoSynth.\n     *  Similar to holding down a key on a piano, but it will\n     *  hold the sustain level until you let go.\n     *\n     *  @method  noteAttack\n     *  @for p5.PolySynth\n     *  @param  {Number} [note]           midi note on which attack should be triggered.\n     *  @param  {Number} [velocity]       velocity of the note to play (ranging from 0 to 1)/\n     *  @param  {Number} [secondsFromNow] time from now (in seconds)\n     *  @example\n     *  <div><code>\n     *  let polySynth = new p5.PolySynth();\n     *  let pitches = ['G', 'D', 'G', 'C'];\n     *  let octaves = [2, 3, 4];\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(playChord);\n     *    background(220);\n     *    text('tap to play', 20, 20);\n     *  }\n     *\n     *  function playChord() {\n     *    userStartAudio();\n     *\n     *    // play a chord: multiple notes at the same time\n     *    for (let i = 0; i < 4; i++) {\n     *      let note = random(pitches) + random(octaves);\n     *      polySynth.noteAttack(note, 0.1);\n     *    }\n     *  }\n     *\n     *  function mouseReleased() {\n     *    // release all voices\n     *    polySynth.noteRelease();\n     *  }\n     *  </code></div>\n     */\n\n  }, {\n    key: \"noteAttack\",\n    value: function noteAttack(_note, _velocity) {\n      var secondsFromNow = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n      var acTime = main.audiocontext.currentTime + secondsFromNow; \n\n      var note = noteToFreq(_note);\n      var velocity = _velocity || 0.1;\n      var currentVoice; \n\n      if (this.notes[note] && this.notes[note].getValueAtTime(acTime) !== null) {\n        this.noteRelease(note, 0);\n      } \n\n\n      if (this._voicesInUse.getValueAtTime(acTime) < this.maxVoices) {\n        currentVoice = Math.max(~~this._voicesInUse.getValueAtTime(acTime), 0);\n      } \n      else {\n          currentVoice = this._oldest;\n          oldestNote = freqToMidi(this.audiovoices[this._oldest].oscillator.freq().value);\n          this.noteRelease(oldestNote);\n          this._oldest = (this._oldest + 1) % (this.maxVoices - 1);\n        } \n\n\n      this.notes[note] = new TimelineSignal_default.a();\n      this.notes[note].setValueAtTime(currentVoice, acTime); \n\n      var previousVal = this._voicesInUse._searchBefore(acTime) === null ? 0 : this._voicesInUse._searchBefore(acTime).value;\n\n      this._voicesInUse.setValueAtTime(previousVal + 1, acTime); \n\n\n      this._updateAfter(acTime, 1);\n\n      this._newest = currentVoice; \n\n      if (typeof velocity === 'number') {\n        var maxRange = 1 / this._voicesInUse.getValueAtTime(acTime) * 2;\n        velocity = velocity > maxRange ? maxRange : velocity;\n      } \n\n\n      this.audiovoices[currentVoice].triggerAttack(note, velocity, secondsFromNow);\n    }\n    /**\n     * Private method to ensure accurate values of this._voicesInUse\n     * Any time a new value is scheduled, it is necessary to increment all subsequent\n     * scheduledValues after attack, and decrement all subsequent\n     * scheduledValues after release\n     *\n     * @private\n     * @for p5.PolySynth\n     * @param  {[type]} time  [description]\n     * @param  {[type]} value [description]\n     * @return {[type]}       [description]\n     */\n\n  }, {\n    key: \"_updateAfter\",\n    value: function _updateAfter(time, value) {\n      if (this._voicesInUse._searchAfter(time) === null) {\n        return;\n      } else {\n        this._voicesInUse._searchAfter(time).value += value;\n\n        var nextTime = this._voicesInUse._searchAfter(time).time;\n\n        this._updateAfter(nextTime, value);\n      }\n    }\n    /**\n     *  Trigger the Release of an AudioVoice note. This is similar to releasing\n     *  the key on a piano and letting the sound fade according to the\n     *  release level and release time.\n     *\n     *  @method  noteRelease\n     *  @for p5.PolySynth\n     *  @param  {Number} [note]           midi note on which attack should be triggered.\n     *                                    If no value is provided, all notes will be released.\n     *  @param  {Number} [secondsFromNow] time to trigger the release\n     *  @example\n     *  <div><code>\n     *  let polySynth = new p5.PolySynth();\n     *  let pitches = ['G', 'D', 'G', 'C'];\n     *  let octaves = [2, 3, 4];\n     *\n     *  function setup() {\n     *    let cnv = createCanvas(100, 100);\n     *    cnv.mousePressed(playChord);\n     *    background(220);\n     *    text('tap to play', 20, 20);\n     *  }\n     *\n     *  function playChord() {\n     *    userStartAudio();\n     *\n     *    // play a chord: multiple notes at the same time\n     *    for (let i = 0; i < 4; i++) {\n     *      let note = random(pitches) + random(octaves);\n     *      polySynth.noteAttack(note, 0.1);\n     *    }\n     *  }\n     *\n     *  function mouseReleased() {\n     *    // release all voices\n     *    polySynth.noteRelease();\n     *  }\n     *  </code></div>\n     *\n     */\n\n  }, {\n    key: \"noteRelease\",\n    value: function noteRelease(_note, secondsFromNow) {\n      var now = main.audiocontext.currentTime;\n      var tFromNow = secondsFromNow || 0;\n      var t = now + tFromNow; \n\n      if (!_note) {\n        this.audiovoices.forEach(function (voice) {\n          voice.triggerRelease(tFromNow);\n        });\n\n        this._voicesInUse.setValueAtTime(0, t);\n\n        for (var n in this.notes) {\n          this.notes[n].dispose();\n          delete this.notes[n];\n        }\n\n        return;\n      } \n\n\n      var note = noteToFreq(_note);\n\n      if (!this.notes[note] || this.notes[note].getValueAtTime(t) === null) {\n        console.warn('Cannot release a note that is not already playing');\n      } else {\n        var previousVal = Math.max(~~this._voicesInUse.getValueAtTime(t).value, 1);\n\n        this._voicesInUse.setValueAtTime(previousVal - 1, t); \n\n\n        if (previousVal > 0) {\n          this._updateAfter(t, -1);\n        }\n\n        this.audiovoices[this.notes[note].getValueAtTime(t)].triggerRelease(tFromNow);\n        this.notes[note].dispose();\n        delete this.notes[note];\n        this._newest = this._newest === 0 ? 0 : (this._newest - 1) % (this.maxVoices - 1);\n      }\n    }\n    /**\n     *  Connect to a p5.sound / Web Audio object.\n     *\n     *  @method  connect\n     *  @for p5.PolySynth\n     *  @param  {Object} unit A p5.sound or Web Audio object\n     */\n\n  }, {\n    key: \"connect\",\n    value: function connect(unit) {\n      var u = unit || main.input;\n      this.output.connect(u.input ? u.input : u);\n    }\n    /**\n     *  Disconnect all outputs\n     *\n     *  @method  disconnect\n     *  @for p5.PolySynth\n     */\n\n  }, {\n    key: \"disconnect\",\n    value: function disconnect() {\n      if (this.output) {\n        this.output.disconnect();\n      }\n    }\n    /**\n     *  Get rid of the MonoSynth and free up its resources / memory.\n     *\n     *  @method  dispose\n     *  @for p5.PolySynth\n     */\n\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      this.audiovoices.forEach(function (voice) {\n        voice.dispose();\n      });\n\n      if (this.output) {\n        this.output.disconnect();\n        delete this.output;\n      }\n    }\n  }]);\n\n  return PolySynth;\n}();\n\n var polysynth = (polysynth_PolySynth);\nfunction Signal_classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Signal_Signal = function Signal() {\n  Signal_classCallCheck(this, Signal);\n\n  console.warn('p5.Signal is deprecated , Use Tone.js Signal instead ');\n};\n\n var deprecations_Signal = (Signal_Signal);\n\n\n\np5.prototype.getAudioContext = audiocontext[\"b\" ];\np5.prototype.userStartAudio = audiocontext[\"c\" ];\n\n\np5.prototype.sampleRate = sampleRate;\np5.prototype.freqToMidi = freqToMidi;\np5.prototype.midiToFreq = midiToFreq;\np5.prototype.noteToFreq = noteToFreq;\np5.prototype.soundFormats = soundFormats;\np5.prototype.disposeSound = disposeSound;\np5.prototype._checkFileFormats = _checkFileFormats;\np5.prototype._mathChain = _mathChain;\np5.prototype.convertToWav = convertToWav;\np5.prototype.interleave = interleave;\np5.prototype.writeUTFBytes = writeUTFBytes;\np5.prototype.safeBufferSize = safeBufferSize;\np5.prototype.saveSound = saveSound; \n\np5.prototype.registerMethod('remove', p5.prototype.disposeSound);\n\n\n\np5.Panner = panner_0;\n\np5.SoundFile = soundfile;\np5.prototype.loadSound = loadSound; \n\np5.prototype.registerPreloadMethod('loadSound', p5.prototype);\n\np5.Amplitude = amplitude;\n\np5.FFT = fft;\n\np5.Oscillator = oscillator;\np5.SinOsc = SinOsc;\np5.TriOsc = TriOsc;\np5.SawOsc = SawOsc;\np5.SqrOsc = SqrOsc;\n\n\np5.Noise = noise;\n\np5.Pulse = pulse;\n\np5.AudioIn = audioin;\n\np5.Effect = effect;\n\np5.Filter = filter;\np5.LowPass = LowPass;\np5.HighPass = HighPass;\np5.BandPass = BandPass;\n\np5.EQ = eq;\n\np5.listener3D = listener3d;\n\np5.Panner3D = panner3d;\n\np5.Delay = delay;\n\np5.Reverb = Reverb;\np5.Convolver = reverb_Convolver;\np5.prototype.createConvolver = createConvolver;\np5.prototype.registerPreloadMethod('createConvolver', p5.prototype);\n\np5.Metro = metro;\n\np5.Phrase = Phrase;\np5.Part = looper_Part;\np5.Score = Score;\n\np5.SoundLoop = soundLoop;\n\np5.Compressor = compressor;\n\np5.peakDetect = peakDetect;\n\np5.SoundRecorder = soundRecorder;\n\np5.Distortion = distortion;\n\np5.Gain = gain;\n\np5.AudioVoice = audioVoice_0;\n\np5.MonoSynth = monosynth;\n\np5.OnsetDetect = onsetDetect;\n\np5.PolySynth = polysynth;\n\np5.PeakDetect = peakDetect; \n\n\np5.Signal = deprecations_Signal;\n\n })\n ]);\n","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"container\"},[_vm._ssrNode(\"<div class=\\\"content\\\" data-v-3e22d00c><div id=\\\"p5Canvas\\\" class=\\\"flex justify-center\\\" data-v-3e22d00c></div> <div class=\\\"tools\\\" data-v-3e22d00c><div class=\\\"pt-6\\\" data-v-3e22d00c><div id=\\\"p5_loading\\\" class=\\\"animate-pulse\\\" data-v-3e22d00c>Loading...</div> <div id=\\\"Play\\\" class=\\\"animate-pulse hide cursor-pointer\\\" data-v-3e22d00c>Click to play</div></div></div></div>\")])}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport Vue from 'vue'\n\nexport default Vue.extend({\n\t\n\tmounted() {   \n\t const script = function (p5) {    \n\t  var speed = 2;    \n\t  var posX = 0;\n\t  let font;\n\t  let points;\n\t  let bounds;\n\t  var para = 200;\n\t  let song;\nlet fft;\nlet analyser;\n\t  \n\t  // NOTE: Set up is here  \n\t  p5.preload = _ => {      \n\t   font = p5.loadFont('UniversalSansDisplayTrial491-Regular.otf');   \n\t   song = p5.loadSound('20181201121239_05-feedback.mp3',soundLoaded); \n\t  }   \n\t  p5.setup = _ => {      \n\t   var canvas = p5.createCanvas(p5.displayWidth, p5.displayHeight);   \n\t   canvas.parent(\"p5Canvas\");   \n\t   \n\t    p5.stroke(255,0,0); \n\t\t  p5.strokeWeight(4);\n\t\t  p5.noFill();\n\t\t\n\t\t  \n\t\t  fft = new P5.FFT();  \n\t\t  analyser = new P5.Amplitude();\n  \n\t  }     \n\t  // NOTE: Draw is here\n\t  p5.draw = _ => {     \n\t\t  p5.background(0);\n\n\t\t  let waveform = fft.waveform();\n\t\t  let amp = analyser.getLevel();\n\t\t  amp = p5.map(amp, 0, 1, -100, 100);\n\t\t  \n\t\t  p5.stroke(255, 255, 255);\n\t\t  p5.strokeWeight(1);\n\t\t  \n\t\t  for (let i = 0; i< waveform.length; i++){\n\t\t    let x = p5.map(i, 0, waveform.length, 0, p5.width);\n\t\t    let y = p5.map( waveform[i], -1, 1, 0, p5.height);\n\t\t    p5.point(x,y);\n\t\t  }\n\t\t  \n\t\t  p5.stroke(255, 0, 0);\n\t\t  p5.strokeWeight(5);\n\t\t  \n\t\t  noiseLine(10, p5.height / 2, p5.width - 20, 0, 0, amp);\n\t   \n\t  }  \n\t  \n\t  p5.mouseClicked = _ => {\n\t\tdocument.getElementById('Play').classList.add(\"hide\");\n\t \tsong.play();\n\t  }\n\t  \n\t  function soundLoaded()\n\t  {\n\t\t  document.getElementById('Play').classList.remove(\"hide\");\n\t\t  //parent.isLoadPage = true;\n\t  }\n\t  \n\t  \n\t  function noiseLine(x, y, len, angle, noiseOff, amp) {\n\t\t  p5.push();\n\t\t  p5.translate(x, y);\n\t\t  p5.rotate(angle);\n\t\t    \n\t\t  let numSegs = 10;\n\t\t  let segLen = len / numSegs;\n\t\t  \n\t\t  let px = 0;\n\t\t  let py = 0;\n\t\t  \n\t\t  let freq = 0.01; // sldFreq.value();\n\t\t  \n\t\t  for( let i = segLen; i < len; i += segLen){\n\t\t    let sampX = (noiseOff + p5.frameCount + i) * freq;\n\t\t    let yOff = p5.noise(sampX);\n\t\t    yOff = p5.map(yOff, 0, 1, -amp, amp);\n\t\t    \n\t\t    let nx = i;\n\t\t    let ny = yOff;\n\t\t    \n\t\t    p5.line(px, py, nx, ny);\n\t\t    \n\t\t    px = nx;\n\t\t    py = ny;\n\t\t  }\n\t\t  \n\t\t  p5.line(px, py, len, 0); \n\t\t  \n\t\t  p5.pop();\n\t\t}\n\t }   \n\n\t // NOTE: Use p5 as an instance mode\n\t const P5 = require('p5');\n\t const P5Sound = require('p5/lib/addons/p5.sound');\n\t //import * as p5Class from 'p5'\n\t \n\t this.tito = new P5(script)\n\t},\n\tdata() {\n\t    return {\n\t\t  tito:'',\n\t\t  bg:0,\n\t\t  isLoadPage:false,\n\t    }\n\t  },\n\tmethods: {\n\t\tPlay() {\n\t\t\tconsole.log(\"tito: \" + this.tito)\n\t\t\tthis.bg = 255\n\t\t  //this.tito.background(255);\n\t    }\n\t}\n})\n","import mod from \"-!../../node_modules/@nuxt/components/dist/loader.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./page_1.vue?vue&type=script&lang=ts&\"; export default mod; export * from \"-!../../node_modules/@nuxt/components/dist/loader.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./page_1.vue?vue&type=script&lang=ts&\"","import { render, staticRenderFns } from \"./page_1.vue?vue&type=template&id=3e22d00c&scoped=true&\"\nimport script from \"./page_1.vue?vue&type=script&lang=ts&\"\nexport * from \"./page_1.vue?vue&type=script&lang=ts&\"\nfunction injectStyles (context) {\n  \n  \n}\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  injectStyles,\n  \"3e22d00c\",\n  \"494e77a4\"\n  \n)\n\nexport default component.exports"],"mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AC3+XA;AACA;AACA;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC5IA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;A","sourceRoot":""}